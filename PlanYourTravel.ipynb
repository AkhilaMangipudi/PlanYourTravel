{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PlanYourTravel.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CraB918UhcgV",
        "colab_type": "code",
        "outputId": "68306e32-7053-4b33-d992-3ed1ee626340",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "!git clone https://github.com/AkhilaMangipudi/PlanYourTravel.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'PlanYourTravel'...\n",
            "remote: Enumerating objects: 13, done.\u001b[K\n",
            "remote: Counting objects: 100% (13/13), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 13 (delta 1), reused 10 (delta 1), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (13/13), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ga159nzhghn",
        "colab_type": "code",
        "outputId": "5609b357-865e-45ff-da3f-e60c93cb4042",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd PlanYourTravel/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/PlanYourTravel\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTil2CpFhuR9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import data.load\n",
        "\n",
        "train_set, valid_set, dicts = data.load.atisfull()\n",
        "w2idx, labels2idx = dicts['words2idx'], dicts['labels2idx']\n",
        "\n",
        "train_x, _, train_label = train_set\n",
        "val_x, _, val_label = valid_set\n",
        "\n",
        "# Create index to word/label dicts\n",
        "idx2w  = {w2idx[k]:k for k in w2idx}\n",
        "idx2la = {labels2idx[k]:k for k in labels2idx}\n",
        "\n",
        "# For conlleval script\n",
        "words_train = [ list(map(lambda x: idx2w[x], w)) for w in train_x]\n",
        "labels_train = [ list(map(lambda x: idx2la[x], y)) for y in train_label]\n",
        "words_val = [ list(map(lambda x: idx2w[x], w)) for w in val_x]\n",
        "labels_val = [ list(map(lambda x: idx2la[x], y)) for y in val_label]\n",
        "\n",
        "n_classes = len(idx2la)\n",
        "n_vocab = len(idx2w)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQWOl7TuuXT9",
        "colab_type": "code",
        "outputId": "12824285-bcd1-4fbc-e563-cf5ee0a11161",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "def replaceDigits(words):\n",
        "  digits_list = ['DIGITDIGITDIGIT', 'DIGITDIGITDIGITDIGIT', 'DIGITDIGIT', 'DIGIT']\n",
        "  words_train_new = []\n",
        "  for sentence in words:\n",
        "    sentence_new = [word if word not in digits_list else 'time' for word in sentence]\n",
        "    words_train_new.append(sentence_new)\n",
        "  return words_train_new\n",
        "\n",
        "########### Replacing all possible digit combinations with a word 'time' ############\n",
        "words_train = replaceDigits(words_train)\n",
        "words_val = replaceDigits(words_val)\n",
        "\n",
        "print(len(words_train))\n",
        "print(len(words_val))\n",
        "print(words_train[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4978\n",
            "893\n",
            "['i', 'want', 'to', 'fly', 'from', 'boston', 'at', 'time', 'am', 'and', 'arrive', 'in', 'denver', 'at', 'time', 'in', 'the', 'morning']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tX1MnnkgHIKY",
        "colab_type": "code",
        "outputId": "48d98d7f-c467-4de1-afd9-ce2097316137",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        }
      },
      "source": [
        "#Download Glove\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-17 16:43:04--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2019-11-17 16:43:05--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2019-11-17 16:43:05--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip         78%[==============>     ] 646.46M  1.88MB/s    eta 83s    "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtrzyr6IHNZb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip glove*.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MI9rvfOLHQFb",
        "colab_type": "code",
        "outputId": "25153dff-612c-4120-d3fa-871bc62d1e24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# load the whole embedding into memory\n",
        "embeddings_index = dict()\n",
        "f = open('glove.6B.300d.txt')\n",
        "for line in f:\n",
        "\tvalues = line.split()\n",
        "\tword = values[0]\n",
        "\tcoefs = np.asarray(values[1:], dtype='float32')\n",
        "\tembeddings_index[word] = coefs\n",
        "f.close()\n",
        "print('Loaded %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKfnxIXIHSMV",
        "colab_type": "code",
        "outputId": "5a5bbe1b-f9b5-4186-c23d-7e9e55865135",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "# pad documents to a max length of 4 words\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "maxLen = 50\n",
        "padded_docs = pad_sequences(train_x, maxlen=maxLen, padding='post')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nf7kwoNBsvey",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#EMBEDDING_DIM =300\n",
        "import re\n",
        "embedding_matrix = np.zeros((len(dicts['words2idx']), 300))\n",
        "for word, i in dicts['words2idx'].items():\n",
        "  word = re.sub('[^\\w\\s]','',word) #remove punctuation\n",
        "  #print(word)\n",
        "  embedding_vector = embeddings_index.get(word)\n",
        "  #print(embedding_vector)\n",
        "  if embedding_vector is not None:\n",
        "    embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ak-jVqWIBxU",
        "colab_type": "text"
      },
      "source": [
        "# **1D-CNN Models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HLIYexFlBR41",
        "colab": {}
      },
      "source": [
        "n_vocab = n_vocab + 1 #Adding an additional word padding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Z59ThQ49BF5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_past_window(data, label, window_size):\n",
        "    cnn_input = []\n",
        "    cnn_labels = []\n",
        "    initial_pad = [n_vocab-1 for x in range(window_size-1)]\n",
        "    for x in data:\n",
        "        x= np.insert(x, 0, initial_pad)\n",
        "        for i in range(window_size-1, len(x)):\n",
        "            cnn_input.append(np.asarray(x[i-window_size+1:i+1]))\n",
        "\n",
        "    for label in label:\n",
        "        for temp in label:\n",
        "            cnn_labels.append(temp)\n",
        "    return np.asarray(cnn_input),  np.asarray(cnn_labels)           "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTHx4RfXBFXA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_future_window(data, labels, window_size):\n",
        "    cnn_input = []\n",
        "    cnn_labels = []\n",
        "    initial_pad = [n_vocab-1 for x in range(window_size-1)]\n",
        "    for x in data:\n",
        "        x = np.append(x, initial_pad)\n",
        "        for i in range(0, len(x)-window_size+1):\n",
        "            cnn_input.append(np.asarray(x[i:i+window_size]))\n",
        "\n",
        "    for label in labels:\n",
        "        for temp in label:\n",
        "            cnn_labels.append(temp)\n",
        "    return np.asarray(cnn_input),  np.asarray(cnn_labels)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQsh8OA5B4EO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_past_and_future_window(data, label, window_size):\n",
        "    cnn_input = []\n",
        "    cnn_labels = []\n",
        "    half_size = int(window_size/2);\n",
        "    initial_pad = [n_vocab-1 for x in range(half_size)]\n",
        "    for x in data:\n",
        "        x = np.insert(x, 0, initial_pad)\n",
        "        x = np.append(x, initial_pad)\n",
        "        for i in range(half_size, len(x)-half_size):\n",
        "            cnn_input.append(np.asarray(x[i-half_size:i+half_size+1]))\n",
        "\n",
        "    for label in label:\n",
        "        for temp in label:\n",
        "            cnn_labels.append(temp)\n",
        "    return np.asarray(cnn_input),  np.asarray(cnn_labels) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohQuVraeCwxn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D, Convolution1D, MaxPooling1D\n",
        "from keras.utils import np_utils\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.optimizers import *\n",
        "from keras import regularizers\n",
        "\n",
        "from keras.layers import Conv1D\n",
        "\n",
        "def get_conv_model(window_length, kernelsize=3):   \n",
        "    model = Sequential()\n",
        "    model.add(Embedding(n_vocab, 100, input_length=window_length))\n",
        "    model.add(Conv1D(100, kernel_size=kernelsize, activation='relu', padding=\"same\"))\n",
        "    model.add(MaxPooling1D(pool_size=2))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dense(n_classes, activation='softmax'))\n",
        "    optim = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
        "    model.compile(loss='sparse_categorical_crossentropy', optimizer=optim, metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcZosKrSDKi3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#For prediction\n",
        "from metrics.accuracy import conlleval\n",
        "\n",
        "def print_evaluation(model, input_idx, output, input_words):\n",
        "    y_pred = model.predict(input_idx)\n",
        "    y_pred_temp = [np.argmax(t) for t in y_pred]\n",
        "\n",
        "    labels_pred_val = []\n",
        "    k = 0\n",
        "    for x in input_words:\n",
        "        temp = []\n",
        "        for i in range(len(x)):\n",
        "            temp.append(y_pred_temp[k])\n",
        "            k = k + 1\n",
        "        labels_pred_val.append(temp)\n",
        "    \n",
        "    labels_pred_val = [ list(map(lambda x: idx2la[x], y)) \\\n",
        "                                    for y in labels_pred_val]\n",
        "    con_dict = conlleval(labels_pred_val, labels_val, \n",
        "                                words_val, 'measure.txt')\n",
        "\n",
        "    print('Precision = {}, Recall = {}, F1 = {}'.format(\n",
        "                con_dict['r'], con_dict['p'], con_dict['f1']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E40QCiCwNv97",
        "colab_type": "text"
      },
      "source": [
        "**Experiment with a window size of 3 using the past context words**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAJgvj2oMge_",
        "colab_type": "code",
        "outputId": "6609c9d9-3ac0-4885-e65b-ce56f4ddbb33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# past context of 3\n",
        "context_size = 3\n",
        "kernel_size = 3\n",
        "cnn_input, cnn_labels = get_past_window(train_x, train_label, context_size)\n",
        "val_input, val_labels = get_past_window(val_x, val_label, context_size)\n",
        "model = get_conv_model(context_size, kernel_size)\n",
        "model.fit(cnn_input, cnn_labels, epochs=30)\n",
        "print_evaluation(model, val_input, val_labels, val_x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 3, 100)            57300     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 3, 100)            30100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 1, 100)            0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1, 100)            0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 128)               12928     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 127)               16383     \n",
            "=================================================================\n",
            "Total params: 116,711\n",
            "Trainable params: 116,711\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.5821 - acc: 0.8810\n",
            "Epoch 2/30\n",
            "56590/56590 [==============================] - 10s 169us/step - loss: 0.1628 - acc: 0.9592\n",
            "Epoch 3/30\n",
            "56590/56590 [==============================] - 10s 168us/step - loss: 0.1132 - acc: 0.9690\n",
            "Epoch 4/30\n",
            "56590/56590 [==============================] - 9s 168us/step - loss: 0.0975 - acc: 0.9719\n",
            "Epoch 5/30\n",
            "56590/56590 [==============================] - 10s 169us/step - loss: 0.0852 - acc: 0.9739\n",
            "Epoch 6/30\n",
            "56590/56590 [==============================] - 9s 168us/step - loss: 0.0801 - acc: 0.9756\n",
            "Epoch 7/30\n",
            "56590/56590 [==============================] - 10s 168us/step - loss: 0.0749 - acc: 0.9761\n",
            "Epoch 8/30\n",
            "56590/56590 [==============================] - 10s 168us/step - loss: 0.0711 - acc: 0.9778\n",
            "Epoch 9/30\n",
            "56590/56590 [==============================] - 10s 169us/step - loss: 0.0677 - acc: 0.9783\n",
            "Epoch 10/30\n",
            "56590/56590 [==============================] - 10s 168us/step - loss: 0.0658 - acc: 0.9782\n",
            "Epoch 11/30\n",
            "56590/56590 [==============================] - 9s 167us/step - loss: 0.0639 - acc: 0.9791\n",
            "Epoch 12/30\n",
            "56590/56590 [==============================] - 9s 168us/step - loss: 0.0614 - acc: 0.9796\n",
            "Epoch 13/30\n",
            "56590/56590 [==============================] - 9s 166us/step - loss: 0.0618 - acc: 0.9800\n",
            "Epoch 14/30\n",
            "56590/56590 [==============================] - 9s 168us/step - loss: 0.0598 - acc: 0.9802\n",
            "Epoch 15/30\n",
            "56590/56590 [==============================] - 10s 168us/step - loss: 0.0594 - acc: 0.9801\n",
            "Epoch 16/30\n",
            "56590/56590 [==============================] - 10s 169us/step - loss: 0.0566 - acc: 0.9813\n",
            "Epoch 17/30\n",
            "56590/56590 [==============================] - 10s 169us/step - loss: 0.0568 - acc: 0.9813\n",
            "Epoch 18/30\n",
            "56590/56590 [==============================] - 10s 168us/step - loss: 0.0560 - acc: 0.9815\n",
            "Epoch 19/30\n",
            "56590/56590 [==============================] - 9s 167us/step - loss: 0.0545 - acc: 0.9816\n",
            "Epoch 20/30\n",
            "56590/56590 [==============================] - 10s 173us/step - loss: 0.0551 - acc: 0.9816\n",
            "Epoch 21/30\n",
            "56590/56590 [==============================] - 10s 169us/step - loss: 0.0531 - acc: 0.9821\n",
            "Epoch 22/30\n",
            "56590/56590 [==============================] - 9s 167us/step - loss: 0.0526 - acc: 0.9814\n",
            "Epoch 23/30\n",
            "56590/56590 [==============================] - 10s 169us/step - loss: 0.0555 - acc: 0.9814\n",
            "Epoch 24/30\n",
            "56590/56590 [==============================] - 10s 168us/step - loss: 0.0524 - acc: 0.9823\n",
            "Epoch 25/30\n",
            "56590/56590 [==============================] - 9s 165us/step - loss: 0.0527 - acc: 0.9822\n",
            "Epoch 26/30\n",
            "56590/56590 [==============================] - 9s 166us/step - loss: 0.0526 - acc: 0.9818\n",
            "Epoch 27/30\n",
            "56590/56590 [==============================] - 10s 169us/step - loss: 0.0514 - acc: 0.9823\n",
            "Epoch 28/30\n",
            "56590/56590 [==============================] - 10s 168us/step - loss: 0.0501 - acc: 0.9830\n",
            "Epoch 29/30\n",
            "56590/56590 [==============================] - 9s 166us/step - loss: 0.0510 - acc: 0.9822\n",
            "Epoch 30/30\n",
            "56590/56590 [==============================] - 9s 167us/step - loss: 0.0517 - acc: 0.9825\n",
            "Precision = 89.74, Recall = 86.98, F1 = 88.34\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Z0GbcQPeQGo_"
      },
      "source": [
        "**Experiment with a window size of 5 using the past context words**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQBnTeerMgpD",
        "colab_type": "code",
        "outputId": "e10b4b0f-d05a-4724-c7c0-aa65ac280cc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# past context of 5, kernel of 3\n",
        "context_size = 5\n",
        "kernel_size = 3\n",
        "cnn_input, cnn_labels = get_past_window(train_x, train_label, context_size)\n",
        "val_input, val_labels = get_past_window(val_x, val_label, context_size)\n",
        "model = get_conv_model(context_size, kernel_size)\n",
        "model.fit(cnn_input, cnn_labels, epochs=30)\n",
        "print_evaluation(model, val_input, val_labels, val_x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 5, 100)            57300     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 5, 100)            30100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1 (None, 2, 100)            0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 2, 100)            0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 128)               25728     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 127)               16383     \n",
            "=================================================================\n",
            "Total params: 129,511\n",
            "Trainable params: 129,511\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.6295 - acc: 0.8699\n",
            "Epoch 2/30\n",
            "56590/56590 [==============================] - 10s 171us/step - loss: 0.1876 - acc: 0.9542\n",
            "Epoch 3/30\n",
            "56590/56590 [==============================] - 10s 170us/step - loss: 0.1205 - acc: 0.9687\n",
            "Epoch 4/30\n",
            "56590/56590 [==============================] - 10s 170us/step - loss: 0.0927 - acc: 0.9749\n",
            "Epoch 5/30\n",
            "56590/56590 [==============================] - 10s 169us/step - loss: 0.0749 - acc: 0.9789\n",
            "Epoch 6/30\n",
            "56590/56590 [==============================] - 10s 171us/step - loss: 0.0657 - acc: 0.9812\n",
            "Epoch 7/30\n",
            "56590/56590 [==============================] - 9s 167us/step - loss: 0.0608 - acc: 0.9824\n",
            "Epoch 8/30\n",
            "56590/56590 [==============================] - 10s 170us/step - loss: 0.0540 - acc: 0.9837\n",
            "Epoch 9/30\n",
            "56590/56590 [==============================] - 10s 171us/step - loss: 0.0501 - acc: 0.9848\n",
            "Epoch 10/30\n",
            "56590/56590 [==============================] - 10s 170us/step - loss: 0.0465 - acc: 0.9858\n",
            "Epoch 11/30\n",
            "56590/56590 [==============================] - 10s 170us/step - loss: 0.0447 - acc: 0.9861\n",
            "Epoch 12/30\n",
            "56590/56590 [==============================] - 10s 170us/step - loss: 0.0403 - acc: 0.9876\n",
            "Epoch 13/30\n",
            "56590/56590 [==============================] - 10s 172us/step - loss: 0.0407 - acc: 0.9875\n",
            "Epoch 14/30\n",
            "56590/56590 [==============================] - 10s 171us/step - loss: 0.0390 - acc: 0.9884\n",
            "Epoch 15/30\n",
            "56590/56590 [==============================] - 10s 169us/step - loss: 0.0369 - acc: 0.9888\n",
            "Epoch 16/30\n",
            "56590/56590 [==============================] - 10s 169us/step - loss: 0.0375 - acc: 0.9884\n",
            "Epoch 17/30\n",
            "56590/56590 [==============================] - 10s 171us/step - loss: 0.0346 - acc: 0.9894\n",
            "Epoch 18/30\n",
            "56590/56590 [==============================] - 10s 170us/step - loss: 0.0338 - acc: 0.9897\n",
            "Epoch 19/30\n",
            "56590/56590 [==============================] - 10s 171us/step - loss: 0.0343 - acc: 0.9894\n",
            "Epoch 20/30\n",
            "56590/56590 [==============================] - 10s 170us/step - loss: 0.0345 - acc: 0.9897\n",
            "Epoch 21/30\n",
            "56590/56590 [==============================] - 10s 172us/step - loss: 0.0327 - acc: 0.9903\n",
            "Epoch 22/30\n",
            "56590/56590 [==============================] - 10s 173us/step - loss: 0.0317 - acc: 0.9906\n",
            "Epoch 23/30\n",
            "56590/56590 [==============================] - 10s 173us/step - loss: 0.0323 - acc: 0.9901\n",
            "Epoch 24/30\n",
            "56590/56590 [==============================] - 10s 172us/step - loss: 0.0308 - acc: 0.9903\n",
            "Epoch 25/30\n",
            "56590/56590 [==============================] - 10s 170us/step - loss: 0.0325 - acc: 0.9905\n",
            "Epoch 26/30\n",
            "56590/56590 [==============================] - 10s 172us/step - loss: 0.0305 - acc: 0.9911\n",
            "Epoch 27/30\n",
            "56590/56590 [==============================] - 10s 170us/step - loss: 0.0289 - acc: 0.9912\n",
            "Epoch 28/30\n",
            "56590/56590 [==============================] - 9s 168us/step - loss: 0.0287 - acc: 0.9917\n",
            "Epoch 29/30\n",
            "56590/56590 [==============================] - 10s 170us/step - loss: 0.0327 - acc: 0.9905\n",
            "Epoch 30/30\n",
            "56590/56590 [==============================] - 10s 172us/step - loss: 0.0303 - acc: 0.9909\n",
            "Precision = 91.58, Recall = 90.4, F1 = 90.98\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckXOJVdyPCeG",
        "colab_type": "code",
        "outputId": "f52511ac-1b35-4244-b595-08cce5ee970c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# past context of 5, kernel of 5\n",
        "context_size = 5\n",
        "kernel_size = 5\n",
        "cnn_input, cnn_labels = get_past_window(train_x, train_label, context_size)\n",
        "val_input, val_labels = get_past_window(val_x, val_label, context_size)\n",
        "model = get_conv_model(context_size, kernel_size)\n",
        "model.fit(cnn_input, cnn_labels, epochs=30)\n",
        "print_evaluation(model, val_input, val_labels, val_x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 5, 100)            57300     \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (None, 5, 100)            50100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_4 (MaxPooling1 (None, 2, 100)            0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 2, 100)            0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 128)               25728     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 127)               16383     \n",
            "=================================================================\n",
            "Total params: 149,511\n",
            "Trainable params: 149,511\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "56590/56590 [==============================] - 10s 180us/step - loss: 0.5226 - acc: 0.8920\n",
            "Epoch 2/30\n",
            "56590/56590 [==============================] - 10s 172us/step - loss: 0.1265 - acc: 0.9702\n",
            "Epoch 3/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.0833 - acc: 0.9782\n",
            "Epoch 4/30\n",
            "56590/56590 [==============================] - 10s 168us/step - loss: 0.0666 - acc: 0.9819\n",
            "Epoch 5/30\n",
            "56590/56590 [==============================] - 10s 169us/step - loss: 0.0546 - acc: 0.9847\n",
            "Epoch 6/30\n",
            "56590/56590 [==============================] - 10s 170us/step - loss: 0.0478 - acc: 0.9857\n",
            "Epoch 7/30\n",
            "56590/56590 [==============================] - 10s 170us/step - loss: 0.0408 - acc: 0.9876\n",
            "Epoch 8/30\n",
            "56590/56590 [==============================] - 10s 170us/step - loss: 0.0389 - acc: 0.9880\n",
            "Epoch 9/30\n",
            "56590/56590 [==============================] - 10s 169us/step - loss: 0.0346 - acc: 0.9897\n",
            "Epoch 10/30\n",
            "56590/56590 [==============================] - 10s 169us/step - loss: 0.0343 - acc: 0.9896\n",
            "Epoch 11/30\n",
            "56590/56590 [==============================] - 10s 171us/step - loss: 0.0325 - acc: 0.9903\n",
            "Epoch 12/30\n",
            "56590/56590 [==============================] - 10s 171us/step - loss: 0.0310 - acc: 0.9904\n",
            "Epoch 13/30\n",
            "56590/56590 [==============================] - 10s 171us/step - loss: 0.0292 - acc: 0.9913\n",
            "Epoch 14/30\n",
            "56590/56590 [==============================] - 10s 169us/step - loss: 0.0292 - acc: 0.9911\n",
            "Epoch 15/30\n",
            "56590/56590 [==============================] - 10s 169us/step - loss: 0.0275 - acc: 0.9920\n",
            "Epoch 16/30\n",
            "56590/56590 [==============================] - 10s 170us/step - loss: 0.0261 - acc: 0.9921\n",
            "Epoch 17/30\n",
            "56590/56590 [==============================] - 10s 170us/step - loss: 0.0285 - acc: 0.9918\n",
            "Epoch 18/30\n",
            "56590/56590 [==============================] - 10s 169us/step - loss: 0.0257 - acc: 0.9926\n",
            "Epoch 19/30\n",
            "56590/56590 [==============================] - 9s 167us/step - loss: 0.0280 - acc: 0.9920\n",
            "Epoch 20/30\n",
            "56590/56590 [==============================] - 9s 168us/step - loss: 0.0244 - acc: 0.9926\n",
            "Epoch 21/30\n",
            "56590/56590 [==============================] - 10s 168us/step - loss: 0.0251 - acc: 0.9926\n",
            "Epoch 22/30\n",
            "56590/56590 [==============================] - 9s 167us/step - loss: 0.0243 - acc: 0.9931\n",
            "Epoch 23/30\n",
            "56590/56590 [==============================] - 10s 170us/step - loss: 0.0229 - acc: 0.9936\n",
            "Epoch 24/30\n",
            "56590/56590 [==============================] - 10s 175us/step - loss: 0.0250 - acc: 0.9929\n",
            "Epoch 25/30\n",
            "56590/56590 [==============================] - 10s 171us/step - loss: 0.0221 - acc: 0.9938\n",
            "Epoch 26/30\n",
            "56590/56590 [==============================] - 10s 169us/step - loss: 0.0257 - acc: 0.9923\n",
            "Epoch 27/30\n",
            "56590/56590 [==============================] - 10s 169us/step - loss: 0.0232 - acc: 0.9936\n",
            "Epoch 28/30\n",
            "56590/56590 [==============================] - 10s 170us/step - loss: 0.0225 - acc: 0.9936\n",
            "Epoch 29/30\n",
            "56590/56590 [==============================] - 10s 168us/step - loss: 0.0229 - acc: 0.9937\n",
            "Epoch 30/30\n",
            "56590/56590 [==============================] - 10s 169us/step - loss: 0.0218 - acc: 0.9938\n",
            "Precision = 92.49, Recall = 90.83, F1 = 91.65\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jX-lHp6DQMV5"
      },
      "source": [
        "**Experiment with a window size of 7 using the past context words**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWABXAEbPCa5",
        "colab_type": "code",
        "outputId": "da28b502-9a14-4153-9d9a-1b7cda25cee8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# past context of 7, kernel of 3\n",
        "context_size = 7\n",
        "kernel_size = 3\n",
        "cnn_input, cnn_labels = get_past_window(train_x, train_label, context_size)\n",
        "val_input, val_labels = get_past_window(val_x, val_label, context_size)\n",
        "model = get_conv_model(context_size, kernel_size)\n",
        "model.fit(cnn_input, cnn_labels, epochs=30)\n",
        "print_evaluation(model, val_input, val_labels, val_x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (None, 7, 100)            57300     \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, 7, 100)            30100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_5 (MaxPooling1 (None, 3, 100)            0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 3, 100)            0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 128)               38528     \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 127)               16383     \n",
            "=================================================================\n",
            "Total params: 142,311\n",
            "Trainable params: 142,311\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "56590/56590 [==============================] - 10s 179us/step - loss: 0.6398 - acc: 0.8657\n",
            "Epoch 2/30\n",
            "56590/56590 [==============================] - 9s 167us/step - loss: 0.1919 - acc: 0.9553\n",
            "Epoch 3/30\n",
            "56590/56590 [==============================] - 10s 171us/step - loss: 0.1222 - acc: 0.9697\n",
            "Epoch 4/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.0916 - acc: 0.9756\n",
            "Epoch 5/30\n",
            "56590/56590 [==============================] - 10s 172us/step - loss: 0.0785 - acc: 0.9783\n",
            "Epoch 6/30\n",
            "56590/56590 [==============================] - 10s 170us/step - loss: 0.0632 - acc: 0.9820\n",
            "Epoch 7/30\n",
            "56590/56590 [==============================] - 10s 170us/step - loss: 0.0584 - acc: 0.9834\n",
            "Epoch 8/30\n",
            "56590/56590 [==============================] - 10s 170us/step - loss: 0.0485 - acc: 0.9859\n",
            "Epoch 9/30\n",
            "56590/56590 [==============================] - 10s 170us/step - loss: 0.0456 - acc: 0.9863\n",
            "Epoch 10/30\n",
            "56590/56590 [==============================] - 10s 168us/step - loss: 0.0438 - acc: 0.9875\n",
            "Epoch 11/30\n",
            "56590/56590 [==============================] - 10s 168us/step - loss: 0.0424 - acc: 0.9875\n",
            "Epoch 12/30\n",
            "56590/56590 [==============================] - 10s 169us/step - loss: 0.0385 - acc: 0.9885\n",
            "Epoch 13/30\n",
            "56590/56590 [==============================] - 10s 170us/step - loss: 0.0359 - acc: 0.9888\n",
            "Epoch 14/30\n",
            "56590/56590 [==============================] - 10s 168us/step - loss: 0.0344 - acc: 0.9896\n",
            "Epoch 15/30\n",
            "56590/56590 [==============================] - 10s 169us/step - loss: 0.0350 - acc: 0.9892\n",
            "Epoch 16/30\n",
            "56590/56590 [==============================] - 9s 167us/step - loss: 0.0344 - acc: 0.9900\n",
            "Epoch 17/30\n",
            "56590/56590 [==============================] - 9s 167us/step - loss: 0.0319 - acc: 0.9905\n",
            "Epoch 18/30\n",
            "56590/56590 [==============================] - 9s 168us/step - loss: 0.0312 - acc: 0.9904\n",
            "Epoch 19/30\n",
            "56590/56590 [==============================] - 10s 168us/step - loss: 0.0301 - acc: 0.9915\n",
            "Epoch 20/30\n",
            "56590/56590 [==============================] - 10s 168us/step - loss: 0.0311 - acc: 0.9911\n",
            "Epoch 21/30\n",
            "56590/56590 [==============================] - 9s 166us/step - loss: 0.0284 - acc: 0.9917\n",
            "Epoch 22/30\n",
            "56590/56590 [==============================] - 10s 168us/step - loss: 0.0300 - acc: 0.9913\n",
            "Epoch 23/30\n",
            "56590/56590 [==============================] - 9s 168us/step - loss: 0.0278 - acc: 0.9920\n",
            "Epoch 24/30\n",
            "56590/56590 [==============================] - 10s 170us/step - loss: 0.0286 - acc: 0.9916\n",
            "Epoch 25/30\n",
            "56590/56590 [==============================] - 10s 168us/step - loss: 0.0290 - acc: 0.9916\n",
            "Epoch 26/30\n",
            "56590/56590 [==============================] - 10s 172us/step - loss: 0.0255 - acc: 0.9926\n",
            "Epoch 27/30\n",
            "56590/56590 [==============================] - 10s 173us/step - loss: 0.0302 - acc: 0.9915\n",
            "Epoch 28/30\n",
            "56590/56590 [==============================] - 10s 169us/step - loss: 0.0269 - acc: 0.9921\n",
            "Epoch 29/30\n",
            "56590/56590 [==============================] - 9s 168us/step - loss: 0.0266 - acc: 0.9924\n",
            "Epoch 30/30\n",
            "56590/56590 [==============================] - 10s 168us/step - loss: 0.0280 - acc: 0.9921\n",
            "Precision = 92.25, Recall = 91.03, F1 = 91.63\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wFCjL5kPCWj",
        "colab_type": "code",
        "outputId": "027c5eef-f092-4226-bb09-4a1275078fb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# past context of 7, kernel of 5\n",
        "context_size = 7\n",
        "kernel_size = 5\n",
        "cnn_input, cnn_labels = get_past_window(train_x, train_label, context_size)\n",
        "val_input, val_labels = get_past_window(val_x, val_label, context_size)\n",
        "model = get_conv_model(context_size, kernel_size)\n",
        "model.fit(cnn_input, cnn_labels, epochs=30)\n",
        "print_evaluation(model, val_input, val_labels, val_x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_6 (Embedding)      (None, 7, 100)            57300     \n",
            "_________________________________________________________________\n",
            "conv1d_6 (Conv1D)            (None, 7, 100)            50100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_6 (MaxPooling1 (None, 3, 100)            0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 3, 100)            0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 128)               38528     \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 127)               16383     \n",
            "=================================================================\n",
            "Total params: 162,311\n",
            "Trainable params: 162,311\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.5341 - acc: 0.8888\n",
            "Epoch 2/30\n",
            "56590/56590 [==============================] - 10s 173us/step - loss: 0.1332 - acc: 0.9695\n",
            "Epoch 3/30\n",
            "56590/56590 [==============================] - 10s 171us/step - loss: 0.0833 - acc: 0.9793\n",
            "Epoch 4/30\n",
            "56590/56590 [==============================] - 10s 172us/step - loss: 0.0633 - acc: 0.9836\n",
            "Epoch 5/30\n",
            "56590/56590 [==============================] - 10s 170us/step - loss: 0.0524 - acc: 0.9860\n",
            "Epoch 6/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.0435 - acc: 0.9883\n",
            "Epoch 7/30\n",
            "56590/56590 [==============================] - 10s 172us/step - loss: 0.0379 - acc: 0.9897\n",
            "Epoch 8/30\n",
            "56590/56590 [==============================] - 10s 172us/step - loss: 0.0362 - acc: 0.9902\n",
            "Epoch 9/30\n",
            "56590/56590 [==============================] - 10s 172us/step - loss: 0.0318 - acc: 0.9906\n",
            "Epoch 10/30\n",
            "56590/56590 [==============================] - 10s 173us/step - loss: 0.0294 - acc: 0.9918\n",
            "Epoch 11/30\n",
            "56590/56590 [==============================] - 10s 171us/step - loss: 0.0285 - acc: 0.9923\n",
            "Epoch 12/30\n",
            "56590/56590 [==============================] - 10s 171us/step - loss: 0.0281 - acc: 0.9921\n",
            "Epoch 13/30\n",
            "56590/56590 [==============================] - 10s 172us/step - loss: 0.0276 - acc: 0.9919\n",
            "Epoch 14/30\n",
            "56590/56590 [==============================] - 10s 172us/step - loss: 0.0250 - acc: 0.9929\n",
            "Epoch 15/30\n",
            "56590/56590 [==============================] - 10s 171us/step - loss: 0.0255 - acc: 0.9930\n",
            "Epoch 16/30\n",
            "56590/56590 [==============================] - 10s 172us/step - loss: 0.0239 - acc: 0.9932\n",
            "Epoch 17/30\n",
            "56590/56590 [==============================] - 10s 171us/step - loss: 0.0222 - acc: 0.9940\n",
            "Epoch 18/30\n",
            "56590/56590 [==============================] - 10s 171us/step - loss: 0.0229 - acc: 0.9939\n",
            "Epoch 19/30\n",
            "56590/56590 [==============================] - 10s 172us/step - loss: 0.0225 - acc: 0.9942\n",
            "Epoch 20/30\n",
            "56590/56590 [==============================] - 10s 171us/step - loss: 0.0233 - acc: 0.9937\n",
            "Epoch 21/30\n",
            "56590/56590 [==============================] - 10s 170us/step - loss: 0.0222 - acc: 0.9941\n",
            "Epoch 22/30\n",
            "56590/56590 [==============================] - 10s 173us/step - loss: 0.0233 - acc: 0.9935\n",
            "Epoch 23/30\n",
            "56590/56590 [==============================] - 10s 171us/step - loss: 0.0200 - acc: 0.9945\n",
            "Epoch 24/30\n",
            "56590/56590 [==============================] - 10s 170us/step - loss: 0.0213 - acc: 0.9945\n",
            "Epoch 25/30\n",
            "56590/56590 [==============================] - 10s 171us/step - loss: 0.0223 - acc: 0.9939\n",
            "Epoch 26/30\n",
            "56590/56590 [==============================] - 10s 171us/step - loss: 0.0210 - acc: 0.9946\n",
            "Epoch 27/30\n",
            "56590/56590 [==============================] - 10s 172us/step - loss: 0.0195 - acc: 0.9949\n",
            "Epoch 28/30\n",
            "56590/56590 [==============================] - 10s 177us/step - loss: 0.0194 - acc: 0.9950\n",
            "Epoch 29/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.0205 - acc: 0.9948\n",
            "Epoch 30/30\n",
            "56590/56590 [==============================] - 10s 171us/step - loss: 0.0227 - acc: 0.9941\n",
            "Precision = 92.67, Recall = 91.67, F1 = 92.16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7akS8nYMgm1",
        "colab_type": "code",
        "outputId": "de27a8a7-c15b-42ce-93f7-04152065a4ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# past context of 7, kernel of 7\n",
        "context_size = 7\n",
        "kernel_size = 7\n",
        "cnn_input, cnn_labels = get_past_window(train_x, train_label, context_size)\n",
        "val_input, val_labels = get_past_window(val_x, val_label, context_size)\n",
        "model = get_conv_model(context_size, kernel_size)\n",
        "model.fit(cnn_input, cnn_labels, epochs=30)\n",
        "print_evaluation(model, val_input, val_labels, val_x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_7 (Embedding)      (None, 7, 100)            57300     \n",
            "_________________________________________________________________\n",
            "conv1d_7 (Conv1D)            (None, 7, 100)            70100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_7 (MaxPooling1 (None, 3, 100)            0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 3, 100)            0         \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 128)               38528     \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 127)               16383     \n",
            "=================================================================\n",
            "Total params: 182,311\n",
            "Trainable params: 182,311\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.5094 - acc: 0.8937\n",
            "Epoch 2/30\n",
            "56590/56590 [==============================] - 10s 172us/step - loss: 0.1224 - acc: 0.9716\n",
            "Epoch 3/30\n",
            "56590/56590 [==============================] - 10s 172us/step - loss: 0.0775 - acc: 0.9808\n",
            "Epoch 4/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.0584 - acc: 0.9843\n",
            "Epoch 5/30\n",
            "56590/56590 [==============================] - 10s 175us/step - loss: 0.0457 - acc: 0.9874\n",
            "Epoch 6/30\n",
            "56590/56590 [==============================] - 10s 173us/step - loss: 0.0395 - acc: 0.9886\n",
            "Epoch 7/30\n",
            "56590/56590 [==============================] - 10s 178us/step - loss: 0.0355 - acc: 0.9901\n",
            "Epoch 8/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.0314 - acc: 0.9910\n",
            "Epoch 9/30\n",
            "56590/56590 [==============================] - 10s 172us/step - loss: 0.0286 - acc: 0.9916\n",
            "Epoch 10/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.0272 - acc: 0.9926\n",
            "Epoch 11/30\n",
            "56590/56590 [==============================] - 10s 173us/step - loss: 0.0251 - acc: 0.9934\n",
            "Epoch 12/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.0252 - acc: 0.9928\n",
            "Epoch 13/30\n",
            "56590/56590 [==============================] - 10s 172us/step - loss: 0.0236 - acc: 0.9935\n",
            "Epoch 14/30\n",
            "56590/56590 [==============================] - 10s 173us/step - loss: 0.0236 - acc: 0.9937\n",
            "Epoch 15/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.0241 - acc: 0.9932\n",
            "Epoch 16/30\n",
            "56590/56590 [==============================] - 10s 173us/step - loss: 0.0211 - acc: 0.9945\n",
            "Epoch 17/30\n",
            "56590/56590 [==============================] - 10s 171us/step - loss: 0.0231 - acc: 0.9933\n",
            "Epoch 18/30\n",
            "56590/56590 [==============================] - 10s 171us/step - loss: 0.0201 - acc: 0.9947\n",
            "Epoch 19/30\n",
            "56590/56590 [==============================] - 10s 175us/step - loss: 0.0207 - acc: 0.9946\n",
            "Epoch 20/30\n",
            "56590/56590 [==============================] - 10s 175us/step - loss: 0.0189 - acc: 0.9948\n",
            "Epoch 21/30\n",
            "56590/56590 [==============================] - 10s 175us/step - loss: 0.0192 - acc: 0.9947\n",
            "Epoch 22/30\n",
            "56590/56590 [==============================] - 10s 175us/step - loss: 0.0225 - acc: 0.9943\n",
            "Epoch 23/30\n",
            "56590/56590 [==============================] - 10s 175us/step - loss: 0.0175 - acc: 0.9951\n",
            "Epoch 24/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.0202 - acc: 0.9946\n",
            "Epoch 25/30\n",
            "56590/56590 [==============================] - 10s 173us/step - loss: 0.0184 - acc: 0.9953\n",
            "Epoch 26/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.0215 - acc: 0.9947\n",
            "Epoch 27/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.0190 - acc: 0.9947\n",
            "Epoch 28/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.0205 - acc: 0.9947\n",
            "Epoch 29/30\n",
            "56590/56590 [==============================] - 10s 176us/step - loss: 0.0203 - acc: 0.9947\n",
            "Epoch 30/30\n",
            "56590/56590 [==============================] - 10s 177us/step - loss: 0.0172 - acc: 0.9952\n",
            "Precision = 92.56, Recall = 91.91, F1 = 92.24\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_pgd0C2-QQA6"
      },
      "source": [
        "**Experiment with a window size of 9 using the past context words**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pN3BWtqhMgj9",
        "colab_type": "code",
        "outputId": "0fcecef0-b880-4a11-eaa5-8df0265f4f5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# past context of 9, kernel of 3\n",
        "context_size = 9\n",
        "kernel_size = 3\n",
        "cnn_input, cnn_labels = get_past_window(train_x, train_label, context_size)\n",
        "val_input, val_labels = get_past_window(val_x, val_label, context_size)\n",
        "model = get_conv_model(context_size, kernel_size)\n",
        "model.fit(cnn_input, cnn_labels, epochs=30)\n",
        "print_evaluation(model, val_input, val_labels, val_x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_8 (Embedding)      (None, 9, 100)            57300     \n",
            "_________________________________________________________________\n",
            "conv1d_8 (Conv1D)            (None, 9, 100)            30100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_8 (MaxPooling1 (None, 4, 100)            0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 4, 100)            0         \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 400)               0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 128)               51328     \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 127)               16383     \n",
            "=================================================================\n",
            "Total params: 155,111\n",
            "Trainable params: 155,111\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.6517 - acc: 0.8625\n",
            "Epoch 2/30\n",
            "56590/56590 [==============================] - 10s 171us/step - loss: 0.1963 - acc: 0.9533\n",
            "Epoch 3/30\n",
            "56590/56590 [==============================] - 10s 172us/step - loss: 0.1218 - acc: 0.9691\n",
            "Epoch 4/30\n",
            "56590/56590 [==============================] - 10s 173us/step - loss: 0.0899 - acc: 0.9764\n",
            "Epoch 5/30\n",
            "56590/56590 [==============================] - 10s 173us/step - loss: 0.0746 - acc: 0.9798\n",
            "Epoch 6/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.0633 - acc: 0.9830\n",
            "Epoch 7/30\n",
            "56590/56590 [==============================] - 10s 172us/step - loss: 0.0546 - acc: 0.9848\n",
            "Epoch 8/30\n",
            "56590/56590 [==============================] - 10s 175us/step - loss: 0.0494 - acc: 0.9862\n",
            "Epoch 9/30\n",
            "56590/56590 [==============================] - 10s 172us/step - loss: 0.0423 - acc: 0.9874\n",
            "Epoch 10/30\n",
            "56590/56590 [==============================] - 10s 172us/step - loss: 0.0414 - acc: 0.9880\n",
            "Epoch 11/30\n",
            "56590/56590 [==============================] - 10s 171us/step - loss: 0.0370 - acc: 0.9890\n",
            "Epoch 12/30\n",
            "56590/56590 [==============================] - 10s 173us/step - loss: 0.0338 - acc: 0.9898\n",
            "Epoch 13/30\n",
            "56590/56590 [==============================] - 10s 173us/step - loss: 0.0351 - acc: 0.9894\n",
            "Epoch 14/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.0322 - acc: 0.9910\n",
            "Epoch 15/30\n",
            "56590/56590 [==============================] - 10s 172us/step - loss: 0.0335 - acc: 0.9902\n",
            "Epoch 16/30\n",
            "56590/56590 [==============================] - 10s 173us/step - loss: 0.0330 - acc: 0.9901\n",
            "Epoch 17/30\n",
            "56590/56590 [==============================] - 10s 172us/step - loss: 0.0305 - acc: 0.9912\n",
            "Epoch 18/30\n",
            "56590/56590 [==============================] - 10s 173us/step - loss: 0.0298 - acc: 0.9913\n",
            "Epoch 19/30\n",
            "56590/56590 [==============================] - 10s 173us/step - loss: 0.0285 - acc: 0.9918\n",
            "Epoch 20/30\n",
            "56590/56590 [==============================] - 10s 175us/step - loss: 0.0297 - acc: 0.9915\n",
            "Epoch 21/30\n",
            "56590/56590 [==============================] - 10s 173us/step - loss: 0.0288 - acc: 0.9921\n",
            "Epoch 22/30\n",
            "56590/56590 [==============================] - 10s 171us/step - loss: 0.0288 - acc: 0.9919\n",
            "Epoch 23/30\n",
            "56590/56590 [==============================] - 10s 173us/step - loss: 0.0267 - acc: 0.9925\n",
            "Epoch 24/30\n",
            "56590/56590 [==============================] - 10s 172us/step - loss: 0.0286 - acc: 0.9920\n",
            "Epoch 25/30\n",
            "56590/56590 [==============================] - 10s 172us/step - loss: 0.0276 - acc: 0.9922\n",
            "Epoch 26/30\n",
            "56590/56590 [==============================] - 10s 173us/step - loss: 0.0256 - acc: 0.9928\n",
            "Epoch 27/30\n",
            "56590/56590 [==============================] - 10s 173us/step - loss: 0.0280 - acc: 0.9922\n",
            "Epoch 28/30\n",
            "56590/56590 [==============================] - 10s 172us/step - loss: 0.0277 - acc: 0.9927\n",
            "Epoch 29/30\n",
            "56590/56590 [==============================] - 10s 172us/step - loss: 0.0284 - acc: 0.9928\n",
            "Epoch 30/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.0279 - acc: 0.9925\n",
            "Precision = 92.53, Recall = 91.94, F1 = 92.23\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "by0DUXG8Pzwz",
        "colab_type": "code",
        "outputId": "ba232027-051e-4c8c-87bf-551d9a099ee0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# past context of 9, kernel of 5\n",
        "context_size = 9\n",
        "kernel_size = 5\n",
        "cnn_input, cnn_labels = get_past_window(train_x, train_label, context_size)\n",
        "val_input, val_labels = get_past_window(val_x, val_label, context_size)\n",
        "model = get_conv_model(context_size, kernel_size)\n",
        "model.fit(cnn_input, cnn_labels, epochs=30)\n",
        "print_evaluation(model, val_input, val_labels, val_x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_9 (Embedding)      (None, 9, 100)            57300     \n",
            "_________________________________________________________________\n",
            "conv1d_9 (Conv1D)            (None, 9, 100)            50100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_9 (MaxPooling1 (None, 4, 100)            0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 4, 100)            0         \n",
            "_________________________________________________________________\n",
            "flatten_9 (Flatten)          (None, 400)               0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 128)               51328     \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 127)               16383     \n",
            "=================================================================\n",
            "Total params: 175,111\n",
            "Trainable params: 175,111\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "56590/56590 [==============================] - 11s 198us/step - loss: 0.5470 - acc: 0.8842\n",
            "Epoch 2/30\n",
            "56590/56590 [==============================] - 10s 176us/step - loss: 0.1327 - acc: 0.9693\n",
            "Epoch 3/30\n",
            "56590/56590 [==============================] - 10s 175us/step - loss: 0.0795 - acc: 0.9804\n",
            "Epoch 4/30\n",
            "56590/56590 [==============================] - 10s 176us/step - loss: 0.0575 - acc: 0.9845\n",
            "Epoch 5/30\n",
            "56590/56590 [==============================] - 10s 176us/step - loss: 0.0461 - acc: 0.9872\n",
            "Epoch 6/30\n",
            "56590/56590 [==============================] - 10s 175us/step - loss: 0.0397 - acc: 0.9886\n",
            "Epoch 7/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.0351 - acc: 0.9900\n",
            "Epoch 8/30\n",
            "56590/56590 [==============================] - 10s 176us/step - loss: 0.0309 - acc: 0.9905\n",
            "Epoch 9/30\n",
            "56590/56590 [==============================] - 10s 180us/step - loss: 0.0269 - acc: 0.9917\n",
            "Epoch 10/30\n",
            "56590/56590 [==============================] - 10s 176us/step - loss: 0.0256 - acc: 0.9918\n",
            "Epoch 11/30\n",
            "56590/56590 [==============================] - 10s 176us/step - loss: 0.0253 - acc: 0.9925\n",
            "Epoch 12/30\n",
            "56590/56590 [==============================] - 10s 176us/step - loss: 0.0234 - acc: 0.9932\n",
            "Epoch 13/30\n",
            "56590/56590 [==============================] - 10s 177us/step - loss: 0.0243 - acc: 0.9927\n",
            "Epoch 14/30\n",
            "56590/56590 [==============================] - 10s 176us/step - loss: 0.0189 - acc: 0.9938\n",
            "Epoch 15/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.0225 - acc: 0.9934\n",
            "Epoch 16/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.0199 - acc: 0.9940\n",
            "Epoch 17/30\n",
            "56590/56590 [==============================] - 10s 173us/step - loss: 0.0211 - acc: 0.9938\n",
            "Epoch 18/30\n",
            "56590/56590 [==============================] - 10s 173us/step - loss: 0.0228 - acc: 0.9935\n",
            "Epoch 19/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.0193 - acc: 0.9943\n",
            "Epoch 20/30\n",
            "56590/56590 [==============================] - 10s 171us/step - loss: 0.0162 - acc: 0.9954\n",
            "Epoch 21/30\n",
            "56590/56590 [==============================] - 10s 172us/step - loss: 0.0214 - acc: 0.9935\n",
            "Epoch 22/30\n",
            "56590/56590 [==============================] - 10s 171us/step - loss: 0.0190 - acc: 0.9948\n",
            "Epoch 23/30\n",
            "56590/56590 [==============================] - 10s 171us/step - loss: 0.0174 - acc: 0.9951\n",
            "Epoch 24/30\n",
            "56590/56590 [==============================] - 10s 171us/step - loss: 0.0188 - acc: 0.9948\n",
            "Epoch 25/30\n",
            "56590/56590 [==============================] - 10s 171us/step - loss: 0.0174 - acc: 0.9949\n",
            "Epoch 26/30\n",
            "56590/56590 [==============================] - 10s 171us/step - loss: 0.0187 - acc: 0.9952\n",
            "Epoch 27/30\n",
            "56590/56590 [==============================] - 10s 170us/step - loss: 0.0185 - acc: 0.9952\n",
            "Epoch 28/30\n",
            "56590/56590 [==============================] - 10s 171us/step - loss: 0.0197 - acc: 0.9944\n",
            "Epoch 29/30\n",
            "56590/56590 [==============================] - 10s 171us/step - loss: 0.0180 - acc: 0.9952\n",
            "Epoch 30/30\n",
            "56590/56590 [==============================] - 10s 169us/step - loss: 0.0172 - acc: 0.9951\n",
            "Precision = 93.69, Recall = 92.84, F1 = 93.26\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttFzTcn5Pz8z",
        "colab_type": "code",
        "outputId": "6080a06b-27e6-4653-bd0a-cb781c18f3c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# past context of 9, kernel of 7\n",
        "context_size = 9\n",
        "kernel_size = 7\n",
        "cnn_input, cnn_labels = get_past_window(train_x, train_label, context_size)\n",
        "val_input, val_labels = get_past_window(val_x, val_label, context_size)\n",
        "model = get_conv_model(context_size, kernel_size)\n",
        "model.fit(cnn_input, cnn_labels, epochs=30)\n",
        "print_evaluation(model, val_input, val_labels, val_x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_10 (Embedding)     (None, 9, 100)            57300     \n",
            "_________________________________________________________________\n",
            "conv1d_10 (Conv1D)           (None, 9, 100)            70100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_10 (MaxPooling (None, 4, 100)            0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 4, 100)            0         \n",
            "_________________________________________________________________\n",
            "flatten_10 (Flatten)         (None, 400)               0         \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 128)               51328     \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 127)               16383     \n",
            "=================================================================\n",
            "Total params: 195,111\n",
            "Trainable params: 195,111\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.5205 - acc: 0.8919\n",
            "Epoch 2/30\n",
            "56590/56590 [==============================] - 10s 179us/step - loss: 0.1232 - acc: 0.9711\n",
            "Epoch 3/30\n",
            "56590/56590 [==============================] - 10s 172us/step - loss: 0.0759 - acc: 0.9809\n",
            "Epoch 4/30\n",
            "56590/56590 [==============================] - 10s 170us/step - loss: 0.0566 - acc: 0.9856\n",
            "Epoch 5/30\n",
            "56590/56590 [==============================] - 10s 170us/step - loss: 0.0453 - acc: 0.9879\n",
            "Epoch 6/30\n",
            "56590/56590 [==============================] - 10s 172us/step - loss: 0.0400 - acc: 0.9893\n",
            "Epoch 7/30\n",
            "56590/56590 [==============================] - 10s 170us/step - loss: 0.0366 - acc: 0.9900\n",
            "Epoch 8/30\n",
            "56590/56590 [==============================] - 10s 171us/step - loss: 0.0322 - acc: 0.9912\n",
            "Epoch 9/30\n",
            "56590/56590 [==============================] - 10s 171us/step - loss: 0.0281 - acc: 0.9925\n",
            "Epoch 10/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.0292 - acc: 0.9922\n",
            "Epoch 11/30\n",
            "56590/56590 [==============================] - 10s 172us/step - loss: 0.0272 - acc: 0.9929\n",
            "Epoch 12/30\n",
            "56590/56590 [==============================] - 10s 171us/step - loss: 0.0243 - acc: 0.9935\n",
            "Epoch 13/30\n",
            "56590/56590 [==============================] - 10s 171us/step - loss: 0.0240 - acc: 0.9938\n",
            "Epoch 14/30\n",
            "56590/56590 [==============================] - 10s 170us/step - loss: 0.0229 - acc: 0.9941\n",
            "Epoch 15/30\n",
            "56590/56590 [==============================] - 10s 172us/step - loss: 0.0246 - acc: 0.9940\n",
            "Epoch 16/30\n",
            "56590/56590 [==============================] - 10s 171us/step - loss: 0.0242 - acc: 0.9936\n",
            "Epoch 17/30\n",
            "56590/56590 [==============================] - 10s 172us/step - loss: 0.0209 - acc: 0.9947\n",
            "Epoch 18/30\n",
            "56590/56590 [==============================] - 10s 170us/step - loss: 0.0206 - acc: 0.9948\n",
            "Epoch 19/30\n",
            "56590/56590 [==============================] - 10s 171us/step - loss: 0.0219 - acc: 0.9946\n",
            "Epoch 20/30\n",
            "56590/56590 [==============================] - 10s 172us/step - loss: 0.0232 - acc: 0.9943\n",
            "Epoch 21/30\n",
            "56590/56590 [==============================] - 10s 171us/step - loss: 0.0238 - acc: 0.9940\n",
            "Epoch 22/30\n",
            "56590/56590 [==============================] - 10s 171us/step - loss: 0.0209 - acc: 0.9954\n",
            "Epoch 23/30\n",
            "56590/56590 [==============================] - 10s 170us/step - loss: 0.0225 - acc: 0.9950\n",
            "Epoch 24/30\n",
            "56590/56590 [==============================] - 10s 171us/step - loss: 0.0216 - acc: 0.9949\n",
            "Epoch 25/30\n",
            "56590/56590 [==============================] - 10s 170us/step - loss: 0.0219 - acc: 0.9949\n",
            "Epoch 26/30\n",
            "56590/56590 [==============================] - 10s 169us/step - loss: 0.0216 - acc: 0.9951\n",
            "Epoch 27/30\n",
            "56590/56590 [==============================] - 10s 171us/step - loss: 0.0236 - acc: 0.9946\n",
            "Epoch 28/30\n",
            "56590/56590 [==============================] - 10s 170us/step - loss: 0.0209 - acc: 0.9952\n",
            "Epoch 29/30\n",
            "56590/56590 [==============================] - 10s 168us/step - loss: 0.0187 - acc: 0.9959\n",
            "Epoch 30/30\n",
            "56590/56590 [==============================] - 10s 170us/step - loss: 0.0239 - acc: 0.9946\n",
            "Precision = 92.7, Recall = 92.38, F1 = 92.54\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XR0Mk0UyP0KJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DO9n_8iqQ3az"
      },
      "source": [
        "**Experiment with a window size of 3 using the future context words**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AH-XbiN7P0Xl",
        "colab_type": "code",
        "outputId": "9b09b3db-8790-4469-cb31-72ec2f9052d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# future context of 3, kernel of 3\n",
        "context_size = 3\n",
        "kernel_size = 3\n",
        "cnn_input, cnn_labels = get_future_window(train_x, train_label, context_size)\n",
        "val_input, val_labels = get_future_window(val_x, val_label, context_size)\n",
        "model = get_conv_model(context_size, kernel_size)\n",
        "model.fit(cnn_input, cnn_labels, epochs=30)\n",
        "print_evaluation(model, val_input, val_labels, val_x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_16 (Embedding)     (None, 3, 100)            57300     \n",
            "_________________________________________________________________\n",
            "conv1d_16 (Conv1D)           (None, 3, 100)            30100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_16 (MaxPooling (None, 1, 100)            0         \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 1, 100)            0         \n",
            "_________________________________________________________________\n",
            "flatten_16 (Flatten)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_31 (Dense)             (None, 128)               12928     \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             (None, 127)               16383     \n",
            "=================================================================\n",
            "Total params: 116,711\n",
            "Trainable params: 116,711\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "56590/56590 [==============================] - 11s 197us/step - loss: 0.5942 - acc: 0.8717\n",
            "Epoch 2/30\n",
            "56590/56590 [==============================] - 10s 178us/step - loss: 0.2302 - acc: 0.9374\n",
            "Epoch 3/30\n",
            "56590/56590 [==============================] - 10s 177us/step - loss: 0.1924 - acc: 0.9436\n",
            "Epoch 4/30\n",
            "56590/56590 [==============================] - 10s 176us/step - loss: 0.1781 - acc: 0.9456\n",
            "Epoch 5/30\n",
            "56590/56590 [==============================] - 10s 176us/step - loss: 0.1662 - acc: 0.9481\n",
            "Epoch 6/30\n",
            "56590/56590 [==============================] - 10s 177us/step - loss: 0.1591 - acc: 0.9495\n",
            "Epoch 7/30\n",
            "56590/56590 [==============================] - 10s 177us/step - loss: 0.1539 - acc: 0.9503\n",
            "Epoch 8/30\n",
            "56590/56590 [==============================] - 10s 176us/step - loss: 0.1502 - acc: 0.9517\n",
            "Epoch 9/30\n",
            "56590/56590 [==============================] - 10s 177us/step - loss: 0.1477 - acc: 0.9515\n",
            "Epoch 10/30\n",
            "56590/56590 [==============================] - 10s 179us/step - loss: 0.1438 - acc: 0.9523\n",
            "Epoch 11/30\n",
            "56590/56590 [==============================] - 10s 179us/step - loss: 0.1414 - acc: 0.9532\n",
            "Epoch 12/30\n",
            "56590/56590 [==============================] - 10s 176us/step - loss: 0.1405 - acc: 0.9534\n",
            "Epoch 13/30\n",
            "56590/56590 [==============================] - 10s 176us/step - loss: 0.1379 - acc: 0.9547\n",
            "Epoch 14/30\n",
            "56590/56590 [==============================] - 10s 176us/step - loss: 0.1376 - acc: 0.9544\n",
            "Epoch 15/30\n",
            "56590/56590 [==============================] - 10s 180us/step - loss: 0.1339 - acc: 0.9544\n",
            "Epoch 16/30\n",
            "56590/56590 [==============================] - 10s 176us/step - loss: 0.1333 - acc: 0.9549\n",
            "Epoch 17/30\n",
            "56590/56590 [==============================] - 10s 176us/step - loss: 0.1316 - acc: 0.9559\n",
            "Epoch 18/30\n",
            "56590/56590 [==============================] - 10s 175us/step - loss: 0.1318 - acc: 0.9557\n",
            "Epoch 19/30\n",
            "56590/56590 [==============================] - 10s 177us/step - loss: 0.1308 - acc: 0.9560\n",
            "Epoch 20/30\n",
            "56590/56590 [==============================] - 10s 175us/step - loss: 0.1285 - acc: 0.9565\n",
            "Epoch 21/30\n",
            "56590/56590 [==============================] - 10s 175us/step - loss: 0.1281 - acc: 0.9561\n",
            "Epoch 22/30\n",
            "56590/56590 [==============================] - 10s 173us/step - loss: 0.1300 - acc: 0.9566\n",
            "Epoch 23/30\n",
            "56590/56590 [==============================] - 10s 175us/step - loss: 0.1266 - acc: 0.9573\n",
            "Epoch 24/30\n",
            "56590/56590 [==============================] - 10s 175us/step - loss: 0.1279 - acc: 0.9563\n",
            "Epoch 25/30\n",
            "56590/56590 [==============================] - 10s 175us/step - loss: 0.1257 - acc: 0.9574\n",
            "Epoch 26/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.1260 - acc: 0.9570\n",
            "Epoch 27/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.1250 - acc: 0.9578\n",
            "Epoch 28/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.1239 - acc: 0.9580\n",
            "Epoch 29/30\n",
            "56590/56590 [==============================] - 10s 175us/step - loss: 0.1256 - acc: 0.9572\n",
            "Epoch 30/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.1249 - acc: 0.9575\n",
            "Precision = 83.4, Recall = 79.8, F1 = 81.56\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pUCG-NDidRI4"
      },
      "source": [
        "**Experiment with a window size of 5 using the future context words**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZbfJQSxcv56",
        "colab_type": "code",
        "outputId": "727e37a7-b319-4043-ff3c-1a8055445ef8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# future context of 5, kernel of 3\n",
        "context_size = 5\n",
        "kernel_size = 3\n",
        "cnn_input, cnn_labels = get_future_window(train_x, train_label, context_size)\n",
        "val_input, val_labels = get_future_window(val_x, val_label, context_size)\n",
        "model = get_conv_model(context_size, kernel_size)\n",
        "model.fit(cnn_input, cnn_labels, epochs=30)\n",
        "print_evaluation(model, val_input, val_labels, val_x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_17 (Embedding)     (None, 5, 100)            57300     \n",
            "_________________________________________________________________\n",
            "conv1d_17 (Conv1D)           (None, 5, 100)            30100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_17 (MaxPooling (None, 2, 100)            0         \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 2, 100)            0         \n",
            "_________________________________________________________________\n",
            "flatten_17 (Flatten)         (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_33 (Dense)             (None, 128)               25728     \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 127)               16383     \n",
            "=================================================================\n",
            "Total params: 129,511\n",
            "Trainable params: 129,511\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "56590/56590 [==============================] - 11s 198us/step - loss: 0.6043 - acc: 0.8691\n",
            "Epoch 2/30\n",
            "56590/56590 [==============================] - 10s 177us/step - loss: 0.2261 - acc: 0.9374\n",
            "Epoch 3/30\n",
            "56590/56590 [==============================] - 10s 176us/step - loss: 0.1830 - acc: 0.9462\n",
            "Epoch 4/30\n",
            "56590/56590 [==============================] - 10s 176us/step - loss: 0.1638 - acc: 0.9497\n",
            "Epoch 5/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.1516 - acc: 0.9519\n",
            "Epoch 6/30\n",
            "56590/56590 [==============================] - 10s 175us/step - loss: 0.1440 - acc: 0.9532\n",
            "Epoch 7/30\n",
            "56590/56590 [==============================] - 10s 176us/step - loss: 0.1377 - acc: 0.9545\n",
            "Epoch 8/30\n",
            "56590/56590 [==============================] - 10s 178us/step - loss: 0.1335 - acc: 0.9560\n",
            "Epoch 9/30\n",
            "56590/56590 [==============================] - 10s 179us/step - loss: 0.1280 - acc: 0.9578\n",
            "Epoch 10/30\n",
            "56590/56590 [==============================] - 10s 175us/step - loss: 0.1259 - acc: 0.9584\n",
            "Epoch 11/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.1222 - acc: 0.9590\n",
            "Epoch 12/30\n",
            "56590/56590 [==============================] - 10s 175us/step - loss: 0.1199 - acc: 0.9598\n",
            "Epoch 13/30\n",
            "56590/56590 [==============================] - 10s 175us/step - loss: 0.1180 - acc: 0.9601\n",
            "Epoch 14/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.1169 - acc: 0.9608\n",
            "Epoch 15/30\n",
            "56590/56590 [==============================] - 10s 175us/step - loss: 0.1151 - acc: 0.9606\n",
            "Epoch 16/30\n",
            "56590/56590 [==============================] - 10s 177us/step - loss: 0.1125 - acc: 0.9618\n",
            "Epoch 17/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.1129 - acc: 0.9617\n",
            "Epoch 18/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.1110 - acc: 0.9620\n",
            "Epoch 19/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.1105 - acc: 0.9626\n",
            "Epoch 20/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.1085 - acc: 0.9628\n",
            "Epoch 21/30\n",
            "56590/56590 [==============================] - 10s 172us/step - loss: 0.1094 - acc: 0.9621\n",
            "Epoch 22/30\n",
            "56590/56590 [==============================] - 10s 175us/step - loss: 0.1078 - acc: 0.9628\n",
            "Epoch 23/30\n",
            "56590/56590 [==============================] - 10s 171us/step - loss: 0.1083 - acc: 0.9629\n",
            "Epoch 24/30\n",
            "56590/56590 [==============================] - 10s 173us/step - loss: 0.1065 - acc: 0.9634\n",
            "Epoch 25/30\n",
            "56590/56590 [==============================] - 10s 175us/step - loss: 0.1053 - acc: 0.9636\n",
            "Epoch 26/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.1057 - acc: 0.9642\n",
            "Epoch 27/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.1063 - acc: 0.9635\n",
            "Epoch 28/30\n",
            "56590/56590 [==============================] - 10s 172us/step - loss: 0.1050 - acc: 0.9637\n",
            "Epoch 29/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.1064 - acc: 0.9643\n",
            "Epoch 30/30\n",
            "56590/56590 [==============================] - 10s 173us/step - loss: 0.1052 - acc: 0.9638\n",
            "Precision = 85.44, Recall = 83.47, F1 = 84.45\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-Vv17EGcwxb",
        "colab_type": "code",
        "outputId": "e17460cf-c8f0-436a-d024-61e642f92233",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# future context of 5, kernel of 5\n",
        "context_size = 5\n",
        "kernel_size = 5\n",
        "cnn_input, cnn_labels = get_future_window(train_x, train_label, context_size)\n",
        "val_input, val_labels = get_future_window(val_x, val_label, context_size)\n",
        "model = get_conv_model(context_size, kernel_size)\n",
        "model.fit(cnn_input, cnn_labels, epochs=30)\n",
        "print_evaluation(model, val_input, val_labels, val_x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_18 (Embedding)     (None, 5, 100)            57300     \n",
            "_________________________________________________________________\n",
            "conv1d_18 (Conv1D)           (None, 5, 100)            50100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_18 (MaxPooling (None, 2, 100)            0         \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 2, 100)            0         \n",
            "_________________________________________________________________\n",
            "flatten_18 (Flatten)         (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_35 (Dense)             (None, 128)               25728     \n",
            "_________________________________________________________________\n",
            "dense_36 (Dense)             (None, 127)               16383     \n",
            "=================================================================\n",
            "Total params: 149,511\n",
            "Trainable params: 149,511\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "56590/56590 [==============================] - 11s 200us/step - loss: 0.5850 - acc: 0.8718\n",
            "Epoch 2/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.2205 - acc: 0.9385\n",
            "Epoch 3/30\n",
            "56590/56590 [==============================] - 10s 176us/step - loss: 0.1798 - acc: 0.9462\n",
            "Epoch 4/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.1611 - acc: 0.9495\n",
            "Epoch 5/30\n",
            "56590/56590 [==============================] - 10s 175us/step - loss: 0.1492 - acc: 0.9518\n",
            "Epoch 6/30\n",
            "56590/56590 [==============================] - 10s 176us/step - loss: 0.1408 - acc: 0.9538\n",
            "Epoch 7/30\n",
            "56590/56590 [==============================] - 10s 177us/step - loss: 0.1364 - acc: 0.9554\n",
            "Epoch 8/30\n",
            "56590/56590 [==============================] - 10s 176us/step - loss: 0.1288 - acc: 0.9575\n",
            "Epoch 9/30\n",
            "56590/56590 [==============================] - 10s 175us/step - loss: 0.1255 - acc: 0.9580\n",
            "Epoch 10/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.1221 - acc: 0.9591\n",
            "Epoch 11/30\n",
            "56590/56590 [==============================] - 10s 176us/step - loss: 0.1199 - acc: 0.9595\n",
            "Epoch 12/30\n",
            "56590/56590 [==============================] - 10s 180us/step - loss: 0.1166 - acc: 0.9602\n",
            "Epoch 13/30\n",
            "56590/56590 [==============================] - 10s 176us/step - loss: 0.1150 - acc: 0.9613\n",
            "Epoch 14/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.1120 - acc: 0.9620\n",
            "Epoch 15/30\n",
            "56590/56590 [==============================] - 10s 176us/step - loss: 0.1105 - acc: 0.9631\n",
            "Epoch 16/30\n",
            "56590/56590 [==============================] - 10s 179us/step - loss: 0.1081 - acc: 0.9634\n",
            "Epoch 17/30\n",
            "56590/56590 [==============================] - 10s 177us/step - loss: 0.1104 - acc: 0.9625\n",
            "Epoch 18/30\n",
            "56590/56590 [==============================] - 10s 177us/step - loss: 0.1076 - acc: 0.9634\n",
            "Epoch 19/30\n",
            "56590/56590 [==============================] - 10s 175us/step - loss: 0.1059 - acc: 0.9643\n",
            "Epoch 20/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.1069 - acc: 0.9631\n",
            "Epoch 21/30\n",
            "56590/56590 [==============================] - 10s 175us/step - loss: 0.1049 - acc: 0.9644\n",
            "Epoch 22/30\n",
            "56590/56590 [==============================] - 10s 175us/step - loss: 0.1047 - acc: 0.9647\n",
            "Epoch 23/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.1037 - acc: 0.9648\n",
            "Epoch 24/30\n",
            "56590/56590 [==============================] - 10s 175us/step - loss: 0.1024 - acc: 0.9651\n",
            "Epoch 25/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.1047 - acc: 0.9658\n",
            "Epoch 26/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.1030 - acc: 0.9654\n",
            "Epoch 27/30\n",
            "56590/56590 [==============================] - 10s 176us/step - loss: 0.1008 - acc: 0.9658\n",
            "Epoch 28/30\n",
            "56590/56590 [==============================] - 10s 176us/step - loss: 0.1036 - acc: 0.9648\n",
            "Epoch 29/30\n",
            "56590/56590 [==============================] - 10s 175us/step - loss: 0.1018 - acc: 0.9656\n",
            "Epoch 30/30\n",
            "56590/56590 [==============================] - 10s 176us/step - loss: 0.0998 - acc: 0.9660\n",
            "Precision = 85.55, Recall = 84.77, F1 = 85.16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3dXljHozdVW9"
      },
      "source": [
        "**Experiment with a window size of 7 using the future context words**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPDgmnD0cxVr",
        "colab_type": "code",
        "outputId": "3f2a2d30-8044-4fae-c97a-49d138ee56dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# future context of 7, kernel of 3\n",
        "context_size = 7\n",
        "kernel_size = 3\n",
        "cnn_input, cnn_labels = get_future_window(train_x, train_label, context_size)\n",
        "val_input, val_labels = get_future_window(val_x, val_label, context_size)\n",
        "model = get_conv_model(context_size, kernel_size)\n",
        "model.fit(cnn_input, cnn_labels, epochs=30)\n",
        "print_evaluation(model, val_input, val_labels, val_x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_19 (Embedding)     (None, 7, 100)            57300     \n",
            "_________________________________________________________________\n",
            "conv1d_19 (Conv1D)           (None, 7, 100)            30100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_19 (MaxPooling (None, 3, 100)            0         \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 3, 100)            0         \n",
            "_________________________________________________________________\n",
            "flatten_19 (Flatten)         (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dense_37 (Dense)             (None, 128)               38528     \n",
            "_________________________________________________________________\n",
            "dense_38 (Dense)             (None, 127)               16383     \n",
            "=================================================================\n",
            "Total params: 142,311\n",
            "Trainable params: 142,311\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "56590/56590 [==============================] - 11s 200us/step - loss: 0.6358 - acc: 0.8615\n",
            "Epoch 2/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.2306 - acc: 0.9377\n",
            "Epoch 3/30\n",
            "56590/56590 [==============================] - 10s 175us/step - loss: 0.1884 - acc: 0.9464\n",
            "Epoch 4/30\n",
            "56590/56590 [==============================] - 10s 176us/step - loss: 0.1686 - acc: 0.9489\n",
            "Epoch 5/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.1552 - acc: 0.9524\n",
            "Epoch 6/30\n",
            "56590/56590 [==============================] - 10s 172us/step - loss: 0.1475 - acc: 0.9532\n",
            "Epoch 7/30\n",
            "56590/56590 [==============================] - 10s 175us/step - loss: 0.1403 - acc: 0.9559\n",
            "Epoch 8/30\n",
            "56590/56590 [==============================] - 10s 172us/step - loss: 0.1350 - acc: 0.9563\n",
            "Epoch 9/30\n",
            "56590/56590 [==============================] - 10s 175us/step - loss: 0.1300 - acc: 0.9583\n",
            "Epoch 10/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.1270 - acc: 0.9594\n",
            "Epoch 11/30\n",
            "56590/56590 [==============================] - 10s 170us/step - loss: 0.1245 - acc: 0.9597\n",
            "Epoch 12/30\n",
            "56590/56590 [==============================] - 10s 171us/step - loss: 0.1215 - acc: 0.9607\n",
            "Epoch 13/30\n",
            "56590/56590 [==============================] - 10s 178us/step - loss: 0.1191 - acc: 0.9614\n",
            "Epoch 14/30\n",
            "56590/56590 [==============================] - 10s 175us/step - loss: 0.1180 - acc: 0.9614\n",
            "Epoch 15/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.1170 - acc: 0.9620\n",
            "Epoch 16/30\n",
            "56590/56590 [==============================] - 10s 175us/step - loss: 0.1158 - acc: 0.9622\n",
            "Epoch 17/30\n",
            "56590/56590 [==============================] - 10s 177us/step - loss: 0.1131 - acc: 0.9627\n",
            "Epoch 18/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.1130 - acc: 0.9633\n",
            "Epoch 19/30\n",
            "56590/56590 [==============================] - 10s 173us/step - loss: 0.1101 - acc: 0.9638\n",
            "Epoch 20/30\n",
            "56590/56590 [==============================] - 10s 170us/step - loss: 0.1099 - acc: 0.9637\n",
            "Epoch 21/30\n",
            "56590/56590 [==============================] - 10s 172us/step - loss: 0.1106 - acc: 0.9643\n",
            "Epoch 22/30\n",
            "56590/56590 [==============================] - 10s 172us/step - loss: 0.1084 - acc: 0.9648\n",
            "Epoch 23/30\n",
            "56590/56590 [==============================] - 10s 170us/step - loss: 0.1098 - acc: 0.9644\n",
            "Epoch 24/30\n",
            "56590/56590 [==============================] - 10s 171us/step - loss: 0.1069 - acc: 0.9646\n",
            "Epoch 25/30\n",
            "56590/56590 [==============================] - 10s 169us/step - loss: 0.1071 - acc: 0.9658\n",
            "Epoch 26/30\n",
            "56590/56590 [==============================] - 10s 172us/step - loss: 0.1061 - acc: 0.9656\n",
            "Epoch 27/30\n",
            "56590/56590 [==============================] - 10s 171us/step - loss: 0.1075 - acc: 0.9647\n",
            "Epoch 28/30\n",
            "56590/56590 [==============================] - 10s 171us/step - loss: 0.1061 - acc: 0.9652\n",
            "Epoch 29/30\n",
            "56590/56590 [==============================] - 10s 173us/step - loss: 0.1068 - acc: 0.9653\n",
            "Epoch 30/30\n",
            "56590/56590 [==============================] - 10s 175us/step - loss: 0.1069 - acc: 0.9652\n",
            "Precision = 85.41, Recall = 83.81, F1 = 84.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zb73W7Z6cxTB",
        "colab_type": "code",
        "outputId": "7314e811-eafd-4ff5-b353-42d0d7daac78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# future context of 7, kernel of 5\n",
        "context_size = 7\n",
        "kernel_size = 5\n",
        "cnn_input, cnn_labels = get_future_window(train_x, train_label, context_size)\n",
        "val_input, val_labels = get_future_window(val_x, val_label, context_size)\n",
        "model = get_conv_model(context_size, kernel_size)\n",
        "model.fit(cnn_input, cnn_labels, epochs=30)\n",
        "print_evaluation(model, val_input, val_labels, val_x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_20 (Embedding)     (None, 7, 100)            57300     \n",
            "_________________________________________________________________\n",
            "conv1d_20 (Conv1D)           (None, 7, 100)            50100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_20 (MaxPooling (None, 3, 100)            0         \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, 3, 100)            0         \n",
            "_________________________________________________________________\n",
            "flatten_20 (Flatten)         (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dense_39 (Dense)             (None, 128)               38528     \n",
            "_________________________________________________________________\n",
            "dense_40 (Dense)             (None, 127)               16383     \n",
            "=================================================================\n",
            "Total params: 162,311\n",
            "Trainable params: 162,311\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "56590/56590 [==============================] - 11s 197us/step - loss: 0.6182 - acc: 0.8637\n",
            "Epoch 2/30\n",
            "56590/56590 [==============================] - 10s 170us/step - loss: 0.2244 - acc: 0.9383\n",
            "Epoch 3/30\n",
            "56590/56590 [==============================] - 10s 173us/step - loss: 0.1821 - acc: 0.9463\n",
            "Epoch 4/30\n",
            "56590/56590 [==============================] - 10s 175us/step - loss: 0.1608 - acc: 0.9512\n",
            "Epoch 5/30\n",
            "56590/56590 [==============================] - 10s 173us/step - loss: 0.1474 - acc: 0.9530\n",
            "Epoch 6/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.1378 - acc: 0.9550\n",
            "Epoch 7/30\n",
            "56590/56590 [==============================] - 10s 171us/step - loss: 0.1315 - acc: 0.9575\n",
            "Epoch 8/30\n",
            "56590/56590 [==============================] - 10s 171us/step - loss: 0.1262 - acc: 0.9583\n",
            "Epoch 9/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.1216 - acc: 0.9600\n",
            "Epoch 10/30\n",
            "56590/56590 [==============================] - 10s 173us/step - loss: 0.1177 - acc: 0.9606\n",
            "Epoch 11/30\n",
            "56590/56590 [==============================] - 10s 172us/step - loss: 0.1140 - acc: 0.9625\n",
            "Epoch 12/30\n",
            "56590/56590 [==============================] - 10s 173us/step - loss: 0.1130 - acc: 0.9625\n",
            "Epoch 13/30\n",
            "56590/56590 [==============================] - 10s 175us/step - loss: 0.1105 - acc: 0.9632\n",
            "Epoch 14/30\n",
            "56590/56590 [==============================] - 10s 177us/step - loss: 0.1093 - acc: 0.9640\n",
            "Epoch 15/30\n",
            "56590/56590 [==============================] - 10s 178us/step - loss: 0.1078 - acc: 0.9635\n",
            "Epoch 16/30\n",
            "56590/56590 [==============================] - 10s 172us/step - loss: 0.1061 - acc: 0.9647\n",
            "Epoch 17/30\n",
            "56590/56590 [==============================] - 10s 170us/step - loss: 0.1074 - acc: 0.9643\n",
            "Epoch 18/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.1036 - acc: 0.9652\n",
            "Epoch 19/30\n",
            "56590/56590 [==============================] - 10s 171us/step - loss: 0.1024 - acc: 0.9649\n",
            "Epoch 20/30\n",
            "56590/56590 [==============================] - 10s 173us/step - loss: 0.1034 - acc: 0.9647\n",
            "Epoch 21/30\n",
            "56590/56590 [==============================] - 10s 172us/step - loss: 0.1045 - acc: 0.9649\n",
            "Epoch 22/30\n",
            "56590/56590 [==============================] - 10s 170us/step - loss: 0.1008 - acc: 0.9657\n",
            "Epoch 23/30\n",
            "56590/56590 [==============================] - 10s 172us/step - loss: 0.1010 - acc: 0.9657\n",
            "Epoch 24/30\n",
            "56590/56590 [==============================] - 10s 172us/step - loss: 0.1024 - acc: 0.9655\n",
            "Epoch 25/30\n",
            "56590/56590 [==============================] - 10s 173us/step - loss: 0.0991 - acc: 0.9663\n",
            "Epoch 26/30\n",
            "56590/56590 [==============================] - 10s 172us/step - loss: 0.1005 - acc: 0.9662\n",
            "Epoch 27/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.0992 - acc: 0.9665\n",
            "Epoch 28/30\n",
            "56590/56590 [==============================] - 10s 168us/step - loss: 0.0998 - acc: 0.9671\n",
            "Epoch 29/30\n",
            "56590/56590 [==============================] - 10s 172us/step - loss: 0.1000 - acc: 0.9672\n",
            "Epoch 30/30\n",
            "56590/56590 [==============================] - 10s 171us/step - loss: 0.1000 - acc: 0.9664\n",
            "Precision = 85.69, Recall = 85.21, F1 = 85.45\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Any5dK6FcxPr",
        "colab_type": "code",
        "outputId": "b716d45f-79b0-4a52-8b54-60c79bff1e49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# future context of 7, kernel of 7\n",
        "context_size = 7\n",
        "kernel_size = 7\n",
        "cnn_input, cnn_labels = get_future_window(train_x, train_label, context_size)\n",
        "val_input, val_labels = get_future_window(val_x, val_label, context_size)\n",
        "model = get_conv_model(context_size, kernel_size)\n",
        "model.fit(cnn_input, cnn_labels, epochs=30)\n",
        "print_evaluation(model, val_input, val_labels, val_x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_21 (Embedding)     (None, 7, 100)            57300     \n",
            "_________________________________________________________________\n",
            "conv1d_21 (Conv1D)           (None, 7, 100)            70100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_21 (MaxPooling (None, 3, 100)            0         \n",
            "_________________________________________________________________\n",
            "dropout_21 (Dropout)         (None, 3, 100)            0         \n",
            "_________________________________________________________________\n",
            "flatten_21 (Flatten)         (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dense_41 (Dense)             (None, 128)               38528     \n",
            "_________________________________________________________________\n",
            "dense_42 (Dense)             (None, 127)               16383     \n",
            "=================================================================\n",
            "Total params: 182,311\n",
            "Trainable params: 182,311\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "56590/56590 [==============================] - 12s 204us/step - loss: 0.6031 - acc: 0.8678\n",
            "Epoch 2/30\n",
            "56590/56590 [==============================] - 10s 172us/step - loss: 0.2218 - acc: 0.9392\n",
            "Epoch 3/30\n",
            "56590/56590 [==============================] - 10s 173us/step - loss: 0.1775 - acc: 0.9470\n",
            "Epoch 4/30\n",
            "56590/56590 [==============================] - 10s 173us/step - loss: 0.1599 - acc: 0.9508\n",
            "Epoch 5/30\n",
            "56590/56590 [==============================] - 10s 172us/step - loss: 0.1469 - acc: 0.9528\n",
            "Epoch 6/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.1347 - acc: 0.9563\n",
            "Epoch 7/30\n",
            "56590/56590 [==============================] - 10s 173us/step - loss: 0.1300 - acc: 0.9572\n",
            "Epoch 8/30\n",
            "56590/56590 [==============================] - 10s 175us/step - loss: 0.1229 - acc: 0.9589\n",
            "Epoch 9/30\n",
            "56590/56590 [==============================] - 10s 173us/step - loss: 0.1202 - acc: 0.9600\n",
            "Epoch 10/30\n",
            "56590/56590 [==============================] - 10s 172us/step - loss: 0.1151 - acc: 0.9621\n",
            "Epoch 11/30\n",
            "56590/56590 [==============================] - 10s 173us/step - loss: 0.1121 - acc: 0.9628\n",
            "Epoch 12/30\n",
            "56590/56590 [==============================] - 10s 173us/step - loss: 0.1117 - acc: 0.9624\n",
            "Epoch 13/30\n",
            "56590/56590 [==============================] - 10s 173us/step - loss: 0.1081 - acc: 0.9640\n",
            "Epoch 14/30\n",
            "56590/56590 [==============================] - 10s 173us/step - loss: 0.1086 - acc: 0.9636\n",
            "Epoch 15/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.1051 - acc: 0.9644\n",
            "Epoch 16/30\n",
            "56590/56590 [==============================] - 10s 182us/step - loss: 0.1054 - acc: 0.9643\n",
            "Epoch 17/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.1040 - acc: 0.9652\n",
            "Epoch 18/30\n",
            "56590/56590 [==============================] - 10s 172us/step - loss: 0.1031 - acc: 0.9652\n",
            "Epoch 19/30\n",
            "56590/56590 [==============================] - 10s 178us/step - loss: 0.1058 - acc: 0.9642\n",
            "Epoch 20/30\n",
            "56590/56590 [==============================] - 10s 175us/step - loss: 0.1033 - acc: 0.9658\n",
            "Epoch 21/30\n",
            "56590/56590 [==============================] - 10s 173us/step - loss: 0.1011 - acc: 0.9658\n",
            "Epoch 22/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.1015 - acc: 0.9655\n",
            "Epoch 23/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.1028 - acc: 0.9656\n",
            "Epoch 24/30\n",
            "56590/56590 [==============================] - 10s 173us/step - loss: 0.1002 - acc: 0.9670\n",
            "Epoch 25/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.1008 - acc: 0.9670\n",
            "Epoch 26/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.1001 - acc: 0.9669\n",
            "Epoch 27/30\n",
            "56590/56590 [==============================] - 10s 175us/step - loss: 0.0986 - acc: 0.9665\n",
            "Epoch 28/30\n",
            "56590/56590 [==============================] - 10s 173us/step - loss: 0.0992 - acc: 0.9663\n",
            "Epoch 29/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.1002 - acc: 0.9664\n",
            "Epoch 30/30\n",
            "56590/56590 [==============================] - 10s 172us/step - loss: 0.0987 - acc: 0.9669\n",
            "Precision = 85.65, Recall = 85.08, F1 = 85.37\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Vr4DPM2-dYdO"
      },
      "source": [
        "**Experiment with a window size of 9 using the future context words**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKfa5V2WcxM8",
        "colab_type": "code",
        "outputId": "3db79b31-c1eb-4f4f-e786-2eabbc210f2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# future context of 9, kernel of 3\n",
        "context_size = 9\n",
        "kernel_size = 3\n",
        "cnn_input, cnn_labels = get_future_window(train_x, train_label, context_size)\n",
        "val_input, val_labels = get_future_window(val_x, val_label, context_size)\n",
        "model = get_conv_model(context_size, kernel_size)\n",
        "model.fit(cnn_input, cnn_labels, epochs=30)\n",
        "print_evaluation(model, val_input, val_labels, val_x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_22\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_22 (Embedding)     (None, 9, 100)            57300     \n",
            "_________________________________________________________________\n",
            "conv1d_22 (Conv1D)           (None, 9, 100)            30100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_22 (MaxPooling (None, 4, 100)            0         \n",
            "_________________________________________________________________\n",
            "dropout_22 (Dropout)         (None, 4, 100)            0         \n",
            "_________________________________________________________________\n",
            "flatten_22 (Flatten)         (None, 400)               0         \n",
            "_________________________________________________________________\n",
            "dense_43 (Dense)             (None, 128)               51328     \n",
            "_________________________________________________________________\n",
            "dense_44 (Dense)             (None, 127)               16383     \n",
            "=================================================================\n",
            "Total params: 155,111\n",
            "Trainable params: 155,111\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "56590/56590 [==============================] - 11s 203us/step - loss: 0.6301 - acc: 0.8625\n",
            "Epoch 2/30\n",
            "56590/56590 [==============================] - 10s 176us/step - loss: 0.2268 - acc: 0.9371\n",
            "Epoch 3/30\n",
            "56590/56590 [==============================] - 10s 176us/step - loss: 0.1839 - acc: 0.9454\n",
            "Epoch 4/30\n",
            "56590/56590 [==============================] - 10s 175us/step - loss: 0.1617 - acc: 0.9499\n",
            "Epoch 5/30\n",
            "56590/56590 [==============================] - 10s 178us/step - loss: 0.1468 - acc: 0.9535\n",
            "Epoch 6/30\n",
            "56590/56590 [==============================] - 10s 175us/step - loss: 0.1418 - acc: 0.9547\n",
            "Epoch 7/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.1315 - acc: 0.9568\n",
            "Epoch 8/30\n",
            "56590/56590 [==============================] - 10s 175us/step - loss: 0.1285 - acc: 0.9578\n",
            "Epoch 9/30\n",
            "56590/56590 [==============================] - 10s 173us/step - loss: 0.1241 - acc: 0.9591\n",
            "Epoch 10/30\n",
            "56590/56590 [==============================] - 10s 176us/step - loss: 0.1207 - acc: 0.9598\n",
            "Epoch 11/30\n",
            "56590/56590 [==============================] - 10s 176us/step - loss: 0.1183 - acc: 0.9611\n",
            "Epoch 12/30\n",
            "56590/56590 [==============================] - 10s 177us/step - loss: 0.1144 - acc: 0.9619\n",
            "Epoch 13/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.1148 - acc: 0.9618\n",
            "Epoch 14/30\n",
            "56590/56590 [==============================] - 10s 176us/step - loss: 0.1123 - acc: 0.9616\n",
            "Epoch 15/30\n",
            "56590/56590 [==============================] - 10s 176us/step - loss: 0.1103 - acc: 0.9631\n",
            "Epoch 16/30\n",
            "56590/56590 [==============================] - 10s 176us/step - loss: 0.1083 - acc: 0.9637\n",
            "Epoch 17/30\n",
            "56590/56590 [==============================] - 10s 181us/step - loss: 0.1084 - acc: 0.9638\n",
            "Epoch 18/30\n",
            "56590/56590 [==============================] - 10s 176us/step - loss: 0.1078 - acc: 0.9637\n",
            "Epoch 19/30\n",
            "56590/56590 [==============================] - 10s 179us/step - loss: 0.1082 - acc: 0.9641\n",
            "Epoch 20/30\n",
            "56590/56590 [==============================] - 10s 177us/step - loss: 0.1048 - acc: 0.9645\n",
            "Epoch 21/30\n",
            "56590/56590 [==============================] - 10s 175us/step - loss: 0.1038 - acc: 0.9647\n",
            "Epoch 22/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.1046 - acc: 0.9651\n",
            "Epoch 23/30\n",
            "56590/56590 [==============================] - 10s 177us/step - loss: 0.1023 - acc: 0.9657\n",
            "Epoch 24/30\n",
            "56590/56590 [==============================] - 10s 176us/step - loss: 0.1019 - acc: 0.9665\n",
            "Epoch 25/30\n",
            "56590/56590 [==============================] - 10s 175us/step - loss: 0.1027 - acc: 0.9654\n",
            "Epoch 26/30\n",
            "56590/56590 [==============================] - 10s 178us/step - loss: 0.1018 - acc: 0.9657\n",
            "Epoch 27/30\n",
            "56590/56590 [==============================] - 10s 177us/step - loss: 0.1026 - acc: 0.9655\n",
            "Epoch 28/30\n",
            "56590/56590 [==============================] - 10s 177us/step - loss: 0.1000 - acc: 0.9663\n",
            "Epoch 29/30\n",
            "56590/56590 [==============================] - 10s 178us/step - loss: 0.1009 - acc: 0.9662\n",
            "Epoch 30/30\n",
            "56590/56590 [==============================] - 10s 182us/step - loss: 0.1000 - acc: 0.9663\n",
            "Precision = 86.5, Recall = 85.92, F1 = 86.21\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaArdcvFcxKg",
        "colab_type": "code",
        "outputId": "4554dffd-5689-4a51-bac9-0b4706548cfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# future context of 9, kernel of 5\n",
        "context_size = 9\n",
        "kernel_size = 5\n",
        "cnn_input, cnn_labels = get_future_window(train_x, train_label, context_size)\n",
        "val_input, val_labels = get_future_window(val_x, val_label, context_size)\n",
        "model = get_conv_model(context_size, kernel_size)\n",
        "model.fit(cnn_input, cnn_labels, epochs=30)\n",
        "print_evaluation(model, val_input, val_labels, val_x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_23\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_23 (Embedding)     (None, 9, 100)            57300     \n",
            "_________________________________________________________________\n",
            "conv1d_23 (Conv1D)           (None, 9, 100)            50100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_23 (MaxPooling (None, 4, 100)            0         \n",
            "_________________________________________________________________\n",
            "dropout_23 (Dropout)         (None, 4, 100)            0         \n",
            "_________________________________________________________________\n",
            "flatten_23 (Flatten)         (None, 400)               0         \n",
            "_________________________________________________________________\n",
            "dense_45 (Dense)             (None, 128)               51328     \n",
            "_________________________________________________________________\n",
            "dense_46 (Dense)             (None, 127)               16383     \n",
            "=================================================================\n",
            "Total params: 175,111\n",
            "Trainable params: 175,111\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "56590/56590 [==============================] - 12s 213us/step - loss: 0.6353 - acc: 0.8613\n",
            "Epoch 2/30\n",
            "56590/56590 [==============================] - 10s 180us/step - loss: 0.2329 - acc: 0.9370\n",
            "Epoch 3/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.1864 - acc: 0.9458\n",
            "Epoch 4/30\n",
            "56590/56590 [==============================] - 10s 180us/step - loss: 0.1649 - acc: 0.9500\n",
            "Epoch 5/30\n",
            "56590/56590 [==============================] - 10s 182us/step - loss: 0.1504 - acc: 0.9533\n",
            "Epoch 6/30\n",
            "56590/56590 [==============================] - 10s 180us/step - loss: 0.1412 - acc: 0.9555\n",
            "Epoch 7/30\n",
            "56590/56590 [==============================] - 10s 182us/step - loss: 0.1330 - acc: 0.9574\n",
            "Epoch 8/30\n",
            "56590/56590 [==============================] - 10s 179us/step - loss: 0.1294 - acc: 0.9587\n",
            "Epoch 9/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.1220 - acc: 0.9599\n",
            "Epoch 10/30\n",
            "56590/56590 [==============================] - 10s 181us/step - loss: 0.1202 - acc: 0.9608\n",
            "Epoch 11/30\n",
            "56590/56590 [==============================] - 10s 181us/step - loss: 0.1184 - acc: 0.9606\n",
            "Epoch 12/30\n",
            "56590/56590 [==============================] - 10s 181us/step - loss: 0.1144 - acc: 0.9624\n",
            "Epoch 13/30\n",
            "56590/56590 [==============================] - 10s 181us/step - loss: 0.1118 - acc: 0.9627\n",
            "Epoch 14/30\n",
            "56590/56590 [==============================] - 10s 181us/step - loss: 0.1098 - acc: 0.9634\n",
            "Epoch 15/30\n",
            "56590/56590 [==============================] - 10s 182us/step - loss: 0.1106 - acc: 0.9634\n",
            "Epoch 16/30\n",
            "56590/56590 [==============================] - 10s 182us/step - loss: 0.1091 - acc: 0.9640\n",
            "Epoch 17/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.1069 - acc: 0.9641\n",
            "Epoch 18/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.1060 - acc: 0.9656\n",
            "Epoch 19/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.1057 - acc: 0.9651\n",
            "Epoch 20/30\n",
            "56590/56590 [==============================] - 10s 180us/step - loss: 0.1042 - acc: 0.9661\n",
            "Epoch 21/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.1058 - acc: 0.9656\n",
            "Epoch 22/30\n",
            "56590/56590 [==============================] - 10s 181us/step - loss: 0.1045 - acc: 0.9653\n",
            "Epoch 23/30\n",
            "56590/56590 [==============================] - 10s 180us/step - loss: 0.1039 - acc: 0.9656\n",
            "Epoch 24/30\n",
            "56590/56590 [==============================] - 10s 181us/step - loss: 0.1053 - acc: 0.9656\n",
            "Epoch 25/30\n",
            "56590/56590 [==============================] - 10s 181us/step - loss: 0.1038 - acc: 0.9658\n",
            "Epoch 26/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.1038 - acc: 0.9663\n",
            "Epoch 27/30\n",
            "56590/56590 [==============================] - 10s 181us/step - loss: 0.1045 - acc: 0.9654\n",
            "Epoch 28/30\n",
            "56590/56590 [==============================] - 10s 180us/step - loss: 0.1019 - acc: 0.9664\n",
            "Epoch 29/30\n",
            "56590/56590 [==============================] - 10s 181us/step - loss: 0.1008 - acc: 0.9666\n",
            "Epoch 30/30\n",
            "56590/56590 [==============================] - 10s 180us/step - loss: 0.1019 - acc: 0.9660\n",
            "Precision = 85.55, Recall = 83.95, F1 = 84.74\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cEszT2OcxHn",
        "colab_type": "code",
        "outputId": "80149582-d861-4b79-a22c-a695ad335dbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# future context of 9, kernel of 7\n",
        "context_size = 9\n",
        "kernel_size = 7\n",
        "cnn_input, cnn_labels = get_future_window(train_x, train_label, context_size)\n",
        "val_input, val_labels = get_future_window(val_x, val_label, context_size)\n",
        "model = get_conv_model(context_size, kernel_size)\n",
        "model.fit(cnn_input, cnn_labels, epochs=30)\n",
        "print_evaluation(model, val_input, val_labels, val_x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_24\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_24 (Embedding)     (None, 9, 100)            57300     \n",
            "_________________________________________________________________\n",
            "conv1d_24 (Conv1D)           (None, 9, 100)            70100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_24 (MaxPooling (None, 4, 100)            0         \n",
            "_________________________________________________________________\n",
            "dropout_24 (Dropout)         (None, 4, 100)            0         \n",
            "_________________________________________________________________\n",
            "flatten_24 (Flatten)         (None, 400)               0         \n",
            "_________________________________________________________________\n",
            "dense_47 (Dense)             (None, 128)               51328     \n",
            "_________________________________________________________________\n",
            "dense_48 (Dense)             (None, 127)               16383     \n",
            "=================================================================\n",
            "Total params: 195,111\n",
            "Trainable params: 195,111\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "56590/56590 [==============================] - 12s 217us/step - loss: 0.6162 - acc: 0.8668\n",
            "Epoch 2/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.2260 - acc: 0.9381\n",
            "Epoch 3/30\n",
            "56590/56590 [==============================] - 10s 180us/step - loss: 0.1798 - acc: 0.9466\n",
            "Epoch 4/30\n",
            "56590/56590 [==============================] - 10s 180us/step - loss: 0.1591 - acc: 0.9513\n",
            "Epoch 5/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.1461 - acc: 0.9539\n",
            "Epoch 6/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.1378 - acc: 0.9561\n",
            "Epoch 7/30\n",
            "56590/56590 [==============================] - 10s 182us/step - loss: 0.1285 - acc: 0.9591\n",
            "Epoch 8/30\n",
            "56590/56590 [==============================] - 10s 182us/step - loss: 0.1251 - acc: 0.9588\n",
            "Epoch 9/30\n",
            "56590/56590 [==============================] - 10s 181us/step - loss: 0.1211 - acc: 0.9600\n",
            "Epoch 10/30\n",
            "56590/56590 [==============================] - 10s 181us/step - loss: 0.1175 - acc: 0.9613\n",
            "Epoch 11/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.1139 - acc: 0.9631\n",
            "Epoch 12/30\n",
            "56590/56590 [==============================] - 10s 181us/step - loss: 0.1118 - acc: 0.9631\n",
            "Epoch 13/30\n",
            "56590/56590 [==============================] - 10s 180us/step - loss: 0.1102 - acc: 0.9639\n",
            "Epoch 14/30\n",
            "56590/56590 [==============================] - 10s 181us/step - loss: 0.1102 - acc: 0.9641\n",
            "Epoch 15/30\n",
            "56590/56590 [==============================] - 10s 182us/step - loss: 0.1069 - acc: 0.9650\n",
            "Epoch 16/30\n",
            "56590/56590 [==============================] - 10s 180us/step - loss: 0.1058 - acc: 0.9649\n",
            "Epoch 17/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.1064 - acc: 0.9646\n",
            "Epoch 18/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.1070 - acc: 0.9653\n",
            "Epoch 19/30\n",
            "56590/56590 [==============================] - 10s 181us/step - loss: 0.1015 - acc: 0.9663\n",
            "Epoch 20/30\n",
            "56590/56590 [==============================] - 10s 182us/step - loss: 0.1037 - acc: 0.9661\n",
            "Epoch 21/30\n",
            "56590/56590 [==============================] - 10s 181us/step - loss: 0.1027 - acc: 0.9661\n",
            "Epoch 22/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.1022 - acc: 0.9660\n",
            "Epoch 23/30\n",
            "56590/56590 [==============================] - 10s 180us/step - loss: 0.1033 - acc: 0.9659\n",
            "Epoch 24/30\n",
            "56590/56590 [==============================] - 10s 181us/step - loss: 0.1011 - acc: 0.9667\n",
            "Epoch 25/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.1049 - acc: 0.9660\n",
            "Epoch 26/30\n",
            "56590/56590 [==============================] - 10s 181us/step - loss: 0.1019 - acc: 0.9659\n",
            "Epoch 27/30\n",
            "56590/56590 [==============================] - 10s 181us/step - loss: 0.1000 - acc: 0.9670\n",
            "Epoch 28/30\n",
            "56590/56590 [==============================] - 10s 181us/step - loss: 0.1002 - acc: 0.9670\n",
            "Epoch 29/30\n",
            "56590/56590 [==============================] - 10s 181us/step - loss: 0.1002 - acc: 0.9669\n",
            "Epoch 30/30\n",
            "56590/56590 [==============================] - 10s 182us/step - loss: 0.1015 - acc: 0.9667\n",
            "Precision = 84.35, Recall = 83.61, F1 = 83.98\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSh-19LZcxEx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvPNoL4NcxCK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zO4brrMTcw-j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGOTZvQUcw7I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7aKmxcmcw4M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jca5OeeJddAH"
      },
      "source": [
        "**Experiment with a window size of 3 using both future and past context words**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmVWDNx6Y9qo",
        "colab_type": "code",
        "outputId": "b0d333fa-bd27-40d9-c507-2f60f90296e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# past and future context of 3, kernel of 3\n",
        "context_size = 3\n",
        "kernel_size = 3\n",
        "cnn_input, cnn_labels = get_past_and_future_window(train_x, train_label, context_size)\n",
        "val_input, val_labels = get_past_and_future_window(val_x, val_label, context_size)\n",
        "model = get_conv_model(context_size, kernel_size)\n",
        "model.fit(cnn_input, cnn_labels, epochs=30)\n",
        "print_evaluation(model, val_input, val_labels, val_x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_25\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_25 (Embedding)     (None, 3, 100)            57300     \n",
            "_________________________________________________________________\n",
            "conv1d_25 (Conv1D)           (None, 3, 100)            30100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_25 (MaxPooling (None, 1, 100)            0         \n",
            "_________________________________________________________________\n",
            "dropout_25 (Dropout)         (None, 1, 100)            0         \n",
            "_________________________________________________________________\n",
            "flatten_25 (Flatten)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_49 (Dense)             (None, 128)               12928     \n",
            "_________________________________________________________________\n",
            "dense_50 (Dense)             (None, 127)               16383     \n",
            "=================================================================\n",
            "Total params: 116,711\n",
            "Trainable params: 116,711\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "56590/56590 [==============================] - 13s 223us/step - loss: 0.5197 - acc: 0.8907\n",
            "Epoch 2/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.1615 - acc: 0.9546\n",
            "Epoch 3/30\n",
            "56590/56590 [==============================] - 10s 182us/step - loss: 0.1233 - acc: 0.9623\n",
            "Epoch 4/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.1077 - acc: 0.9663\n",
            "Epoch 5/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.0983 - acc: 0.9670\n",
            "Epoch 6/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.0948 - acc: 0.9682\n",
            "Epoch 7/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.0904 - acc: 0.9698\n",
            "Epoch 8/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0845 - acc: 0.9700\n",
            "Epoch 9/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.0844 - acc: 0.9711\n",
            "Epoch 10/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.0813 - acc: 0.9713\n",
            "Epoch 11/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.0800 - acc: 0.9723\n",
            "Epoch 12/30\n",
            "56590/56590 [==============================] - 10s 182us/step - loss: 0.0790 - acc: 0.9721\n",
            "Epoch 13/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.0762 - acc: 0.9725\n",
            "Epoch 14/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.0766 - acc: 0.9726\n",
            "Epoch 15/30\n",
            "56590/56590 [==============================] - 10s 182us/step - loss: 0.0735 - acc: 0.9731\n",
            "Epoch 16/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0739 - acc: 0.9733\n",
            "Epoch 17/30\n",
            "56590/56590 [==============================] - 11s 191us/step - loss: 0.0729 - acc: 0.9737\n",
            "Epoch 18/30\n",
            "56590/56590 [==============================] - 10s 181us/step - loss: 0.0726 - acc: 0.9736\n",
            "Epoch 19/30\n",
            "56590/56590 [==============================] - 10s 182us/step - loss: 0.0706 - acc: 0.9746\n",
            "Epoch 20/30\n",
            "56590/56590 [==============================] - 10s 182us/step - loss: 0.0705 - acc: 0.9744\n",
            "Epoch 21/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0713 - acc: 0.9741\n",
            "Epoch 22/30\n",
            "56590/56590 [==============================] - 10s 180us/step - loss: 0.0706 - acc: 0.9744\n",
            "Epoch 23/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.0685 - acc: 0.9748\n",
            "Epoch 24/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.0692 - acc: 0.9749\n",
            "Epoch 25/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.0685 - acc: 0.9752\n",
            "Epoch 26/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.0669 - acc: 0.9756\n",
            "Epoch 27/30\n",
            "56590/56590 [==============================] - 10s 181us/step - loss: 0.0699 - acc: 0.9752\n",
            "Epoch 28/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.0683 - acc: 0.9750\n",
            "Epoch 29/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.0670 - acc: 0.9746\n",
            "Epoch 30/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.0682 - acc: 0.9753\n",
            "Precision = 86.85, Recall = 82.38, F1 = 84.56\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Q_Ql5T76ePbd"
      },
      "source": [
        "**Experiment with a window size of 5 using both future and past context words**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRMZ-iP3Y9-y",
        "colab_type": "code",
        "outputId": "bbf9a4b8-031b-475c-9ade-7aef84bcbe0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# past and future context of 5, kernel of 3\n",
        "context_size = 5\n",
        "kernel_size = 3\n",
        "cnn_input, cnn_labels = get_past_and_future_window(train_x, train_label, context_size)\n",
        "val_input, val_labels = get_past_and_future_window(val_x, val_label, context_size)\n",
        "model = get_conv_model(context_size, kernel_size)\n",
        "model.fit(cnn_input, cnn_labels, epochs=30)\n",
        "print_evaluation(model, val_input, val_labels, val_x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_26\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_26 (Embedding)     (None, 3, 100)            57300     \n",
            "_________________________________________________________________\n",
            "conv1d_26 (Conv1D)           (None, 3, 100)            30100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_26 (MaxPooling (None, 1, 100)            0         \n",
            "_________________________________________________________________\n",
            "dropout_26 (Dropout)         (None, 1, 100)            0         \n",
            "_________________________________________________________________\n",
            "flatten_26 (Flatten)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_51 (Dense)             (None, 128)               12928     \n",
            "_________________________________________________________________\n",
            "dense_52 (Dense)             (None, 127)               16383     \n",
            "=================================================================\n",
            "Total params: 116,711\n",
            "Trainable params: 116,711\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "56590/56590 [==============================] - 13s 221us/step - loss: 0.5177 - acc: 0.8922\n",
            "Epoch 2/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.1578 - acc: 0.9554\n",
            "Epoch 3/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.1222 - acc: 0.9625\n",
            "Epoch 4/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.1079 - acc: 0.9648\n",
            "Epoch 5/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.1005 - acc: 0.9665\n",
            "Epoch 6/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.0939 - acc: 0.9680\n",
            "Epoch 7/30\n",
            "56590/56590 [==============================] - 10s 182us/step - loss: 0.0896 - acc: 0.9693\n",
            "Epoch 8/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.0868 - acc: 0.9700\n",
            "Epoch 9/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.0832 - acc: 0.9706\n",
            "Epoch 10/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.0807 - acc: 0.9714\n",
            "Epoch 11/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.0787 - acc: 0.9719\n",
            "Epoch 12/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.0783 - acc: 0.9722\n",
            "Epoch 13/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.0749 - acc: 0.9730\n",
            "Epoch 14/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.0751 - acc: 0.9732\n",
            "Epoch 15/30\n",
            "56590/56590 [==============================] - 10s 180us/step - loss: 0.0743 - acc: 0.9735\n",
            "Epoch 16/30\n",
            "56590/56590 [==============================] - 11s 191us/step - loss: 0.0730 - acc: 0.9737\n",
            "Epoch 17/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0721 - acc: 0.9738\n",
            "Epoch 18/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0719 - acc: 0.9737\n",
            "Epoch 19/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.0705 - acc: 0.9745\n",
            "Epoch 20/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.0706 - acc: 0.9737\n",
            "Epoch 21/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.0694 - acc: 0.9748\n",
            "Epoch 22/30\n",
            "56590/56590 [==============================] - 10s 181us/step - loss: 0.0698 - acc: 0.9744\n",
            "Epoch 23/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.0685 - acc: 0.9744\n",
            "Epoch 24/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.0693 - acc: 0.9744\n",
            "Epoch 25/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.0683 - acc: 0.9748\n",
            "Epoch 26/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0670 - acc: 0.9750\n",
            "Epoch 27/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0681 - acc: 0.9745\n",
            "Epoch 28/30\n",
            "56590/56590 [==============================] - 10s 182us/step - loss: 0.0674 - acc: 0.9755\n",
            "Epoch 29/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.0670 - acc: 0.9754\n",
            "Epoch 30/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0660 - acc: 0.9756\n",
            "Precision = 85.9, Recall = 81.75, F1 = 83.77\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LC9b43LPY-OQ",
        "colab_type": "code",
        "outputId": "18c2cf78-c983-4e0e-ff94-2b8d81a4c7cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# past and future context of 5, kernel of 5\n",
        "context_size = 5\n",
        "kernel_size = 5\n",
        "cnn_input, cnn_labels = get_past_and_future_window(train_x, train_label, context_size)\n",
        "val_input, val_labels = get_past_and_future_window(val_x, val_label, context_size)\n",
        "model = get_conv_model(context_size, kernel_size)\n",
        "model.fit(cnn_input, cnn_labels, epochs=30)\n",
        "print_evaluation(model, val_input, val_labels, val_x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_27\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_27 (Embedding)     (None, 5, 100)            57300     \n",
            "_________________________________________________________________\n",
            "conv1d_27 (Conv1D)           (None, 5, 100)            50100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_27 (MaxPooling (None, 2, 100)            0         \n",
            "_________________________________________________________________\n",
            "dropout_27 (Dropout)         (None, 2, 100)            0         \n",
            "_________________________________________________________________\n",
            "flatten_27 (Flatten)         (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_53 (Dense)             (None, 128)               25728     \n",
            "_________________________________________________________________\n",
            "dense_54 (Dense)             (None, 127)               16383     \n",
            "=================================================================\n",
            "Total params: 149,511\n",
            "Trainable params: 149,511\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "56590/56590 [==============================] - 13s 226us/step - loss: 0.4826 - acc: 0.9008\n",
            "Epoch 2/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.1224 - acc: 0.9683\n",
            "Epoch 3/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0821 - acc: 0.9766\n",
            "Epoch 4/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0680 - acc: 0.9791\n",
            "Epoch 5/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.0587 - acc: 0.9817\n",
            "Epoch 6/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0542 - acc: 0.9825\n",
            "Epoch 7/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.0473 - acc: 0.9846\n",
            "Epoch 8/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0446 - acc: 0.9854\n",
            "Epoch 9/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.0424 - acc: 0.9858\n",
            "Epoch 10/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0410 - acc: 0.9866\n",
            "Epoch 11/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.0393 - acc: 0.9863\n",
            "Epoch 12/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.0371 - acc: 0.9873\n",
            "Epoch 13/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.0362 - acc: 0.9878\n",
            "Epoch 14/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.0374 - acc: 0.9877\n",
            "Epoch 15/30\n",
            "56590/56590 [==============================] - 11s 193us/step - loss: 0.0336 - acc: 0.9886\n",
            "Epoch 16/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.0354 - acc: 0.9880\n",
            "Epoch 17/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.0333 - acc: 0.9891\n",
            "Epoch 18/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0321 - acc: 0.9893\n",
            "Epoch 19/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.0336 - acc: 0.9890\n",
            "Epoch 20/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.0340 - acc: 0.9887\n",
            "Epoch 21/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.0315 - acc: 0.9894\n",
            "Epoch 22/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0307 - acc: 0.9897\n",
            "Epoch 23/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.0298 - acc: 0.9905\n",
            "Epoch 24/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0335 - acc: 0.9893\n",
            "Epoch 25/30\n",
            "56590/56590 [==============================] - 10s 186us/step - loss: 0.0313 - acc: 0.9896\n",
            "Epoch 26/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.0296 - acc: 0.9899\n",
            "Epoch 27/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0291 - acc: 0.9904\n",
            "Epoch 28/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0287 - acc: 0.9902\n",
            "Epoch 29/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.0304 - acc: 0.9899\n",
            "Epoch 30/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.0318 - acc: 0.9902\n",
            "Precision = 91.51, Recall = 89.98, F1 = 90.74\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4Sar4pzoeSru"
      },
      "source": [
        "**Experiment with a window size of 7 using both future and past context words**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Icr4Ix71Y-Lx",
        "colab_type": "code",
        "outputId": "ffa1e0ec-38fc-43b1-a0d5-b72d9d575859",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# past and future context of 7, kernel of 3\n",
        "context_size = 7\n",
        "kernel_size = 3\n",
        "cnn_input, cnn_labels = get_past_and_future_window(train_x, train_label, context_size)\n",
        "val_input, val_labels = get_past_and_future_window(val_x, val_label, context_size)\n",
        "model = get_conv_model(context_size, kernel_size)\n",
        "model.fit(cnn_input, cnn_labels, epochs=30)\n",
        "print_evaluation(model, val_input, val_labels, val_x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_28\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_28 (Embedding)     (None, 7, 100)            57300     \n",
            "_________________________________________________________________\n",
            "conv1d_28 (Conv1D)           (None, 7, 100)            30100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_28 (MaxPooling (None, 3, 100)            0         \n",
            "_________________________________________________________________\n",
            "dropout_28 (Dropout)         (None, 3, 100)            0         \n",
            "_________________________________________________________________\n",
            "flatten_28 (Flatten)         (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dense_55 (Dense)             (None, 128)               38528     \n",
            "_________________________________________________________________\n",
            "dense_56 (Dense)             (None, 127)               16383     \n",
            "=================================================================\n",
            "Total params: 142,311\n",
            "Trainable params: 142,311\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "56590/56590 [==============================] - 13s 228us/step - loss: 0.5053 - acc: 0.8955\n",
            "Epoch 2/30\n",
            "56590/56590 [==============================] - 10s 180us/step - loss: 0.1256 - acc: 0.9692\n",
            "Epoch 3/30\n",
            "56590/56590 [==============================] - 10s 181us/step - loss: 0.0797 - acc: 0.9786\n",
            "Epoch 4/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.0598 - acc: 0.9828\n",
            "Epoch 5/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0519 - acc: 0.9843\n",
            "Epoch 6/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0447 - acc: 0.9862\n",
            "Epoch 7/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0407 - acc: 0.9865\n",
            "Epoch 8/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0366 - acc: 0.9880\n",
            "Epoch 9/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.0335 - acc: 0.9890\n",
            "Epoch 10/30\n",
            "56590/56590 [==============================] - 10s 181us/step - loss: 0.0315 - acc: 0.9895\n",
            "Epoch 11/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0291 - acc: 0.9904\n",
            "Epoch 12/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.0303 - acc: 0.9901\n",
            "Epoch 13/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.0274 - acc: 0.9909\n",
            "Epoch 14/30\n",
            "56590/56590 [==============================] - 11s 191us/step - loss: 0.0264 - acc: 0.9917\n",
            "Epoch 15/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.0256 - acc: 0.9914\n",
            "Epoch 16/30\n",
            "56590/56590 [==============================] - 10s 182us/step - loss: 0.0255 - acc: 0.9919\n",
            "Epoch 17/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.0232 - acc: 0.9921\n",
            "Epoch 18/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.0237 - acc: 0.9919\n",
            "Epoch 19/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0215 - acc: 0.9923\n",
            "Epoch 20/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.0243 - acc: 0.9922\n",
            "Epoch 21/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.0220 - acc: 0.9927\n",
            "Epoch 22/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0227 - acc: 0.9924\n",
            "Epoch 23/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.0232 - acc: 0.9924\n",
            "Epoch 24/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.0208 - acc: 0.9931\n",
            "Epoch 25/30\n",
            "56590/56590 [==============================] - 10s 180us/step - loss: 0.0211 - acc: 0.9931\n",
            "Epoch 26/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.0212 - acc: 0.9927\n",
            "Epoch 27/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0205 - acc: 0.9933\n",
            "Epoch 28/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.0221 - acc: 0.9927\n",
            "Epoch 29/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.0224 - acc: 0.9931\n",
            "Epoch 30/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0218 - acc: 0.9931\n",
            "Precision = 92.99, Recall = 92.17, F1 = 92.58\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmpYLGOWd0h-",
        "colab_type": "code",
        "outputId": "aceb3741-09c9-4439-ae65-3014e136f1fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# past and future context of 7, kernel of 5\n",
        "context_size = 7\n",
        "kernel_size = 5\n",
        "cnn_input, cnn_labels = get_past_and_future_window(train_x, train_label, context_size)\n",
        "val_input, val_labels = get_past_and_future_window(val_x, val_label, context_size)\n",
        "model = get_conv_model(context_size, kernel_size)\n",
        "model.fit(cnn_input, cnn_labels, epochs=30)\n",
        "print_evaluation(model, val_input, val_labels, val_x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_29\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_29 (Embedding)     (None, 7, 100)            57300     \n",
            "_________________________________________________________________\n",
            "conv1d_29 (Conv1D)           (None, 7, 100)            50100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_29 (MaxPooling (None, 3, 100)            0         \n",
            "_________________________________________________________________\n",
            "dropout_29 (Dropout)         (None, 3, 100)            0         \n",
            "_________________________________________________________________\n",
            "flatten_29 (Flatten)         (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dense_57 (Dense)             (None, 128)               38528     \n",
            "_________________________________________________________________\n",
            "dense_58 (Dense)             (None, 127)               16383     \n",
            "=================================================================\n",
            "Total params: 162,311\n",
            "Trainable params: 162,311\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "56590/56590 [==============================] - 13s 236us/step - loss: 0.4915 - acc: 0.8974\n",
            "Epoch 2/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.1161 - acc: 0.9707\n",
            "Epoch 3/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.0737 - acc: 0.9796\n",
            "Epoch 4/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0567 - acc: 0.9837\n",
            "Epoch 5/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0462 - acc: 0.9859\n",
            "Epoch 6/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0405 - acc: 0.9874\n",
            "Epoch 7/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0369 - acc: 0.9881\n",
            "Epoch 8/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.0330 - acc: 0.9896\n",
            "Epoch 9/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0296 - acc: 0.9906\n",
            "Epoch 10/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.0287 - acc: 0.9909\n",
            "Epoch 11/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.0276 - acc: 0.9911\n",
            "Epoch 12/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.0271 - acc: 0.9915\n",
            "Epoch 13/30\n",
            "56590/56590 [==============================] - 11s 193us/step - loss: 0.0267 - acc: 0.9916\n",
            "Epoch 14/30\n",
            "56590/56590 [==============================] - 11s 195us/step - loss: 0.0238 - acc: 0.9926\n",
            "Epoch 15/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0231 - acc: 0.9925\n",
            "Epoch 16/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0230 - acc: 0.9927\n",
            "Epoch 17/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0226 - acc: 0.9927\n",
            "Epoch 18/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0217 - acc: 0.9933\n",
            "Epoch 19/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0214 - acc: 0.9934\n",
            "Epoch 20/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0237 - acc: 0.9928\n",
            "Epoch 21/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.0214 - acc: 0.9935\n",
            "Epoch 22/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0210 - acc: 0.9935\n",
            "Epoch 23/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0194 - acc: 0.9941\n",
            "Epoch 24/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.0208 - acc: 0.9937\n",
            "Epoch 25/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0213 - acc: 0.9937\n",
            "Epoch 26/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0211 - acc: 0.9937\n",
            "Epoch 27/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.0212 - acc: 0.9938\n",
            "Epoch 28/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.0230 - acc: 0.9936\n",
            "Epoch 29/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0206 - acc: 0.9939\n",
            "Epoch 30/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.0205 - acc: 0.9941\n",
            "Precision = 92.28, Recall = 91.73, F1 = 92.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0C5FOm1d0oZ",
        "colab_type": "code",
        "outputId": "4a9d3c54-74f1-4188-a9ad-4648afd9f0f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# past and future context of 7, kernel of 7\n",
        "context_size = 7\n",
        "kernel_size = 7\n",
        "cnn_input, cnn_labels = get_past_and_future_window(train_x, train_label, context_size)\n",
        "val_input, val_labels = get_past_and_future_window(val_x, val_label, context_size)\n",
        "model = get_conv_model(context_size, kernel_size)\n",
        "model.fit(cnn_input, cnn_labels, epochs=30)\n",
        "print_evaluation(model, val_input, val_labels, val_x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_30\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_30 (Embedding)     (None, 7, 100)            57300     \n",
            "_________________________________________________________________\n",
            "conv1d_30 (Conv1D)           (None, 7, 100)            70100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_30 (MaxPooling (None, 3, 100)            0         \n",
            "_________________________________________________________________\n",
            "dropout_30 (Dropout)         (None, 3, 100)            0         \n",
            "_________________________________________________________________\n",
            "flatten_30 (Flatten)         (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dense_59 (Dense)             (None, 128)               38528     \n",
            "_________________________________________________________________\n",
            "dense_60 (Dense)             (None, 127)               16383     \n",
            "=================================================================\n",
            "Total params: 182,311\n",
            "Trainable params: 182,311\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "56590/56590 [==============================] - 13s 234us/step - loss: 0.4736 - acc: 0.9020\n",
            "Epoch 2/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.1075 - acc: 0.9723\n",
            "Epoch 3/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0678 - acc: 0.9808\n",
            "Epoch 4/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0533 - acc: 0.9840\n",
            "Epoch 5/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0440 - acc: 0.9876\n",
            "Epoch 6/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0371 - acc: 0.9884\n",
            "Epoch 7/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.0348 - acc: 0.9893\n",
            "Epoch 8/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0307 - acc: 0.9904\n",
            "Epoch 9/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.0285 - acc: 0.9913\n",
            "Epoch 10/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.0294 - acc: 0.9909\n",
            "Epoch 11/30\n",
            "56590/56590 [==============================] - 11s 194us/step - loss: 0.0252 - acc: 0.9921\n",
            "Epoch 12/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.0252 - acc: 0.9923\n",
            "Epoch 13/30\n",
            "56590/56590 [==============================] - 11s 191us/step - loss: 0.0232 - acc: 0.9929\n",
            "Epoch 14/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.0233 - acc: 0.9929\n",
            "Epoch 15/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.0230 - acc: 0.9926\n",
            "Epoch 16/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0228 - acc: 0.9932\n",
            "Epoch 17/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0227 - acc: 0.9933\n",
            "Epoch 18/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0206 - acc: 0.9940\n",
            "Epoch 19/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.0223 - acc: 0.9933\n",
            "Epoch 20/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.0220 - acc: 0.9935\n",
            "Epoch 21/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.0204 - acc: 0.9940\n",
            "Epoch 22/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.0223 - acc: 0.9933\n",
            "Epoch 23/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0198 - acc: 0.9943\n",
            "Epoch 24/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.0209 - acc: 0.9943\n",
            "Epoch 25/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0193 - acc: 0.9944\n",
            "Epoch 26/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.0200 - acc: 0.9942\n",
            "Epoch 27/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0210 - acc: 0.9941\n",
            "Epoch 28/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.0192 - acc: 0.9943\n",
            "Epoch 29/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0190 - acc: 0.9945\n",
            "Epoch 30/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.0199 - acc: 0.9943\n",
            "Precision = 92.56, Recall = 91.95, F1 = 92.25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nBfVXaKCeU2W"
      },
      "source": [
        "**Experiment with a window size of 9 using both future and past context words**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGdnLITXd0vE",
        "colab_type": "code",
        "outputId": "36f77ecb-b3f0-4a42-f385-66d97caebfee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# past and future context of 9, kernel of 3\n",
        "context_size = 9\n",
        "kernel_size = 3\n",
        "cnn_input, cnn_labels = get_past_and_future_window(train_x, train_label, context_size)\n",
        "val_input, val_labels = get_past_and_future_window(val_x, val_label, context_size)\n",
        "model = get_conv_model(context_size, kernel_size)\n",
        "model.fit(cnn_input, cnn_labels, epochs=30)\n",
        "print_evaluation(model, val_input, val_labels, val_x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_31\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_31 (Embedding)     (None, 9, 100)            57300     \n",
            "_________________________________________________________________\n",
            "conv1d_31 (Conv1D)           (None, 9, 100)            30100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_31 (MaxPooling (None, 4, 100)            0         \n",
            "_________________________________________________________________\n",
            "dropout_31 (Dropout)         (None, 4, 100)            0         \n",
            "_________________________________________________________________\n",
            "flatten_31 (Flatten)         (None, 400)               0         \n",
            "_________________________________________________________________\n",
            "dense_61 (Dense)             (None, 128)               51328     \n",
            "_________________________________________________________________\n",
            "dense_62 (Dense)             (None, 127)               16383     \n",
            "=================================================================\n",
            "Total params: 155,111\n",
            "Trainable params: 155,111\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "56590/56590 [==============================] - 13s 236us/step - loss: 0.5258 - acc: 0.8884\n",
            "Epoch 2/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.1252 - acc: 0.9688\n",
            "Epoch 3/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.0750 - acc: 0.9791\n",
            "Epoch 4/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0564 - acc: 0.9839\n",
            "Epoch 5/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.0472 - acc: 0.9863\n",
            "Epoch 6/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.0399 - acc: 0.9885\n",
            "Epoch 7/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0350 - acc: 0.9894\n",
            "Epoch 8/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.0323 - acc: 0.9903\n",
            "Epoch 9/30\n",
            "56590/56590 [==============================] - 11s 192us/step - loss: 0.0312 - acc: 0.9905\n",
            "Epoch 10/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.0292 - acc: 0.9909\n",
            "Epoch 11/30\n",
            "56590/56590 [==============================] - 11s 194us/step - loss: 0.0277 - acc: 0.9916\n",
            "Epoch 12/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.0245 - acc: 0.9920\n",
            "Epoch 13/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0250 - acc: 0.9923\n",
            "Epoch 14/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.0224 - acc: 0.9930\n",
            "Epoch 15/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0249 - acc: 0.9917\n",
            "Epoch 16/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0222 - acc: 0.9931\n",
            "Epoch 17/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0213 - acc: 0.9935\n",
            "Epoch 18/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0220 - acc: 0.9934\n",
            "Epoch 19/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0192 - acc: 0.9938\n",
            "Epoch 20/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0214 - acc: 0.9939\n",
            "Epoch 21/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0201 - acc: 0.9942\n",
            "Epoch 22/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.0197 - acc: 0.9941\n",
            "Epoch 23/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.0215 - acc: 0.9933\n",
            "Epoch 24/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0193 - acc: 0.9943\n",
            "Epoch 25/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0199 - acc: 0.9946\n",
            "Epoch 26/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0193 - acc: 0.9945\n",
            "Epoch 27/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0219 - acc: 0.9941\n",
            "Epoch 28/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.0194 - acc: 0.9946\n",
            "Epoch 29/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0190 - acc: 0.9948\n",
            "Epoch 30/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0196 - acc: 0.9943\n",
            "Precision = 93.48, Recall = 93.12, F1 = 93.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Nr00Y-9Y-IS",
        "colab_type": "code",
        "outputId": "df81a3e2-c02f-43c1-9f60-8f29b8dd45bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# past and future context of 9, kernel of 5\n",
        "context_size = 9\n",
        "kernel_size = 5\n",
        "cnn_input, cnn_labels = get_past_and_future_window(train_x, train_label, context_size)\n",
        "val_input, val_labels = get_past_and_future_window(val_x, val_label, context_size)\n",
        "model = get_conv_model(context_size, kernel_size)\n",
        "model.fit(cnn_input, cnn_labels, epochs=30)\n",
        "print_evaluation(model, val_input, val_labels, val_x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_32\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_32 (Embedding)     (None, 9, 100)            57300     \n",
            "_________________________________________________________________\n",
            "conv1d_32 (Conv1D)           (None, 9, 100)            50100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_32 (MaxPooling (None, 4, 100)            0         \n",
            "_________________________________________________________________\n",
            "dropout_32 (Dropout)         (None, 4, 100)            0         \n",
            "_________________________________________________________________\n",
            "flatten_32 (Flatten)         (None, 400)               0         \n",
            "_________________________________________________________________\n",
            "dense_63 (Dense)             (None, 128)               51328     \n",
            "_________________________________________________________________\n",
            "dense_64 (Dense)             (None, 127)               16383     \n",
            "=================================================================\n",
            "Total params: 175,111\n",
            "Trainable params: 175,111\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "56590/56590 [==============================] - 14s 242us/step - loss: 0.5098 - acc: 0.8930\n",
            "Epoch 2/30\n",
            "56590/56590 [==============================] - 11s 191us/step - loss: 0.1234 - acc: 0.9689\n",
            "Epoch 3/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0722 - acc: 0.9810\n",
            "Epoch 4/30\n",
            "56590/56590 [==============================] - 11s 194us/step - loss: 0.0534 - acc: 0.9841\n",
            "Epoch 5/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.0423 - acc: 0.9872\n",
            "Epoch 6/30\n",
            "56590/56590 [==============================] - 11s 191us/step - loss: 0.0350 - acc: 0.9889\n",
            "Epoch 7/30\n",
            "56590/56590 [==============================] - 11s 191us/step - loss: 0.0319 - acc: 0.9900\n",
            "Epoch 8/30\n",
            "56590/56590 [==============================] - 11s 191us/step - loss: 0.0277 - acc: 0.9912\n",
            "Epoch 9/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.0257 - acc: 0.9922\n",
            "Epoch 10/30\n",
            "56590/56590 [==============================] - 11s 195us/step - loss: 0.0256 - acc: 0.9920\n",
            "Epoch 11/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.0246 - acc: 0.9925\n",
            "Epoch 12/30\n",
            "56590/56590 [==============================] - 11s 191us/step - loss: 0.0223 - acc: 0.9936\n",
            "Epoch 13/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.0195 - acc: 0.9937\n",
            "Epoch 14/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.0211 - acc: 0.9936\n",
            "Epoch 15/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.0203 - acc: 0.9939\n",
            "Epoch 16/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.0181 - acc: 0.9945\n",
            "Epoch 17/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.0204 - acc: 0.9937\n",
            "Epoch 18/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.0191 - acc: 0.9943\n",
            "Epoch 19/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.0192 - acc: 0.9944\n",
            "Epoch 20/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.0181 - acc: 0.9950\n",
            "Epoch 21/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.0188 - acc: 0.9943\n",
            "Epoch 22/30\n",
            "56590/56590 [==============================] - 11s 192us/step - loss: 0.0175 - acc: 0.9949\n",
            "Epoch 23/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.0177 - acc: 0.9951\n",
            "Epoch 24/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.0180 - acc: 0.9948\n",
            "Epoch 25/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.0198 - acc: 0.9944\n",
            "Epoch 26/30\n",
            "56590/56590 [==============================] - 11s 191us/step - loss: 0.0167 - acc: 0.9956\n",
            "Epoch 27/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.0184 - acc: 0.9952\n",
            "Epoch 28/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.0186 - acc: 0.9951\n",
            "Epoch 29/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.0188 - acc: 0.9950\n",
            "Epoch 30/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0181 - acc: 0.9949\n",
            "Precision = 92.67, Recall = 92.6, F1 = 92.64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMIitcgsY-Fm",
        "colab_type": "code",
        "outputId": "cfeb55ba-49a2-4051-8eb0-6ab0d3b3c8f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# past and future context of 9, kernel of 7\n",
        "context_size = 9\n",
        "kernel_size = 7\n",
        "cnn_input, cnn_labels = get_past_and_future_window(train_x, train_label, context_size)\n",
        "val_input, val_labels = get_past_and_future_window(val_x, val_label, context_size)\n",
        "model = get_conv_model(context_size, kernel_size)\n",
        "model.fit(cnn_input, cnn_labels, epochs=30)\n",
        "print_evaluation(model, val_input, val_labels, val_x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_33\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_33 (Embedding)     (None, 9, 100)            57300     \n",
            "_________________________________________________________________\n",
            "conv1d_33 (Conv1D)           (None, 9, 100)            70100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_33 (MaxPooling (None, 4, 100)            0         \n",
            "_________________________________________________________________\n",
            "dropout_33 (Dropout)         (None, 4, 100)            0         \n",
            "_________________________________________________________________\n",
            "flatten_33 (Flatten)         (None, 400)               0         \n",
            "_________________________________________________________________\n",
            "dense_65 (Dense)             (None, 128)               51328     \n",
            "_________________________________________________________________\n",
            "dense_66 (Dense)             (None, 127)               16383     \n",
            "=================================================================\n",
            "Total params: 195,111\n",
            "Trainable params: 195,111\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "56590/56590 [==============================] - 14s 247us/step - loss: 0.4872 - acc: 0.8988\n",
            "Epoch 2/30\n",
            "56590/56590 [==============================] - 11s 192us/step - loss: 0.1085 - acc: 0.9739\n",
            "Epoch 3/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.0642 - acc: 0.9830\n",
            "Epoch 4/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.0486 - acc: 0.9858\n",
            "Epoch 5/30\n",
            "56590/56590 [==============================] - 11s 199us/step - loss: 0.0374 - acc: 0.9887\n",
            "Epoch 6/30\n",
            "56590/56590 [==============================] - 11s 191us/step - loss: 0.0314 - acc: 0.9906\n",
            "Epoch 7/30\n",
            "56590/56590 [==============================] - 11s 191us/step - loss: 0.0299 - acc: 0.9908\n",
            "Epoch 8/30\n",
            "56590/56590 [==============================] - 11s 196us/step - loss: 0.0250 - acc: 0.9926\n",
            "Epoch 9/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.0255 - acc: 0.9920\n",
            "Epoch 10/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.0227 - acc: 0.9931\n",
            "Epoch 11/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.0205 - acc: 0.9937\n",
            "Epoch 12/30\n",
            "56590/56590 [==============================] - 11s 192us/step - loss: 0.0201 - acc: 0.9940\n",
            "Epoch 13/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.0199 - acc: 0.9942\n",
            "Epoch 14/30\n",
            "56590/56590 [==============================] - 11s 192us/step - loss: 0.0194 - acc: 0.9946\n",
            "Epoch 15/30\n",
            "56590/56590 [==============================] - 11s 191us/step - loss: 0.0176 - acc: 0.9947\n",
            "Epoch 16/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.0187 - acc: 0.9947\n",
            "Epoch 17/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.0191 - acc: 0.9945\n",
            "Epoch 18/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.0161 - acc: 0.9954\n",
            "Epoch 19/30\n",
            "56590/56590 [==============================] - 11s 192us/step - loss: 0.0171 - acc: 0.9949\n",
            "Epoch 20/30\n",
            "56590/56590 [==============================] - 11s 192us/step - loss: 0.0166 - acc: 0.9954\n",
            "Epoch 21/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.0170 - acc: 0.9956\n",
            "Epoch 22/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.0182 - acc: 0.9948\n",
            "Epoch 23/30\n",
            "56590/56590 [==============================] - 11s 194us/step - loss: 0.0153 - acc: 0.9960\n",
            "Epoch 24/30\n",
            "56590/56590 [==============================] - 11s 193us/step - loss: 0.0168 - acc: 0.9953\n",
            "Epoch 25/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.0166 - acc: 0.9955\n",
            "Epoch 26/30\n",
            "56590/56590 [==============================] - 11s 192us/step - loss: 0.0184 - acc: 0.9953\n",
            "Epoch 27/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.0165 - acc: 0.9955\n",
            "Epoch 28/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0170 - acc: 0.9957\n",
            "Epoch 29/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.0185 - acc: 0.9952\n",
            "Epoch 30/30\n",
            "56590/56590 [==============================] - 11s 191us/step - loss: 0.0161 - acc: 0.9960\n",
            "Precision = 92.77, Recall = 92.35, F1 = 92.56\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kq1d-m4TeJJk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Glove embedding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkfNJHxyeJPh",
        "colab_type": "code",
        "outputId": "80059d44-9489-405d-b48e-2552d28965c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "#Download Glove\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-17 05:23:28--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2019-11-17 05:23:28--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2019-11-17 05:23:29--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  2.18MB/s    in 6m 30s  \n",
            "\n",
            "2019-11-17 05:29:59 (2.11 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxRrpKvCyqUa",
        "colab_type": "code",
        "outputId": "5c9c2d0b-2ae7-4809-9507-24adf10eaa29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!unzip glove*.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrv8EKxaeKAz",
        "colab_type": "code",
        "outputId": "3ffcd2af-ae7a-4977-a796-ef316eae326a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# load the whole embedding into memory\n",
        "embeddings_index = dict()\n",
        "f = open('glove.6B.100d.txt')\n",
        "for line in f:\n",
        "\tvalues = line.split()\n",
        "\tword = values[0]\n",
        "\tcoefs = np.array([float(val) for val in values[1:]])\n",
        "\tembeddings_index[word] = coefs\n",
        "f.close()\n",
        "print('Loaded %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EBCK03ReJGA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preparePastCNNGloveInput(sentences_list, window_size, labels, glove_model):\n",
        "  cnn_input = []\n",
        "  cnn_labels = []\n",
        "  for sentence in sentences_list:\n",
        "    #prepend a pad word to the beginning of the sentence\n",
        "    sentence = ['padding'] * (window_size - 1) + sentence\n",
        "    #Now for each word, take the (window_size - 1) previous words and itself, and form an embedding representation of each word\n",
        "    for i in range(window_size - 1, len(sentence)):\n",
        "      words_list = sentence[i-window_size+1:i+1]\n",
        "      embedding = np.zeros(shape=(window_size,100))\n",
        "      for j in range(window_size):\n",
        "        if words_list[j] in glove_model:\n",
        "          embedding[j, :] = glove_model[words_list[j]]\n",
        "      cnn_input.append(embedding)\n",
        "\n",
        "  for label in labels:\n",
        "    for temp in label:\n",
        "      cnn_labels.append(temp)\n",
        "  return np.asarray(cnn_input), np.asarray(cnn_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEB7uuD2eJCG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepareFutureCNNGloveInput(sentences_list, window_size, labels, glove_model):\n",
        "  cnn_input = []\n",
        "  cnn_labels = []\n",
        "  for sentence in sentences_list:\n",
        "    #prepend a pad word to the beginning of the sentence\n",
        "    sentence =  sentence + ['padding'] * (window_size - 1)\n",
        "    #Now for each word, take the (window_size - 1) previous words and itself, and form an embedding representation of each word\n",
        "    for i in range(0, len(sentence) - (window_size) + 1):\n",
        "      words_list = sentence[i:i+window_size]\n",
        "      embedding = np.zeros(shape=(window_size,100))\n",
        "      for j in range(window_size):\n",
        "        if words_list[j] in glove_model:\n",
        "          embedding[j, :] = glove_model[words_list[j]]\n",
        "      cnn_input.append(embedding)\n",
        "\n",
        "  for label in labels:\n",
        "    for temp in label:\n",
        "      cnn_labels.append(temp)\n",
        "  return np.asarray(cnn_input), np.asarray(cnn_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pw2BnWEm32hV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preparePastFutureCNNGloveInput(sentences_list, window_size, labels, glove_model):\n",
        "  cnn_input = []\n",
        "  cnn_labels = []\n",
        "  half_size = int(window_size/2);\n",
        "  for sentence in sentences_list:\n",
        "    #prepend a pad word to the beginning of the sentence\n",
        "    sentence =  ['padding'] * (half_size) + sentence + ['padding'] * (half_size)\n",
        "    #Now for each word, take the (window_size - 1) previous words and itself, and form an embedding representation of each word\n",
        "    for i in range(half_size, len(sentence) - half_size):\n",
        "      words_list = sentence[i-half_size:i+half_size+1]\n",
        "      embedding = np.zeros(shape=(window_size,100))\n",
        "      for j in range(window_size):\n",
        "        if words_list[j] in glove_model:\n",
        "          embedding[j, :] = glove_model[words_list[j]]\n",
        "      cnn_input.append(embedding)\n",
        "\n",
        "  for label in labels:\n",
        "    for temp in label:\n",
        "      cnn_labels.append(temp)\n",
        "  return np.asarray(cnn_input), np.asarray(cnn_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xns_nuUx32rN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10m_5QFinTMv",
        "colab_type": "code",
        "outputId": "32ba3ab7-d284-46b2-e293-a18bd45d739d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "def replaceDigits(words):\n",
        "  digits_list = ['DIGITDIGITDIGIT', 'DIGITDIGITDIGITDIGIT', 'DIGITDIGIT', 'DIGIT']\n",
        "  words_train_new = []\n",
        "  for sentence in words:\n",
        "    sentence_new = [word if word not in digits_list else 'time' for word in sentence]\n",
        "    words_train_new.append(sentence_new)\n",
        "  return words_train_new\n",
        "\n",
        "########### Replacing all possible digit combinations with a word 'time' ############\n",
        "words_train = replaceDigits(words_train)\n",
        "words_val = replaceDigits(words_val)\n",
        "\n",
        "print(len(words_train))\n",
        "print(len(words_val))\n",
        "print(words_train[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4978\n",
            "893\n",
            "['i', 'want', 'to', 'fly', 'from', 'boston', 'at', 'time', 'am', 'and', 'arrive', 'in', 'denver', 'at', 'time', 'in', 'the', 'morning']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqgxpZ433cvu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import layers\n",
        "from keras.models import Sequential, Model\n",
        "\n",
        "def get_glove_model(window_size, kernelsize=3):\n",
        "    input_tensor = layers.Input(shape=(window_size,100))\n",
        "    x = Conv1D(100, kernel_size=kernelsize, activation='relu', padding=\"same\") (input_tensor)\n",
        "    x = MaxPooling1D(pool_size=2)(x)\n",
        "    x = Dropout(0.25)(x)\n",
        "    x = Flatten() (x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dense(n_classes, activation='softmax')(x)   \n",
        "    optim = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
        "    model = Model([input_tensor], x)\n",
        "    model.compile(loss='sparse_categorical_crossentropy', optimizer=optim, metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rezXUn3c-5l9"
      },
      "source": [
        "**Experiment with a window size of 3 using the past context words and glove embedding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSOaj3673dAp",
        "colab_type": "code",
        "outputId": "f062c6d6-be6d-4e55-caea-d9e82b8bf985",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# past context of 3, kernel of 3\n",
        "context_size = 3\n",
        "kernel_size = 3\n",
        "cnn_input, cnn_labels = preparePastCNNGloveInput(words_train, context_size, train_label, embeddings_index)\n",
        "val_input, val_labels = preparePastCNNGloveInput(words_val, context_size, val_label, embeddings_index)\n",
        "model = get_glove_model(context_size, kernel_size)\n",
        "model.fit(cnn_input, cnn_labels, epochs=30)\n",
        "print_evaluation(model, val_input, val_labels, val_x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         (None, 3, 100)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_38 (Conv1D)           (None, 3, 100)            30100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_38 (MaxPooling (None, 1, 100)            0         \n",
            "_________________________________________________________________\n",
            "dropout_38 (Dropout)         (None, 1, 100)            0         \n",
            "_________________________________________________________________\n",
            "flatten_38 (Flatten)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_75 (Dense)             (None, 128)               12928     \n",
            "_________________________________________________________________\n",
            "dense_76 (Dense)             (None, 127)               16383     \n",
            "=================================================================\n",
            "Total params: 59,411\n",
            "Trainable params: 59,411\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "56590/56590 [==============================] - 13s 229us/step - loss: 0.4368 - acc: 0.9054\n",
            "Epoch 2/30\n",
            "56590/56590 [==============================] - 10s 171us/step - loss: 0.1728 - acc: 0.9546\n",
            "Epoch 3/30\n",
            "56590/56590 [==============================] - 10s 171us/step - loss: 0.1380 - acc: 0.9609\n",
            "Epoch 4/30\n",
            "56590/56590 [==============================] - 10s 175us/step - loss: 0.1223 - acc: 0.9653\n",
            "Epoch 5/30\n",
            "56590/56590 [==============================] - 10s 179us/step - loss: 0.1096 - acc: 0.9670\n",
            "Epoch 6/30\n",
            "56590/56590 [==============================] - 10s 175us/step - loss: 0.1030 - acc: 0.9687\n",
            "Epoch 7/30\n",
            "56590/56590 [==============================] - 10s 172us/step - loss: 0.0968 - acc: 0.9693\n",
            "Epoch 8/30\n",
            "56590/56590 [==============================] - 10s 171us/step - loss: 0.0923 - acc: 0.9710\n",
            "Epoch 9/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.0914 - acc: 0.9713\n",
            "Epoch 10/30\n",
            "56590/56590 [==============================] - 10s 176us/step - loss: 0.0862 - acc: 0.9726\n",
            "Epoch 11/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.0836 - acc: 0.9735\n",
            "Epoch 12/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.0832 - acc: 0.9731\n",
            "Epoch 13/30\n",
            "56590/56590 [==============================] - 10s 175us/step - loss: 0.0805 - acc: 0.9740\n",
            "Epoch 14/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.0778 - acc: 0.9741\n",
            "Epoch 15/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.0769 - acc: 0.9746\n",
            "Epoch 16/30\n",
            "56590/56590 [==============================] - 10s 173us/step - loss: 0.0749 - acc: 0.9751\n",
            "Epoch 17/30\n",
            "56590/56590 [==============================] - 10s 173us/step - loss: 0.0757 - acc: 0.9746\n",
            "Epoch 18/30\n",
            "56590/56590 [==============================] - 10s 176us/step - loss: 0.0746 - acc: 0.9753\n",
            "Epoch 19/30\n",
            "56590/56590 [==============================] - 10s 173us/step - loss: 0.0730 - acc: 0.9753\n",
            "Epoch 20/30\n",
            "56590/56590 [==============================] - 10s 175us/step - loss: 0.0719 - acc: 0.9763\n",
            "Epoch 21/30\n",
            "56590/56590 [==============================] - 10s 176us/step - loss: 0.0730 - acc: 0.9748\n",
            "Epoch 22/30\n",
            "56590/56590 [==============================] - 10s 175us/step - loss: 0.0703 - acc: 0.9770\n",
            "Epoch 23/30\n",
            "56590/56590 [==============================] - 10s 175us/step - loss: 0.0679 - acc: 0.9771\n",
            "Epoch 24/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.0694 - acc: 0.9767\n",
            "Epoch 25/30\n",
            "56590/56590 [==============================] - 10s 175us/step - loss: 0.0699 - acc: 0.9773\n",
            "Epoch 26/30\n",
            "56590/56590 [==============================] - 10s 176us/step - loss: 0.0666 - acc: 0.9772\n",
            "Epoch 27/30\n",
            "56590/56590 [==============================] - 10s 179us/step - loss: 0.0692 - acc: 0.9766\n",
            "Epoch 28/30\n",
            "56590/56590 [==============================] - 10s 175us/step - loss: 0.0667 - acc: 0.9776\n",
            "Epoch 29/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.0681 - acc: 0.9771\n",
            "Epoch 30/30\n",
            "56590/56590 [==============================] - 10s 176us/step - loss: 0.0684 - acc: 0.9768\n",
            "Precision = 89.07, Recall = 85.55, F1 = 87.27\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "A_jvYCPm_5pY"
      },
      "source": [
        "**Experiment with a window size of 5 using the past context words and glove embedding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVCDrrPf_S7H",
        "colab_type": "code",
        "outputId": "d303a6f8-760a-4291-bab2-5fc8cd562684",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# past context of 5, kernel of 3\n",
        "context_size = 5\n",
        "kernel_size = 3\n",
        "cnn_input, cnn_labels = preparePastCNNGloveInput(words_train, context_size, train_label, embeddings_index)\n",
        "val_input, val_labels = preparePastCNNGloveInput(words_val, context_size, val_label, embeddings_index)\n",
        "model = get_glove_model(context_size, kernel_size)\n",
        "model.fit(cnn_input, cnn_labels, epochs=30)\n",
        "print_evaluation(model, val_input, val_labels, val_x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         (None, 5, 100)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_39 (Conv1D)           (None, 5, 100)            30100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_39 (MaxPooling (None, 2, 100)            0         \n",
            "_________________________________________________________________\n",
            "dropout_39 (Dropout)         (None, 2, 100)            0         \n",
            "_________________________________________________________________\n",
            "flatten_39 (Flatten)         (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_77 (Dense)             (None, 128)               25728     \n",
            "_________________________________________________________________\n",
            "dense_78 (Dense)             (None, 127)               16383     \n",
            "=================================================================\n",
            "Total params: 72,211\n",
            "Trainable params: 72,211\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "56590/56590 [==============================] - 14s 243us/step - loss: 0.5524 - acc: 0.8813\n",
            "Epoch 2/30\n",
            "56590/56590 [==============================] - 10s 179us/step - loss: 0.2099 - acc: 0.9462\n",
            "Epoch 3/30\n",
            "56590/56590 [==============================] - 10s 178us/step - loss: 0.1543 - acc: 0.9591\n",
            "Epoch 4/30\n",
            "56590/56590 [==============================] - 10s 178us/step - loss: 0.1250 - acc: 0.9656\n",
            "Epoch 5/30\n",
            "56590/56590 [==============================] - 10s 180us/step - loss: 0.1080 - acc: 0.9693\n",
            "Epoch 6/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.0978 - acc: 0.9717\n",
            "Epoch 7/30\n",
            "56590/56590 [==============================] - 10s 177us/step - loss: 0.0897 - acc: 0.9735\n",
            "Epoch 8/30\n",
            "56590/56590 [==============================] - 10s 178us/step - loss: 0.0840 - acc: 0.9757\n",
            "Epoch 9/30\n",
            "56590/56590 [==============================] - 10s 179us/step - loss: 0.0788 - acc: 0.9768\n",
            "Epoch 10/30\n",
            "56590/56590 [==============================] - 10s 176us/step - loss: 0.0734 - acc: 0.9776\n",
            "Epoch 11/30\n",
            "56590/56590 [==============================] - 10s 180us/step - loss: 0.0705 - acc: 0.9787\n",
            "Epoch 12/30\n",
            "56590/56590 [==============================] - 10s 178us/step - loss: 0.0685 - acc: 0.9789\n",
            "Epoch 13/30\n",
            "56590/56590 [==============================] - 10s 179us/step - loss: 0.0656 - acc: 0.9803\n",
            "Epoch 14/30\n",
            "56590/56590 [==============================] - 10s 178us/step - loss: 0.0587 - acc: 0.9813\n",
            "Epoch 15/30\n",
            "56590/56590 [==============================] - 10s 174us/step - loss: 0.0621 - acc: 0.9814\n",
            "Epoch 16/30\n",
            "56590/56590 [==============================] - 10s 179us/step - loss: 0.0594 - acc: 0.9818\n",
            "Epoch 17/30\n",
            "56590/56590 [==============================] - 10s 180us/step - loss: 0.0594 - acc: 0.9819\n",
            "Epoch 18/30\n",
            "56590/56590 [==============================] - 10s 179us/step - loss: 0.0570 - acc: 0.9828\n",
            "Epoch 19/30\n",
            "56590/56590 [==============================] - 10s 177us/step - loss: 0.0577 - acc: 0.9824\n",
            "Epoch 20/30\n",
            "56590/56590 [==============================] - 10s 179us/step - loss: 0.0570 - acc: 0.9831\n",
            "Epoch 21/30\n",
            "56590/56590 [==============================] - 10s 178us/step - loss: 0.0576 - acc: 0.9825\n",
            "Epoch 22/30\n",
            "56590/56590 [==============================] - 10s 177us/step - loss: 0.0521 - acc: 0.9835\n",
            "Epoch 23/30\n",
            "56590/56590 [==============================] - 10s 178us/step - loss: 0.0526 - acc: 0.9837\n",
            "Epoch 24/30\n",
            "56590/56590 [==============================] - 10s 176us/step - loss: 0.0542 - acc: 0.9834\n",
            "Epoch 25/30\n",
            "56590/56590 [==============================] - 10s 180us/step - loss: 0.0515 - acc: 0.9839\n",
            "Epoch 26/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.0513 - acc: 0.9850\n",
            "Epoch 27/30\n",
            "56590/56590 [==============================] - 10s 178us/step - loss: 0.0532 - acc: 0.9837\n",
            "Epoch 28/30\n",
            "56590/56590 [==============================] - 10s 177us/step - loss: 0.0496 - acc: 0.9849\n",
            "Epoch 29/30\n",
            "56590/56590 [==============================] - 10s 178us/step - loss: 0.0532 - acc: 0.9837\n",
            "Epoch 30/30\n",
            "56590/56590 [==============================] - 10s 177us/step - loss: 0.0489 - acc: 0.9852\n",
            "Precision = 91.08, Recall = 89.72, F1 = 90.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkPqQ-JI_TF_",
        "colab_type": "code",
        "outputId": "0cf603bd-5a83-438f-a759-6e72102d1bdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# past context of 5, kernel of 5\n",
        "context_size = 5\n",
        "kernel_size = 5\n",
        "cnn_input, cnn_labels = preparePastCNNGloveInput(words_train, context_size, train_label, embeddings_index)\n",
        "val_input, val_labels = preparePastCNNGloveInput(words_val, context_size, val_label, embeddings_index)\n",
        "model = get_glove_model(context_size, kernel_size)\n",
        "model.fit(cnn_input, cnn_labels, epochs=30)\n",
        "print_evaluation(model, val_input, val_labels, val_x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_7 (InputLayer)         (None, 5, 100)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_40 (Conv1D)           (None, 5, 100)            50100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_40 (MaxPooling (None, 2, 100)            0         \n",
            "_________________________________________________________________\n",
            "dropout_40 (Dropout)         (None, 2, 100)            0         \n",
            "_________________________________________________________________\n",
            "flatten_40 (Flatten)         (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_79 (Dense)             (None, 128)               25728     \n",
            "_________________________________________________________________\n",
            "dense_80 (Dense)             (None, 127)               16383     \n",
            "=================================================================\n",
            "Total params: 92,211\n",
            "Trainable params: 92,211\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "56590/56590 [==============================] - 14s 248us/step - loss: 0.4324 - acc: 0.9088\n",
            "Epoch 2/30\n",
            "56590/56590 [==============================] - 10s 180us/step - loss: 0.1468 - acc: 0.9621\n",
            "Epoch 3/30\n",
            "56590/56590 [==============================] - 10s 182us/step - loss: 0.1061 - acc: 0.9711\n",
            "Epoch 4/30\n",
            "56590/56590 [==============================] - 10s 180us/step - loss: 0.0893 - acc: 0.9752\n",
            "Epoch 5/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0755 - acc: 0.9784\n",
            "Epoch 6/30\n",
            "56590/56590 [==============================] - 10s 182us/step - loss: 0.0707 - acc: 0.9790\n",
            "Epoch 7/30\n",
            "56590/56590 [==============================] - 10s 182us/step - loss: 0.0623 - acc: 0.9810\n",
            "Epoch 8/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.0580 - acc: 0.9820\n",
            "Epoch 9/30\n",
            "56590/56590 [==============================] - 10s 181us/step - loss: 0.0549 - acc: 0.9831\n",
            "Epoch 10/30\n",
            "56590/56590 [==============================] - 10s 181us/step - loss: 0.0498 - acc: 0.9842\n",
            "Epoch 11/30\n",
            "56590/56590 [==============================] - 10s 181us/step - loss: 0.0497 - acc: 0.9845\n",
            "Epoch 12/30\n",
            "56590/56590 [==============================] - 10s 182us/step - loss: 0.0494 - acc: 0.9843\n",
            "Epoch 13/30\n",
            "56590/56590 [==============================] - 10s 179us/step - loss: 0.0448 - acc: 0.9856\n",
            "Epoch 14/30\n",
            "56590/56590 [==============================] - 10s 180us/step - loss: 0.0461 - acc: 0.9852\n",
            "Epoch 15/30\n",
            "56590/56590 [==============================] - 10s 181us/step - loss: 0.0418 - acc: 0.9866\n",
            "Epoch 16/30\n",
            "56590/56590 [==============================] - 10s 180us/step - loss: 0.0425 - acc: 0.9865\n",
            "Epoch 17/30\n",
            "56590/56590 [==============================] - 10s 180us/step - loss: 0.0446 - acc: 0.9858\n",
            "Epoch 18/30\n",
            "56590/56590 [==============================] - 10s 179us/step - loss: 0.0391 - acc: 0.9875\n",
            "Epoch 19/30\n",
            "56590/56590 [==============================] - 10s 182us/step - loss: 0.0409 - acc: 0.9876\n",
            "Epoch 20/30\n",
            "56590/56590 [==============================] - 10s 181us/step - loss: 0.0411 - acc: 0.9868\n",
            "Epoch 21/30\n",
            "56590/56590 [==============================] - 10s 181us/step - loss: 0.0391 - acc: 0.9878\n",
            "Epoch 22/30\n",
            "56590/56590 [==============================] - 10s 180us/step - loss: 0.0388 - acc: 0.9877\n",
            "Epoch 23/30\n",
            "56590/56590 [==============================] - 10s 179us/step - loss: 0.0369 - acc: 0.9881\n",
            "Epoch 24/30\n",
            "56590/56590 [==============================] - 10s 180us/step - loss: 0.0384 - acc: 0.9877\n",
            "Epoch 25/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.0363 - acc: 0.9885\n",
            "Epoch 26/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.0361 - acc: 0.9885\n",
            "Epoch 27/30\n",
            "56590/56590 [==============================] - 10s 182us/step - loss: 0.0363 - acc: 0.9884\n",
            "Epoch 28/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.0372 - acc: 0.9883\n",
            "Epoch 29/30\n",
            "56590/56590 [==============================] - 10s 182us/step - loss: 0.0332 - acc: 0.9893\n",
            "Epoch 30/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.0374 - acc: 0.9884\n",
            "Precision = 91.68, Recall = 90.63, F1 = 91.15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5LvCRBb7_9L4"
      },
      "source": [
        "**Experiment with a window size of 7 using the past context words and glove embedding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y22RWgOi_fRz",
        "colab_type": "code",
        "outputId": "352e5891-81aa-4e98-b1e1-5d45a7203f6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# past context of 7, kernel of 3\n",
        "context_size = 7\n",
        "kernel_size = 3\n",
        "cnn_input, cnn_labels = preparePastCNNGloveInput(words_train, context_size, train_label, embeddings_index)\n",
        "val_input, val_labels = preparePastCNNGloveInput(words_val, context_size, val_label, embeddings_index)\n",
        "model = get_glove_model(context_size, kernel_size)\n",
        "model.fit(cnn_input, cnn_labels, epochs=30)\n",
        "print_evaluation(model, val_input, val_labels, val_x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_8 (InputLayer)         (None, 7, 100)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_41 (Conv1D)           (None, 7, 100)            30100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_41 (MaxPooling (None, 3, 100)            0         \n",
            "_________________________________________________________________\n",
            "dropout_41 (Dropout)         (None, 3, 100)            0         \n",
            "_________________________________________________________________\n",
            "flatten_41 (Flatten)         (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dense_81 (Dense)             (None, 128)               38528     \n",
            "_________________________________________________________________\n",
            "dense_82 (Dense)             (None, 127)               16383     \n",
            "=================================================================\n",
            "Total params: 85,011\n",
            "Trainable params: 85,011\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "56590/56590 [==============================] - 14s 252us/step - loss: 0.5659 - acc: 0.8777\n",
            "Epoch 2/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.2204 - acc: 0.9440\n",
            "Epoch 3/30\n",
            "56590/56590 [==============================] - 10s 182us/step - loss: 0.1516 - acc: 0.9601\n",
            "Epoch 4/30\n",
            "56590/56590 [==============================] - 10s 180us/step - loss: 0.1240 - acc: 0.9664\n",
            "Epoch 5/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.1073 - acc: 0.9696\n",
            "Epoch 6/30\n",
            "56590/56590 [==============================] - 10s 181us/step - loss: 0.0933 - acc: 0.9732\n",
            "Epoch 7/30\n",
            "56590/56590 [==============================] - 10s 182us/step - loss: 0.0845 - acc: 0.9748\n",
            "Epoch 8/30\n",
            "56590/56590 [==============================] - 10s 179us/step - loss: 0.0784 - acc: 0.9773\n",
            "Epoch 9/30\n",
            "56590/56590 [==============================] - 10s 182us/step - loss: 0.0713 - acc: 0.9786\n",
            "Epoch 10/30\n",
            "56590/56590 [==============================] - 10s 180us/step - loss: 0.0673 - acc: 0.9803\n",
            "Epoch 11/30\n",
            "56590/56590 [==============================] - 10s 180us/step - loss: 0.0637 - acc: 0.9805\n",
            "Epoch 12/30\n",
            "56590/56590 [==============================] - 10s 182us/step - loss: 0.0641 - acc: 0.9812\n",
            "Epoch 13/30\n",
            "56590/56590 [==============================] - 10s 182us/step - loss: 0.0583 - acc: 0.9821\n",
            "Epoch 14/30\n",
            "56590/56590 [==============================] - 10s 179us/step - loss: 0.0582 - acc: 0.9822\n",
            "Epoch 15/30\n",
            "56590/56590 [==============================] - 10s 182us/step - loss: 0.0548 - acc: 0.9833\n",
            "Epoch 16/30\n",
            "56590/56590 [==============================] - 10s 179us/step - loss: 0.0556 - acc: 0.9830\n",
            "Epoch 17/30\n",
            "56590/56590 [==============================] - 10s 181us/step - loss: 0.0511 - acc: 0.9842\n",
            "Epoch 18/30\n",
            "56590/56590 [==============================] - 10s 181us/step - loss: 0.0498 - acc: 0.9848\n",
            "Epoch 19/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.0497 - acc: 0.9856\n",
            "Epoch 20/30\n",
            "56590/56590 [==============================] - 10s 180us/step - loss: 0.0462 - acc: 0.9861\n",
            "Epoch 21/30\n",
            "56590/56590 [==============================] - 10s 181us/step - loss: 0.0495 - acc: 0.9851\n",
            "Epoch 22/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.0461 - acc: 0.9867\n",
            "Epoch 23/30\n",
            "56590/56590 [==============================] - 10s 179us/step - loss: 0.0471 - acc: 0.9862\n",
            "Epoch 24/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0463 - acc: 0.9860\n",
            "Epoch 25/30\n",
            "56590/56590 [==============================] - 10s 181us/step - loss: 0.0460 - acc: 0.9866\n",
            "Epoch 26/30\n",
            "56590/56590 [==============================] - 10s 180us/step - loss: 0.0472 - acc: 0.9861\n",
            "Epoch 27/30\n",
            "56590/56590 [==============================] - 10s 182us/step - loss: 0.0464 - acc: 0.9863\n",
            "Epoch 28/30\n",
            "56590/56590 [==============================] - 10s 180us/step - loss: 0.0417 - acc: 0.9877\n",
            "Epoch 29/30\n",
            "56590/56590 [==============================] - 10s 182us/step - loss: 0.0420 - acc: 0.9875\n",
            "Epoch 30/30\n",
            "56590/56590 [==============================] - 10s 180us/step - loss: 0.0431 - acc: 0.9878\n",
            "Precision = 91.75, Recall = 90.86, F1 = 91.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNyjHedj_fdD",
        "colab_type": "code",
        "outputId": "07550848-1858-4d82-f7f1-8966a03837bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# past context of 7, kernel of 5\n",
        "context_size = 7\n",
        "kernel_size = 5\n",
        "cnn_input, cnn_labels = preparePastCNNGloveInput(words_train, context_size, train_label, embeddings_index)\n",
        "val_input, val_labels = preparePastCNNGloveInput(words_val, context_size, val_label, embeddings_index)\n",
        "model = get_glove_model(context_size, kernel_size)\n",
        "model.fit(cnn_input, cnn_labels, epochs=30)\n",
        "print_evaluation(model, val_input, val_labels, val_x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_9 (InputLayer)         (None, 7, 100)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_42 (Conv1D)           (None, 7, 100)            50100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_42 (MaxPooling (None, 3, 100)            0         \n",
            "_________________________________________________________________\n",
            "dropout_42 (Dropout)         (None, 3, 100)            0         \n",
            "_________________________________________________________________\n",
            "flatten_42 (Flatten)         (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dense_83 (Dense)             (None, 128)               38528     \n",
            "_________________________________________________________________\n",
            "dense_84 (Dense)             (None, 127)               16383     \n",
            "=================================================================\n",
            "Total params: 105,011\n",
            "Trainable params: 105,011\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "56590/56590 [==============================] - 14s 252us/step - loss: 0.4334 - acc: 0.9066\n",
            "Epoch 2/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.1470 - acc: 0.9621\n",
            "Epoch 3/30\n",
            "56590/56590 [==============================] - 10s 179us/step - loss: 0.1024 - acc: 0.9727\n",
            "Epoch 4/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.0816 - acc: 0.9772\n",
            "Epoch 5/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.0718 - acc: 0.9797\n",
            "Epoch 6/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.0629 - acc: 0.9813\n",
            "Epoch 7/30\n",
            "56590/56590 [==============================] - 10s 182us/step - loss: 0.0550 - acc: 0.9835\n",
            "Epoch 8/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0523 - acc: 0.9846\n",
            "Epoch 9/30\n",
            "56590/56590 [==============================] - 10s 182us/step - loss: 0.0497 - acc: 0.9847\n",
            "Epoch 10/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.0459 - acc: 0.9856\n",
            "Epoch 11/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.0435 - acc: 0.9871\n",
            "Epoch 12/30\n",
            "56590/56590 [==============================] - 10s 181us/step - loss: 0.0404 - acc: 0.9877\n",
            "Epoch 13/30\n",
            "56590/56590 [==============================] - 10s 182us/step - loss: 0.0414 - acc: 0.9877\n",
            "Epoch 14/30\n",
            "56590/56590 [==============================] - 10s 182us/step - loss: 0.0400 - acc: 0.9882\n",
            "Epoch 15/30\n",
            "56590/56590 [==============================] - 10s 180us/step - loss: 0.0360 - acc: 0.9890\n",
            "Epoch 16/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.0360 - acc: 0.9890\n",
            "Epoch 17/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.0373 - acc: 0.9881\n",
            "Epoch 18/30\n",
            "56590/56590 [==============================] - 10s 181us/step - loss: 0.0353 - acc: 0.9894\n",
            "Epoch 19/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.0330 - acc: 0.9896\n",
            "Epoch 20/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.0336 - acc: 0.9899\n",
            "Epoch 21/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.0332 - acc: 0.9897\n",
            "Epoch 22/30\n",
            "56590/56590 [==============================] - 10s 181us/step - loss: 0.0333 - acc: 0.9901\n",
            "Epoch 23/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0319 - acc: 0.9904\n",
            "Epoch 24/30\n",
            "56590/56590 [==============================] - 10s 182us/step - loss: 0.0318 - acc: 0.9904\n",
            "Epoch 25/30\n",
            "56590/56590 [==============================] - 10s 182us/step - loss: 0.0315 - acc: 0.9910\n",
            "Epoch 26/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.0339 - acc: 0.9907\n",
            "Epoch 27/30\n",
            "56590/56590 [==============================] - 10s 182us/step - loss: 0.0303 - acc: 0.9912\n",
            "Epoch 28/30\n",
            "56590/56590 [==============================] - 10s 178us/step - loss: 0.0304 - acc: 0.9907\n",
            "Epoch 29/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.0322 - acc: 0.9911\n",
            "Epoch 30/30\n",
            "56590/56590 [==============================] - 10s 182us/step - loss: 0.0329 - acc: 0.9912\n",
            "Precision = 91.89, Recall = 90.36, F1 = 91.12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOghEOFK_fqx",
        "colab_type": "code",
        "outputId": "9df8d677-c667-4b93-888d-b3e322a39197",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# past context of 7, kernel of 7\n",
        "context_size = 7\n",
        "kernel_size = 7\n",
        "cnn_input, cnn_labels = preparePastCNNGloveInput(words_train, context_size, train_label, embeddings_index)\n",
        "val_input, val_labels = preparePastCNNGloveInput(words_val, context_size, val_label, embeddings_index)\n",
        "model = get_glove_model(context_size, kernel_size)\n",
        "model.fit(cnn_input, cnn_labels, epochs=30)\n",
        "print_evaluation(model, val_input, val_labels, val_x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_10 (InputLayer)        (None, 7, 100)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_43 (Conv1D)           (None, 7, 100)            70100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_43 (MaxPooling (None, 3, 100)            0         \n",
            "_________________________________________________________________\n",
            "dropout_43 (Dropout)         (None, 3, 100)            0         \n",
            "_________________________________________________________________\n",
            "flatten_43 (Flatten)         (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dense_85 (Dense)             (None, 128)               38528     \n",
            "_________________________________________________________________\n",
            "dense_86 (Dense)             (None, 127)               16383     \n",
            "=================================================================\n",
            "Total params: 125,011\n",
            "Trainable params: 125,011\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "56590/56590 [==============================] - 14s 253us/step - loss: 0.4501 - acc: 0.9026\n",
            "Epoch 2/30\n",
            "56590/56590 [==============================] - 10s 180us/step - loss: 0.1450 - acc: 0.9626\n",
            "Epoch 3/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.1030 - acc: 0.9723\n",
            "Epoch 4/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0867 - acc: 0.9761\n",
            "Epoch 5/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.0724 - acc: 0.9793\n",
            "Epoch 6/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.0631 - acc: 0.9815\n",
            "Epoch 7/30\n",
            "56590/56590 [==============================] - 10s 181us/step - loss: 0.0586 - acc: 0.9828\n",
            "Epoch 8/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0530 - acc: 0.9845\n",
            "Epoch 9/30\n",
            "56590/56590 [==============================] - 10s 180us/step - loss: 0.0484 - acc: 0.9854\n",
            "Epoch 10/30\n",
            "56590/56590 [==============================] - 10s 181us/step - loss: 0.0462 - acc: 0.9864\n",
            "Epoch 11/30\n",
            "56590/56590 [==============================] - 10s 181us/step - loss: 0.0445 - acc: 0.9866\n",
            "Epoch 12/30\n",
            "56590/56590 [==============================] - 10s 182us/step - loss: 0.0416 - acc: 0.9872\n",
            "Epoch 13/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.0393 - acc: 0.9880\n",
            "Epoch 14/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.0395 - acc: 0.9877\n",
            "Epoch 15/30\n",
            "56590/56590 [==============================] - 10s 182us/step - loss: 0.0381 - acc: 0.9887\n",
            "Epoch 16/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.0367 - acc: 0.9898\n",
            "Epoch 17/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.0387 - acc: 0.9885\n",
            "Epoch 18/30\n",
            "56590/56590 [==============================] - 10s 182us/step - loss: 0.0356 - acc: 0.9894\n",
            "Epoch 19/30\n",
            "56590/56590 [==============================] - 10s 182us/step - loss: 0.0345 - acc: 0.9894\n",
            "Epoch 20/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.0317 - acc: 0.9905\n",
            "Epoch 21/30\n",
            "56590/56590 [==============================] - 10s 181us/step - loss: 0.0361 - acc: 0.9896\n",
            "Epoch 22/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0328 - acc: 0.9903\n",
            "Epoch 23/30\n",
            "56590/56590 [==============================] - 10s 182us/step - loss: 0.0353 - acc: 0.9897\n",
            "Epoch 24/30\n",
            "56590/56590 [==============================] - 10s 179us/step - loss: 0.0331 - acc: 0.9900\n",
            "Epoch 25/30\n",
            "56590/56590 [==============================] - 10s 181us/step - loss: 0.0353 - acc: 0.9899\n",
            "Epoch 26/30\n",
            "56590/56590 [==============================] - 10s 182us/step - loss: 0.0313 - acc: 0.9909\n",
            "Epoch 27/30\n",
            "56590/56590 [==============================] - 10s 181us/step - loss: 0.0315 - acc: 0.9911\n",
            "Epoch 28/30\n",
            "56590/56590 [==============================] - 10s 181us/step - loss: 0.0321 - acc: 0.9910\n",
            "Epoch 29/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.0301 - acc: 0.9909\n",
            "Epoch 30/30\n",
            "56590/56590 [==============================] - 10s 182us/step - loss: 0.0313 - acc: 0.9908\n",
            "Precision = 91.54, Recall = 90.17, F1 = 90.85\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ld4VF0GM__iT"
      },
      "source": [
        "**Experiment with a window size of 9 using the past context words and glove embedding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hO6jrJN_f7M",
        "colab_type": "code",
        "outputId": "ef0a4463-d16e-404d-e68b-a8cfd27641f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# past context of 9, kernel of 3\n",
        "context_size = 9\n",
        "kernel_size = 3\n",
        "cnn_input, cnn_labels = preparePastCNNGloveInput(words_train, context_size, train_label, embeddings_index)\n",
        "val_input, val_labels = preparePastCNNGloveInput(words_val, context_size, val_label, embeddings_index)\n",
        "model = get_glove_model(context_size, kernel_size)\n",
        "model.fit(cnn_input, cnn_labels, epochs=30)\n",
        "print_evaluation(model, val_input, val_labels, val_x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_11 (InputLayer)        (None, 9, 100)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_44 (Conv1D)           (None, 9, 100)            30100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_44 (MaxPooling (None, 4, 100)            0         \n",
            "_________________________________________________________________\n",
            "dropout_44 (Dropout)         (None, 4, 100)            0         \n",
            "_________________________________________________________________\n",
            "flatten_44 (Flatten)         (None, 400)               0         \n",
            "_________________________________________________________________\n",
            "dense_87 (Dense)             (None, 128)               51328     \n",
            "_________________________________________________________________\n",
            "dense_88 (Dense)             (None, 127)               16383     \n",
            "=================================================================\n",
            "Total params: 97,811\n",
            "Trainable params: 97,811\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "56590/56590 [==============================] - 15s 261us/step - loss: 0.5781 - acc: 0.8734\n",
            "Epoch 2/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.2209 - acc: 0.9440\n",
            "Epoch 3/30\n",
            "56590/56590 [==============================] - 11s 196us/step - loss: 0.1530 - acc: 0.9599\n",
            "Epoch 4/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.1233 - acc: 0.9661\n",
            "Epoch 5/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.1014 - acc: 0.9712\n",
            "Epoch 6/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0918 - acc: 0.9735\n",
            "Epoch 7/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0799 - acc: 0.9762\n",
            "Epoch 8/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.0728 - acc: 0.9779\n",
            "Epoch 9/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0669 - acc: 0.9793\n",
            "Epoch 10/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0641 - acc: 0.9808\n",
            "Epoch 11/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.0620 - acc: 0.9814\n",
            "Epoch 12/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0583 - acc: 0.9820\n",
            "Epoch 13/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0544 - acc: 0.9837\n",
            "Epoch 14/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0523 - acc: 0.9842\n",
            "Epoch 15/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0544 - acc: 0.9832\n",
            "Epoch 16/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0501 - acc: 0.9853\n",
            "Epoch 17/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0501 - acc: 0.9844\n",
            "Epoch 18/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0477 - acc: 0.9857\n",
            "Epoch 19/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0493 - acc: 0.9854\n",
            "Epoch 20/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.0484 - acc: 0.9854\n",
            "Epoch 21/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.0452 - acc: 0.9862\n",
            "Epoch 22/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0453 - acc: 0.9860\n",
            "Epoch 23/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0444 - acc: 0.9866\n",
            "Epoch 24/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0453 - acc: 0.9870\n",
            "Epoch 25/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0453 - acc: 0.9868\n",
            "Epoch 26/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.0438 - acc: 0.9872\n",
            "Epoch 27/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.0420 - acc: 0.9879\n",
            "Epoch 28/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.0430 - acc: 0.9872\n",
            "Epoch 29/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.0410 - acc: 0.9881\n",
            "Epoch 30/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0412 - acc: 0.9884\n",
            "Precision = 91.65, Recall = 90.91, F1 = 91.28\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsCpesHL_g10",
        "colab_type": "code",
        "outputId": "77ea2867-c20c-43fc-a9bf-6d4cd15bdb89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# past context of 9, kernel of 5\n",
        "context_size = 9\n",
        "kernel_size = 5\n",
        "cnn_input, cnn_labels = preparePastCNNGloveInput(words_train, context_size, train_label, embeddings_index)\n",
        "val_input, val_labels = preparePastCNNGloveInput(words_val, context_size, val_label, embeddings_index)\n",
        "model = get_glove_model(context_size, kernel_size)\n",
        "model.fit(cnn_input, cnn_labels, epochs=30)\n",
        "print_evaluation(model, val_input, val_labels, val_x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_12 (InputLayer)        (None, 9, 100)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_45 (Conv1D)           (None, 9, 100)            50100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_45 (MaxPooling (None, 4, 100)            0         \n",
            "_________________________________________________________________\n",
            "dropout_45 (Dropout)         (None, 4, 100)            0         \n",
            "_________________________________________________________________\n",
            "flatten_45 (Flatten)         (None, 400)               0         \n",
            "_________________________________________________________________\n",
            "dense_89 (Dense)             (None, 128)               51328     \n",
            "_________________________________________________________________\n",
            "dense_90 (Dense)             (None, 127)               16383     \n",
            "=================================================================\n",
            "Total params: 117,811\n",
            "Trainable params: 117,811\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "56590/56590 [==============================] - 15s 270us/step - loss: 0.4655 - acc: 0.8987\n",
            "Epoch 2/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.1538 - acc: 0.9607\n",
            "Epoch 3/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.1033 - acc: 0.9724\n",
            "Epoch 4/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0824 - acc: 0.9777\n",
            "Epoch 5/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0700 - acc: 0.9798\n",
            "Epoch 6/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.0623 - acc: 0.9821\n",
            "Epoch 7/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0559 - acc: 0.9833\n",
            "Epoch 8/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0504 - acc: 0.9854\n",
            "Epoch 9/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.0482 - acc: 0.9858\n",
            "Epoch 10/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0425 - acc: 0.9876\n",
            "Epoch 11/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0428 - acc: 0.9877\n",
            "Epoch 12/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.0413 - acc: 0.9880\n",
            "Epoch 13/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.0385 - acc: 0.9883\n",
            "Epoch 14/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.0381 - acc: 0.9890\n",
            "Epoch 15/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0351 - acc: 0.9892\n",
            "Epoch 16/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0375 - acc: 0.9885\n",
            "Epoch 17/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0342 - acc: 0.9900\n",
            "Epoch 18/30\n",
            "56590/56590 [==============================] - 11s 191us/step - loss: 0.0352 - acc: 0.9904\n",
            "Epoch 19/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.0384 - acc: 0.9891\n",
            "Epoch 20/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.0340 - acc: 0.9904\n",
            "Epoch 21/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0317 - acc: 0.9907\n",
            "Epoch 22/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0351 - acc: 0.9903\n",
            "Epoch 23/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0324 - acc: 0.9907\n",
            "Epoch 24/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0312 - acc: 0.9916\n",
            "Epoch 25/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0328 - acc: 0.9907\n",
            "Epoch 26/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.0332 - acc: 0.9910\n",
            "Epoch 27/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0285 - acc: 0.9921\n",
            "Epoch 28/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0306 - acc: 0.9914\n",
            "Epoch 29/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.0292 - acc: 0.9915\n",
            "Epoch 30/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0321 - acc: 0.9916\n",
            "Precision = 92.32, Recall = 91.7, F1 = 92.01\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0_CcFSL_g7i",
        "colab_type": "code",
        "outputId": "6351bf3d-011f-49d5-fc76-ee38532a7615",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# past context of 9, kernel of 7\n",
        "context_size = 9\n",
        "kernel_size = 7\n",
        "cnn_input, cnn_labels = preparePastCNNGloveInput(words_train, context_size, train_label, embeddings_index)\n",
        "val_input, val_labels = preparePastCNNGloveInput(words_val, context_size, val_label, embeddings_index)\n",
        "model = get_glove_model(context_size, kernel_size)\n",
        "model.fit(cnn_input, cnn_labels, epochs=30)\n",
        "print_evaluation(model, val_input, val_labels, val_x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_13 (InputLayer)        (None, 9, 100)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_46 (Conv1D)           (None, 9, 100)            70100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_46 (MaxPooling (None, 4, 100)            0         \n",
            "_________________________________________________________________\n",
            "dropout_46 (Dropout)         (None, 4, 100)            0         \n",
            "_________________________________________________________________\n",
            "flatten_46 (Flatten)         (None, 400)               0         \n",
            "_________________________________________________________________\n",
            "dense_91 (Dense)             (None, 128)               51328     \n",
            "_________________________________________________________________\n",
            "dense_92 (Dense)             (None, 127)               16383     \n",
            "=================================================================\n",
            "Total params: 137,811\n",
            "Trainable params: 137,811\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "56590/56590 [==============================] - 15s 264us/step - loss: 0.4543 - acc: 0.9020\n",
            "Epoch 2/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.1483 - acc: 0.9618\n",
            "Epoch 3/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.1031 - acc: 0.9728\n",
            "Epoch 4/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0815 - acc: 0.9773\n",
            "Epoch 5/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0696 - acc: 0.9793\n",
            "Epoch 6/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.0620 - acc: 0.9820\n",
            "Epoch 7/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.0540 - acc: 0.9843\n",
            "Epoch 8/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0519 - acc: 0.9848\n",
            "Epoch 9/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0466 - acc: 0.9860\n",
            "Epoch 10/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0475 - acc: 0.9863\n",
            "Epoch 11/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0431 - acc: 0.9876\n",
            "Epoch 12/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0403 - acc: 0.9882\n",
            "Epoch 13/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.0398 - acc: 0.9885\n",
            "Epoch 14/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0394 - acc: 0.9881\n",
            "Epoch 15/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0378 - acc: 0.9886\n",
            "Epoch 16/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0380 - acc: 0.9888\n",
            "Epoch 17/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.0329 - acc: 0.9906\n",
            "Epoch 18/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.0350 - acc: 0.9893\n",
            "Epoch 19/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0336 - acc: 0.9906\n",
            "Epoch 20/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.0345 - acc: 0.9905\n",
            "Epoch 21/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0337 - acc: 0.9906\n",
            "Epoch 22/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0342 - acc: 0.9901\n",
            "Epoch 23/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0310 - acc: 0.9917\n",
            "Epoch 24/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0337 - acc: 0.9910\n",
            "Epoch 25/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0337 - acc: 0.9912\n",
            "Epoch 26/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0304 - acc: 0.9918\n",
            "Epoch 27/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0319 - acc: 0.9913\n",
            "Epoch 28/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0315 - acc: 0.9916\n",
            "Epoch 29/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.0310 - acc: 0.9915\n",
            "Epoch 30/30\n",
            "56590/56590 [==============================] - 11s 192us/step - loss: 0.0297 - acc: 0.9920\n",
            "Precision = 91.12, Recall = 88.95, F1 = 90.02\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aVLF-XB_f53",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SUh8OtK_fXr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wtiK4QuGADE-"
      },
      "source": [
        "**Experiment with a window size of 3 using the future context words and glove embedding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeL8Fjpl9AXo",
        "colab_type": "code",
        "outputId": "c260ffa8-02d9-450a-8acb-8364e2845258",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# future context of 3, kernel of 3\n",
        "context_size = 3\n",
        "kernel_size = 3\n",
        "cnn_input, cnn_labels = prepareFutureCNNGloveInput(words_train, context_size, train_label, embeddings_index)\n",
        "val_input, val_labels = prepareFutureCNNGloveInput(words_val, context_size, val_label, embeddings_index)\n",
        "model = get_glove_model(context_size, kernel_size)\n",
        "model.fit(cnn_input, cnn_labels, epochs=30)\n",
        "print_evaluation(model, val_input, val_labels, val_x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_14 (InputLayer)        (None, 3, 100)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_47 (Conv1D)           (None, 3, 100)            30100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_47 (MaxPooling (None, 1, 100)            0         \n",
            "_________________________________________________________________\n",
            "dropout_47 (Dropout)         (None, 1, 100)            0         \n",
            "_________________________________________________________________\n",
            "flatten_47 (Flatten)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_93 (Dense)             (None, 128)               12928     \n",
            "_________________________________________________________________\n",
            "dense_94 (Dense)             (None, 127)               16383     \n",
            "=================================================================\n",
            "Total params: 59,411\n",
            "Trainable params: 59,411\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "56590/56590 [==============================] - 15s 264us/step - loss: 0.4585 - acc: 0.8951\n",
            "Epoch 2/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.2310 - acc: 0.9333\n",
            "Epoch 3/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.2041 - acc: 0.9383\n",
            "Epoch 4/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.1909 - acc: 0.9402\n",
            "Epoch 5/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.1826 - acc: 0.9429\n",
            "Epoch 6/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.1759 - acc: 0.9435\n",
            "Epoch 7/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.1713 - acc: 0.9448\n",
            "Epoch 8/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.1653 - acc: 0.9465\n",
            "Epoch 9/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.1642 - acc: 0.9460\n",
            "Epoch 10/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.1629 - acc: 0.9475\n",
            "Epoch 11/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.1593 - acc: 0.9471\n",
            "Epoch 12/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.1565 - acc: 0.9484\n",
            "Epoch 13/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.1559 - acc: 0.9478\n",
            "Epoch 14/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.1548 - acc: 0.9484\n",
            "Epoch 15/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.1535 - acc: 0.9478\n",
            "Epoch 16/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.1519 - acc: 0.9489\n",
            "Epoch 17/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.1486 - acc: 0.9500\n",
            "Epoch 18/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.1493 - acc: 0.9494\n",
            "Epoch 19/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.1480 - acc: 0.9497\n",
            "Epoch 20/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.1463 - acc: 0.9506\n",
            "Epoch 21/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.1468 - acc: 0.9505\n",
            "Epoch 22/30\n",
            "56590/56590 [==============================] - 10s 186us/step - loss: 0.1456 - acc: 0.9509\n",
            "Epoch 23/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.1446 - acc: 0.9504\n",
            "Epoch 24/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.1452 - acc: 0.9509\n",
            "Epoch 25/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.1432 - acc: 0.9512\n",
            "Epoch 26/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.1435 - acc: 0.9511\n",
            "Epoch 27/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.1438 - acc: 0.9511\n",
            "Epoch 28/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.1424 - acc: 0.9510\n",
            "Epoch 29/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.1438 - acc: 0.9507\n",
            "Epoch 30/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.1419 - acc: 0.9516\n",
            "Precision = 85.37, Recall = 82.47, F1 = 83.89\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Jk10UU76Armw"
      },
      "source": [
        "**Experiment with a window size of 5 using the future context words and glove embedding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62GzqrMqAM5U",
        "colab_type": "code",
        "outputId": "25269db6-8f35-45c9-d96b-1f1efdf48544",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# future context of 5, kernel of 3\n",
        "context_size = 5\n",
        "kernel_size = 3\n",
        "cnn_input, cnn_labels = prepareFutureCNNGloveInput(words_train, context_size, train_label, embeddings_index)\n",
        "val_input, val_labels = prepareFutureCNNGloveInput(words_val, context_size, val_label, embeddings_index)\n",
        "model = get_glove_model(context_size, kernel_size)\n",
        "model.fit(cnn_input, cnn_labels, epochs=30)\n",
        "print_evaluation(model, val_input, val_labels, val_x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_15 (InputLayer)        (None, 5, 100)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_48 (Conv1D)           (None, 5, 100)            30100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_48 (MaxPooling (None, 2, 100)            0         \n",
            "_________________________________________________________________\n",
            "dropout_48 (Dropout)         (None, 2, 100)            0         \n",
            "_________________________________________________________________\n",
            "flatten_48 (Flatten)         (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_95 (Dense)             (None, 128)               25728     \n",
            "_________________________________________________________________\n",
            "dense_96 (Dense)             (None, 127)               16383     \n",
            "=================================================================\n",
            "Total params: 72,211\n",
            "Trainable params: 72,211\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "56590/56590 [==============================] - 15s 269us/step - loss: 0.4725 - acc: 0.8916\n",
            "Epoch 2/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.2262 - acc: 0.9355\n",
            "Epoch 3/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.1945 - acc: 0.9417\n",
            "Epoch 4/30\n",
            "56590/56590 [==============================] - 11s 192us/step - loss: 0.1798 - acc: 0.9441\n",
            "Epoch 5/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.1701 - acc: 0.9470\n",
            "Epoch 6/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.1633 - acc: 0.9474\n",
            "Epoch 7/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.1575 - acc: 0.9487\n",
            "Epoch 8/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.1521 - acc: 0.9495\n",
            "Epoch 9/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.1483 - acc: 0.9509\n",
            "Epoch 10/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.1449 - acc: 0.9515\n",
            "Epoch 11/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.1440 - acc: 0.9527\n",
            "Epoch 12/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.1412 - acc: 0.9520\n",
            "Epoch 13/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.1393 - acc: 0.9523\n",
            "Epoch 14/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.1353 - acc: 0.9538\n",
            "Epoch 15/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.1353 - acc: 0.9532\n",
            "Epoch 16/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.1329 - acc: 0.9547\n",
            "Epoch 17/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.1324 - acc: 0.9539\n",
            "Epoch 18/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.1315 - acc: 0.9547\n",
            "Epoch 19/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.1290 - acc: 0.9559\n",
            "Epoch 20/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.1297 - acc: 0.9561\n",
            "Epoch 21/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.1290 - acc: 0.9559\n",
            "Epoch 22/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.1281 - acc: 0.9557\n",
            "Epoch 23/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.1277 - acc: 0.9565\n",
            "Epoch 24/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.1259 - acc: 0.9564\n",
            "Epoch 25/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.1241 - acc: 0.9573\n",
            "Epoch 26/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.1246 - acc: 0.9569\n",
            "Epoch 27/30\n",
            "56590/56590 [==============================] - 11s 194us/step - loss: 0.1242 - acc: 0.9573\n",
            "Epoch 28/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.1250 - acc: 0.9567\n",
            "Epoch 29/30\n",
            "56590/56590 [==============================] - 10s 186us/step - loss: 0.1231 - acc: 0.9575\n",
            "Epoch 30/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.1239 - acc: 0.9573\n",
            "Precision = 85.62, Recall = 85.29, F1 = 85.45\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-2U-FXrANJl",
        "colab_type": "code",
        "outputId": "b4df8fe9-0019-4f40-b222-acdfae0d9d52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# future context of 5, kernel of 5\n",
        "context_size = 5\n",
        "kernel_size = 5\n",
        "cnn_input, cnn_labels = prepareFutureCNNGloveInput(words_train, context_size, train_label, embeddings_index)\n",
        "val_input, val_labels = prepareFutureCNNGloveInput(words_val, context_size, val_label, embeddings_index)\n",
        "model = get_glove_model(context_size, kernel_size)\n",
        "model.fit(cnn_input, cnn_labels, epochs=30)\n",
        "print_evaluation(model, val_input, val_labels, val_x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_16 (InputLayer)        (None, 5, 100)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_49 (Conv1D)           (None, 5, 100)            50100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_49 (MaxPooling (None, 2, 100)            0         \n",
            "_________________________________________________________________\n",
            "dropout_49 (Dropout)         (None, 2, 100)            0         \n",
            "_________________________________________________________________\n",
            "flatten_49 (Flatten)         (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_97 (Dense)             (None, 128)               25728     \n",
            "_________________________________________________________________\n",
            "dense_98 (Dense)             (None, 127)               16383     \n",
            "=================================================================\n",
            "Total params: 92,211\n",
            "Trainable params: 92,211\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "56590/56590 [==============================] - 16s 275us/step - loss: 0.4759 - acc: 0.8905\n",
            "Epoch 2/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.2261 - acc: 0.9347\n",
            "Epoch 3/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.1968 - acc: 0.9402\n",
            "Epoch 4/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.1797 - acc: 0.9445\n",
            "Epoch 5/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.1697 - acc: 0.9456\n",
            "Epoch 6/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.1626 - acc: 0.9483\n",
            "Epoch 7/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.1578 - acc: 0.9485\n",
            "Epoch 8/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.1530 - acc: 0.9495\n",
            "Epoch 9/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.1495 - acc: 0.9505\n",
            "Epoch 10/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.1452 - acc: 0.9517\n",
            "Epoch 11/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.1434 - acc: 0.9524\n",
            "Epoch 12/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.1407 - acc: 0.9529\n",
            "Epoch 13/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.1397 - acc: 0.9537\n",
            "Epoch 14/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.1367 - acc: 0.9535\n",
            "Epoch 15/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.1364 - acc: 0.9542\n",
            "Epoch 16/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.1352 - acc: 0.9540\n",
            "Epoch 17/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.1326 - acc: 0.9551\n",
            "Epoch 18/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.1309 - acc: 0.9564\n",
            "Epoch 19/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.1300 - acc: 0.9566\n",
            "Epoch 20/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.1314 - acc: 0.9557\n",
            "Epoch 21/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.1289 - acc: 0.9562\n",
            "Epoch 22/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.1275 - acc: 0.9562\n",
            "Epoch 23/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.1268 - acc: 0.9570\n",
            "Epoch 24/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.1262 - acc: 0.9572\n",
            "Epoch 25/30\n",
            "56590/56590 [==============================] - 11s 195us/step - loss: 0.1281 - acc: 0.9561\n",
            "Epoch 26/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.1265 - acc: 0.9570\n",
            "Epoch 27/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.1264 - acc: 0.9574\n",
            "Epoch 28/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.1249 - acc: 0.9574\n",
            "Epoch 29/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.1249 - acc: 0.9580\n",
            "Epoch 30/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.1237 - acc: 0.9575\n",
            "Precision = 86.57, Recall = 85.16, F1 = 85.86\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EFAsGJzrAukM"
      },
      "source": [
        "**Experiment with a window size of 7 using the future context words and glove embedding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_qX4v8EAN04",
        "colab_type": "code",
        "outputId": "5de1f5f6-76f6-4c45-e31e-6ec22b78eb3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# future context of 7, kernel of 3\n",
        "context_size = 7\n",
        "kernel_size = 3\n",
        "cnn_input, cnn_labels = prepareFutureCNNGloveInput(words_train, context_size, train_label, embeddings_index)\n",
        "val_input, val_labels = prepareFutureCNNGloveInput(words_val, context_size, val_label, embeddings_index)\n",
        "model = get_glove_model(context_size, kernel_size)\n",
        "model.fit(cnn_input, cnn_labels, epochs=30)\n",
        "print_evaluation(model, val_input, val_labels, val_x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_17 (InputLayer)        (None, 7, 100)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_50 (Conv1D)           (None, 7, 100)            30100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_50 (MaxPooling (None, 3, 100)            0         \n",
            "_________________________________________________________________\n",
            "dropout_50 (Dropout)         (None, 3, 100)            0         \n",
            "_________________________________________________________________\n",
            "flatten_50 (Flatten)         (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dense_99 (Dense)             (None, 128)               38528     \n",
            "_________________________________________________________________\n",
            "dense_100 (Dense)            (None, 127)               16383     \n",
            "=================================================================\n",
            "Total params: 85,011\n",
            "Trainable params: 85,011\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "56590/56590 [==============================] - 16s 275us/step - loss: 0.4803 - acc: 0.8909\n",
            "Epoch 2/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.2287 - acc: 0.9360\n",
            "Epoch 3/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.1940 - acc: 0.9426\n",
            "Epoch 4/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.1778 - acc: 0.9456\n",
            "Epoch 5/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.1683 - acc: 0.9470\n",
            "Epoch 6/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.1594 - acc: 0.9490\n",
            "Epoch 7/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.1539 - acc: 0.9493\n",
            "Epoch 8/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.1479 - acc: 0.9517\n",
            "Epoch 9/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.1449 - acc: 0.9519\n",
            "Epoch 10/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.1420 - acc: 0.9528\n",
            "Epoch 11/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.1372 - acc: 0.9541\n",
            "Epoch 12/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.1358 - acc: 0.9543\n",
            "Epoch 13/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.1343 - acc: 0.9549\n",
            "Epoch 14/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.1310 - acc: 0.9557\n",
            "Epoch 15/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.1302 - acc: 0.9559\n",
            "Epoch 16/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.1284 - acc: 0.9571\n",
            "Epoch 17/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.1296 - acc: 0.9567\n",
            "Epoch 18/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.1268 - acc: 0.9568\n",
            "Epoch 19/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.1258 - acc: 0.9575\n",
            "Epoch 20/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.1228 - acc: 0.9590\n",
            "Epoch 21/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.1237 - acc: 0.9585\n",
            "Epoch 22/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.1236 - acc: 0.9584\n",
            "Epoch 23/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.1199 - acc: 0.9595\n",
            "Epoch 24/30\n",
            "56590/56590 [==============================] - 11s 192us/step - loss: 0.1211 - acc: 0.9594\n",
            "Epoch 25/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.1225 - acc: 0.9583\n",
            "Epoch 26/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.1197 - acc: 0.9591\n",
            "Epoch 27/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.1200 - acc: 0.9594\n",
            "Epoch 28/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.1180 - acc: 0.9599\n",
            "Epoch 29/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.1212 - acc: 0.9595\n",
            "Epoch 30/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.1193 - acc: 0.9599\n",
            "Precision = 85.34, Recall = 81.85, F1 = 83.55\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vs-qAq1sAN-Y",
        "colab_type": "code",
        "outputId": "dee03a25-6975-4b74-c58e-434f634460a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# future context of 7, kernel of 5\n",
        "context_size = 7\n",
        "kernel_size = 5\n",
        "cnn_input, cnn_labels = prepareFutureCNNGloveInput(words_train, context_size, train_label, embeddings_index)\n",
        "val_input, val_labels = prepareFutureCNNGloveInput(words_val, context_size, val_label, embeddings_index)\n",
        "model = get_glove_model(context_size, kernel_size)\n",
        "model.fit(cnn_input, cnn_labels, epochs=30)\n",
        "print_evaluation(model, val_input, val_labels, val_x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_17\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_18 (InputLayer)        (None, 7, 100)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_51 (Conv1D)           (None, 7, 100)            50100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_51 (MaxPooling (None, 3, 100)            0         \n",
            "_________________________________________________________________\n",
            "dropout_51 (Dropout)         (None, 3, 100)            0         \n",
            "_________________________________________________________________\n",
            "flatten_51 (Flatten)         (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dense_101 (Dense)            (None, 128)               38528     \n",
            "_________________________________________________________________\n",
            "dense_102 (Dense)            (None, 127)               16383     \n",
            "=================================================================\n",
            "Total params: 105,011\n",
            "Trainable params: 105,011\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "56590/56590 [==============================] - 16s 281us/step - loss: 0.5002 - acc: 0.8848\n",
            "Epoch 2/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.2288 - acc: 0.9347\n",
            "Epoch 3/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.1935 - acc: 0.9415\n",
            "Epoch 4/30\n",
            "56590/56590 [==============================] - 11s 192us/step - loss: 0.1767 - acc: 0.9448\n",
            "Epoch 5/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.1646 - acc: 0.9468\n",
            "Epoch 6/30\n",
            "56590/56590 [==============================] - 11s 191us/step - loss: 0.1575 - acc: 0.9488\n",
            "Epoch 7/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.1510 - acc: 0.9509\n",
            "Epoch 8/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.1485 - acc: 0.9512\n",
            "Epoch 9/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.1450 - acc: 0.9518\n",
            "Epoch 10/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.1398 - acc: 0.9541\n",
            "Epoch 11/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.1380 - acc: 0.9534\n",
            "Epoch 12/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.1376 - acc: 0.9537\n",
            "Epoch 13/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.1323 - acc: 0.9556\n",
            "Epoch 14/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.1328 - acc: 0.9560\n",
            "Epoch 15/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.1293 - acc: 0.9565\n",
            "Epoch 16/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.1279 - acc: 0.9565\n",
            "Epoch 17/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.1269 - acc: 0.9573\n",
            "Epoch 18/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.1266 - acc: 0.9582\n",
            "Epoch 19/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.1251 - acc: 0.9578\n",
            "Epoch 20/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.1238 - acc: 0.9583\n",
            "Epoch 21/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.1219 - acc: 0.9589\n",
            "Epoch 22/30\n",
            "56590/56590 [==============================] - 11s 196us/step - loss: 0.1243 - acc: 0.9579\n",
            "Epoch 23/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.1229 - acc: 0.9586\n",
            "Epoch 24/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.1221 - acc: 0.9588\n",
            "Epoch 25/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.1210 - acc: 0.9596\n",
            "Epoch 26/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.1201 - acc: 0.9592\n",
            "Epoch 27/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.1186 - acc: 0.9604\n",
            "Epoch 28/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.1217 - acc: 0.9589\n",
            "Epoch 29/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.1157 - acc: 0.9606\n",
            "Epoch 30/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.1200 - acc: 0.9597\n",
            "Precision = 85.9, Recall = 83.95, F1 = 84.91\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dk98aAlXAOHJ",
        "colab_type": "code",
        "outputId": "62e3299c-910b-4309-a7ea-0f796ded0118",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# future context of 7, kernel of 7\n",
        "context_size = 7\n",
        "kernel_size = 7\n",
        "cnn_input, cnn_labels = prepareFutureCNNGloveInput(words_train, context_size, train_label, embeddings_index)\n",
        "val_input, val_labels = prepareFutureCNNGloveInput(words_val, context_size, val_label, embeddings_index)\n",
        "model = get_glove_model(context_size, kernel_size)\n",
        "model.fit(cnn_input, cnn_labels, epochs=30)\n",
        "print_evaluation(model, val_input, val_labels, val_x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_18\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_19 (InputLayer)        (None, 7, 100)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_52 (Conv1D)           (None, 7, 100)            70100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_52 (MaxPooling (None, 3, 100)            0         \n",
            "_________________________________________________________________\n",
            "dropout_52 (Dropout)         (None, 3, 100)            0         \n",
            "_________________________________________________________________\n",
            "flatten_52 (Flatten)         (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dense_103 (Dense)            (None, 128)               38528     \n",
            "_________________________________________________________________\n",
            "dense_104 (Dense)            (None, 127)               16383     \n",
            "=================================================================\n",
            "Total params: 125,011\n",
            "Trainable params: 125,011\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "56590/56590 [==============================] - 16s 283us/step - loss: 0.4890 - acc: 0.8876\n",
            "Epoch 2/30\n",
            "56590/56590 [==============================] - 11s 192us/step - loss: 0.2311 - acc: 0.9345\n",
            "Epoch 3/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.1978 - acc: 0.9404\n",
            "Epoch 4/30\n",
            "56590/56590 [==============================] - 11s 194us/step - loss: 0.1826 - acc: 0.9439\n",
            "Epoch 5/30\n",
            "56590/56590 [==============================] - 11s 191us/step - loss: 0.1700 - acc: 0.9462\n",
            "Epoch 6/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.1636 - acc: 0.9473\n",
            "Epoch 7/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.1561 - acc: 0.9499\n",
            "Epoch 8/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.1502 - acc: 0.9507\n",
            "Epoch 9/30\n",
            "56590/56590 [==============================] - 11s 191us/step - loss: 0.1463 - acc: 0.9516\n",
            "Epoch 10/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.1427 - acc: 0.9526\n",
            "Epoch 11/30\n",
            "56590/56590 [==============================] - 11s 192us/step - loss: 0.1393 - acc: 0.9532\n",
            "Epoch 12/30\n",
            "56590/56590 [==============================] - 11s 191us/step - loss: 0.1396 - acc: 0.9534\n",
            "Epoch 13/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.1360 - acc: 0.9535\n",
            "Epoch 14/30\n",
            "56590/56590 [==============================] - 11s 191us/step - loss: 0.1340 - acc: 0.9550\n",
            "Epoch 15/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.1338 - acc: 0.9549\n",
            "Epoch 16/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.1306 - acc: 0.9560\n",
            "Epoch 17/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.1279 - acc: 0.9565\n",
            "Epoch 18/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.1306 - acc: 0.9562\n",
            "Epoch 19/30\n",
            "56590/56590 [==============================] - 11s 192us/step - loss: 0.1292 - acc: 0.9561\n",
            "Epoch 20/30\n",
            "56590/56590 [==============================] - 11s 193us/step - loss: 0.1275 - acc: 0.9569\n",
            "Epoch 21/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.1254 - acc: 0.9582\n",
            "Epoch 22/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.1251 - acc: 0.9576\n",
            "Epoch 23/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.1266 - acc: 0.9571\n",
            "Epoch 24/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.1237 - acc: 0.9580\n",
            "Epoch 25/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.1248 - acc: 0.9582\n",
            "Epoch 26/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.1231 - acc: 0.9586\n",
            "Epoch 27/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.1222 - acc: 0.9584\n",
            "Epoch 28/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.1233 - acc: 0.9585\n",
            "Epoch 29/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.1225 - acc: 0.9585\n",
            "Epoch 30/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.1222 - acc: 0.9598\n",
            "Precision = 85.55, Recall = 84.48, F1 = 85.01\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hwtk16otAw5s"
      },
      "source": [
        "**Experiment with a window size of 9 using the future context words and glove embedding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiTbgW9cAORY",
        "colab_type": "code",
        "outputId": "3815ebb4-1e93-420c-f256-3cd1ab95a6c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# future context of 9, kernel of 3\n",
        "context_size = 9\n",
        "kernel_size = 3\n",
        "cnn_input, cnn_labels = prepareFutureCNNGloveInput(words_train, context_size, train_label, embeddings_index)\n",
        "val_input, val_labels = prepareFutureCNNGloveInput(words_val, context_size, val_label, embeddings_index)\n",
        "model = get_glove_model(context_size, kernel_size)\n",
        "model.fit(cnn_input, cnn_labels, epochs=30)\n",
        "print_evaluation(model, val_input, val_labels, val_x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_20 (InputLayer)        (None, 9, 100)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_53 (Conv1D)           (None, 9, 100)            30100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_53 (MaxPooling (None, 4, 100)            0         \n",
            "_________________________________________________________________\n",
            "dropout_53 (Dropout)         (None, 4, 100)            0         \n",
            "_________________________________________________________________\n",
            "flatten_53 (Flatten)         (None, 400)               0         \n",
            "_________________________________________________________________\n",
            "dense_105 (Dense)            (None, 128)               51328     \n",
            "_________________________________________________________________\n",
            "dense_106 (Dense)            (None, 127)               16383     \n",
            "=================================================================\n",
            "Total params: 97,811\n",
            "Trainable params: 97,811\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "56590/56590 [==============================] - 16s 289us/step - loss: 0.4972 - acc: 0.8860\n",
            "Epoch 2/30\n",
            "56590/56590 [==============================] - 11s 192us/step - loss: 0.2276 - acc: 0.9351\n",
            "Epoch 3/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.1926 - acc: 0.9408\n",
            "Epoch 4/30\n",
            "56590/56590 [==============================] - 11s 191us/step - loss: 0.1752 - acc: 0.9459\n",
            "Epoch 5/30\n",
            "56590/56590 [==============================] - 11s 191us/step - loss: 0.1642 - acc: 0.9481\n",
            "Epoch 6/30\n",
            "56590/56590 [==============================] - 11s 191us/step - loss: 0.1559 - acc: 0.9500\n",
            "Epoch 7/30\n",
            "56590/56590 [==============================] - 11s 192us/step - loss: 0.1495 - acc: 0.9508\n",
            "Epoch 8/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.1440 - acc: 0.9524\n",
            "Epoch 9/30\n",
            "56590/56590 [==============================] - 11s 191us/step - loss: 0.1419 - acc: 0.9530\n",
            "Epoch 10/30\n",
            "56590/56590 [==============================] - 11s 191us/step - loss: 0.1360 - acc: 0.9546\n",
            "Epoch 11/30\n",
            "56590/56590 [==============================] - 11s 191us/step - loss: 0.1340 - acc: 0.9558\n",
            "Epoch 12/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.1314 - acc: 0.9555\n",
            "Epoch 13/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.1298 - acc: 0.9565\n",
            "Epoch 14/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.1299 - acc: 0.9570\n",
            "Epoch 15/30\n",
            "56590/56590 [==============================] - 11s 191us/step - loss: 0.1263 - acc: 0.9572\n",
            "Epoch 16/30\n",
            "56590/56590 [==============================] - 11s 193us/step - loss: 0.1260 - acc: 0.9569\n",
            "Epoch 17/30\n",
            "56590/56590 [==============================] - 11s 198us/step - loss: 0.1250 - acc: 0.9576\n",
            "Epoch 18/30\n",
            "56590/56590 [==============================] - 11s 193us/step - loss: 0.1221 - acc: 0.9584\n",
            "Epoch 19/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.1232 - acc: 0.9582\n",
            "Epoch 20/30\n",
            "56590/56590 [==============================] - 11s 191us/step - loss: 0.1209 - acc: 0.9593\n",
            "Epoch 21/30\n",
            "56590/56590 [==============================] - 11s 191us/step - loss: 0.1203 - acc: 0.9588\n",
            "Epoch 22/30\n",
            "56590/56590 [==============================] - 11s 191us/step - loss: 0.1181 - acc: 0.9601\n",
            "Epoch 23/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.1199 - acc: 0.9591\n",
            "Epoch 24/30\n",
            "56590/56590 [==============================] - 11s 191us/step - loss: 0.1194 - acc: 0.9593\n",
            "Epoch 25/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.1182 - acc: 0.9600\n",
            "Epoch 26/30\n",
            "56590/56590 [==============================] - 11s 191us/step - loss: 0.1176 - acc: 0.9592\n",
            "Epoch 27/30\n",
            "56590/56590 [==============================] - 11s 192us/step - loss: 0.1187 - acc: 0.9599\n",
            "Epoch 28/30\n",
            "56590/56590 [==============================] - 11s 191us/step - loss: 0.1147 - acc: 0.9613\n",
            "Epoch 29/30\n",
            "56590/56590 [==============================] - 11s 191us/step - loss: 0.1165 - acc: 0.9611\n",
            "Epoch 30/30\n",
            "56590/56590 [==============================] - 11s 194us/step - loss: 0.1164 - acc: 0.9606\n",
            "Precision = 85.23, Recall = 81.74, F1 = 83.45\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GhkyQnnAOZt",
        "colab_type": "code",
        "outputId": "7049b2c4-2d73-4f34-8931-89e4d803b53a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# future context of 9, kernel of 5\n",
        "context_size = 9\n",
        "kernel_size = 5\n",
        "cnn_input, cnn_labels = prepareFutureCNNGloveInput(words_train, context_size, train_label, embeddings_index)\n",
        "val_input, val_labels = prepareFutureCNNGloveInput(words_val, context_size, val_label, embeddings_index)\n",
        "model = get_glove_model(context_size, kernel_size)\n",
        "model.fit(cnn_input, cnn_labels, epochs=30)\n",
        "print_evaluation(model, val_input, val_labels, val_x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_20\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_21 (InputLayer)        (None, 9, 100)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_54 (Conv1D)           (None, 9, 100)            50100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_54 (MaxPooling (None, 4, 100)            0         \n",
            "_________________________________________________________________\n",
            "dropout_54 (Dropout)         (None, 4, 100)            0         \n",
            "_________________________________________________________________\n",
            "flatten_54 (Flatten)         (None, 400)               0         \n",
            "_________________________________________________________________\n",
            "dense_107 (Dense)            (None, 128)               51328     \n",
            "_________________________________________________________________\n",
            "dense_108 (Dense)            (None, 127)               16383     \n",
            "=================================================================\n",
            "Total params: 117,811\n",
            "Trainable params: 117,811\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "56590/56590 [==============================] - 16s 288us/step - loss: 0.5029 - acc: 0.8857\n",
            "Epoch 2/30\n",
            "56590/56590 [==============================] - 11s 192us/step - loss: 0.2273 - acc: 0.9355\n",
            "Epoch 3/30\n",
            "56590/56590 [==============================] - 11s 192us/step - loss: 0.1916 - acc: 0.9421\n",
            "Epoch 4/30\n",
            "56590/56590 [==============================] - 11s 193us/step - loss: 0.1732 - acc: 0.9462\n",
            "Epoch 5/30\n",
            "56590/56590 [==============================] - 11s 192us/step - loss: 0.1640 - acc: 0.9476\n",
            "Epoch 6/30\n",
            "56590/56590 [==============================] - 11s 191us/step - loss: 0.1568 - acc: 0.9496\n",
            "Epoch 7/30\n",
            "56590/56590 [==============================] - 11s 193us/step - loss: 0.1484 - acc: 0.9516\n",
            "Epoch 8/30\n",
            "56590/56590 [==============================] - 11s 194us/step - loss: 0.1437 - acc: 0.9525\n",
            "Epoch 9/30\n",
            "56590/56590 [==============================] - 11s 191us/step - loss: 0.1384 - acc: 0.9540\n",
            "Epoch 10/30\n",
            "56590/56590 [==============================] - 11s 194us/step - loss: 0.1370 - acc: 0.9550\n",
            "Epoch 11/30\n",
            "56590/56590 [==============================] - 11s 191us/step - loss: 0.1351 - acc: 0.9546\n",
            "Epoch 12/30\n",
            "56590/56590 [==============================] - 11s 192us/step - loss: 0.1342 - acc: 0.9555\n",
            "Epoch 13/30\n",
            "56590/56590 [==============================] - 11s 192us/step - loss: 0.1292 - acc: 0.9574\n",
            "Epoch 14/30\n",
            "56590/56590 [==============================] - 11s 192us/step - loss: 0.1296 - acc: 0.9568\n",
            "Epoch 15/30\n",
            "56590/56590 [==============================] - 11s 201us/step - loss: 0.1247 - acc: 0.9581\n",
            "Epoch 16/30\n",
            "56590/56590 [==============================] - 11s 192us/step - loss: 0.1284 - acc: 0.9569\n",
            "Epoch 17/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.1257 - acc: 0.9573\n",
            "Epoch 18/30\n",
            "56590/56590 [==============================] - 11s 193us/step - loss: 0.1247 - acc: 0.9586\n",
            "Epoch 19/30\n",
            "56590/56590 [==============================] - 11s 194us/step - loss: 0.1236 - acc: 0.9579\n",
            "Epoch 20/30\n",
            "56590/56590 [==============================] - 11s 192us/step - loss: 0.1218 - acc: 0.9585\n",
            "Epoch 21/30\n",
            "56590/56590 [==============================] - 11s 191us/step - loss: 0.1227 - acc: 0.9588\n",
            "Epoch 22/30\n",
            "56590/56590 [==============================] - 11s 191us/step - loss: 0.1204 - acc: 0.9593\n",
            "Epoch 23/30\n",
            "56590/56590 [==============================] - 11s 192us/step - loss: 0.1192 - acc: 0.9600\n",
            "Epoch 24/30\n",
            "56590/56590 [==============================] - 11s 192us/step - loss: 0.1181 - acc: 0.9599\n",
            "Epoch 25/30\n",
            "56590/56590 [==============================] - 11s 191us/step - loss: 0.1219 - acc: 0.9582\n",
            "Epoch 26/30\n",
            "56590/56590 [==============================] - 11s 191us/step - loss: 0.1164 - acc: 0.9608\n",
            "Epoch 27/30\n",
            "56590/56590 [==============================] - 11s 195us/step - loss: 0.1184 - acc: 0.9606\n",
            "Epoch 28/30\n",
            "56590/56590 [==============================] - 11s 191us/step - loss: 0.1185 - acc: 0.9596\n",
            "Epoch 29/30\n",
            "56590/56590 [==============================] - 11s 192us/step - loss: 0.1203 - acc: 0.9598\n",
            "Epoch 30/30\n",
            "56590/56590 [==============================] - 11s 191us/step - loss: 0.1157 - acc: 0.9606\n",
            "Precision = 85.16, Recall = 84.12, F1 = 84.64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zutU__Z7AOmA",
        "colab_type": "code",
        "outputId": "eb43f23f-18c6-4a6d-c23f-c7dad7957394",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# future context of 9, kernel of 7\n",
        "context_size = 9\n",
        "kernel_size = 7\n",
        "cnn_input, cnn_labels = prepareFutureCNNGloveInput(words_train, context_size, train_label, embeddings_index)\n",
        "val_input, val_labels = prepareFutureCNNGloveInput(words_val, context_size, val_label, embeddings_index)\n",
        "model = get_glove_model(context_size, kernel_size)\n",
        "model.fit(cnn_input, cnn_labels, epochs=30)\n",
        "print_evaluation(model, val_input, val_labels, val_x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_21\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_22 (InputLayer)        (None, 9, 100)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_55 (Conv1D)           (None, 9, 100)            70100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_55 (MaxPooling (None, 4, 100)            0         \n",
            "_________________________________________________________________\n",
            "dropout_55 (Dropout)         (None, 4, 100)            0         \n",
            "_________________________________________________________________\n",
            "flatten_55 (Flatten)         (None, 400)               0         \n",
            "_________________________________________________________________\n",
            "dense_109 (Dense)            (None, 128)               51328     \n",
            "_________________________________________________________________\n",
            "dense_110 (Dense)            (None, 127)               16383     \n",
            "=================================================================\n",
            "Total params: 137,811\n",
            "Trainable params: 137,811\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "56590/56590 [==============================] - 16s 291us/step - loss: 0.5106 - acc: 0.8843\n",
            "Epoch 2/30\n",
            "56590/56590 [==============================] - 11s 192us/step - loss: 0.2296 - acc: 0.9356\n",
            "Epoch 3/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.1963 - acc: 0.9406\n",
            "Epoch 4/30\n",
            "56590/56590 [==============================] - 11s 192us/step - loss: 0.1790 - acc: 0.9444\n",
            "Epoch 5/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.1666 - acc: 0.9470\n",
            "Epoch 6/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.1609 - acc: 0.9481\n",
            "Epoch 7/30\n",
            "56590/56590 [==============================] - 11s 193us/step - loss: 0.1518 - acc: 0.9510\n",
            "Epoch 8/30\n",
            "56590/56590 [==============================] - 11s 192us/step - loss: 0.1495 - acc: 0.9515\n",
            "Epoch 9/30\n",
            "56590/56590 [==============================] - 11s 193us/step - loss: 0.1438 - acc: 0.9529\n",
            "Epoch 10/30\n",
            "56590/56590 [==============================] - 11s 194us/step - loss: 0.1424 - acc: 0.9537\n",
            "Epoch 11/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.1378 - acc: 0.9547\n",
            "Epoch 12/30\n",
            "56590/56590 [==============================] - 11s 195us/step - loss: 0.1368 - acc: 0.9542\n",
            "Epoch 13/30\n",
            "56590/56590 [==============================] - 11s 197us/step - loss: 0.1348 - acc: 0.9562\n",
            "Epoch 14/30\n",
            "56590/56590 [==============================] - 11s 193us/step - loss: 0.1315 - acc: 0.9556\n",
            "Epoch 15/30\n",
            "56590/56590 [==============================] - 11s 192us/step - loss: 0.1315 - acc: 0.9564\n",
            "Epoch 16/30\n",
            "56590/56590 [==============================] - 11s 191us/step - loss: 0.1308 - acc: 0.9562\n",
            "Epoch 17/30\n",
            "56590/56590 [==============================] - 11s 192us/step - loss: 0.1295 - acc: 0.9578\n",
            "Epoch 18/30\n",
            "56590/56590 [==============================] - 11s 191us/step - loss: 0.1293 - acc: 0.9567\n",
            "Epoch 19/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.1282 - acc: 0.9570\n",
            "Epoch 20/30\n",
            "56590/56590 [==============================] - 11s 192us/step - loss: 0.1238 - acc: 0.9589\n",
            "Epoch 21/30\n",
            "56590/56590 [==============================] - 11s 191us/step - loss: 0.1248 - acc: 0.9576\n",
            "Epoch 22/30\n",
            "56590/56590 [==============================] - 11s 191us/step - loss: 0.1253 - acc: 0.9581\n",
            "Epoch 23/30\n",
            "56590/56590 [==============================] - 11s 191us/step - loss: 0.1245 - acc: 0.9591\n",
            "Epoch 24/30\n",
            "56590/56590 [==============================] - 11s 194us/step - loss: 0.1237 - acc: 0.9586\n",
            "Epoch 25/30\n",
            "56590/56590 [==============================] - 11s 191us/step - loss: 0.1237 - acc: 0.9590\n",
            "Epoch 26/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.1222 - acc: 0.9586\n",
            "Epoch 27/30\n",
            "56590/56590 [==============================] - 11s 192us/step - loss: 0.1205 - acc: 0.9598\n",
            "Epoch 28/30\n",
            "56590/56590 [==============================] - 11s 192us/step - loss: 0.1197 - acc: 0.9601\n",
            "Epoch 29/30\n",
            "56590/56590 [==============================] - 11s 192us/step - loss: 0.1207 - acc: 0.9598\n",
            "Epoch 30/30\n",
            "56590/56590 [==============================] - 11s 191us/step - loss: 0.1192 - acc: 0.9607\n",
            "Precision = 85.44, Recall = 84.87, F1 = 85.16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dk9QepwuAopJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Man5et4ZAo2x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "O8dsWJWZA1X7"
      },
      "source": [
        "**Experiment with a window size of 3 using both the future and past context words and glove embedding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HE92VT_o-T55",
        "colab_type": "code",
        "outputId": "1a405244-21bb-4069-c665-c6b5bf93d1fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# past and future context of 3, kernel of 3\n",
        "context_size = 3\n",
        "kernel_size = 3\n",
        "cnn_input, cnn_labels = preparePastFutureCNNGloveInput(words_train, context_size, train_label, embeddings_index)\n",
        "val_input, val_labels = preparePastFutureCNNGloveInput(words_val, context_size, val_label, embeddings_index)\n",
        "model = get_glove_model(context_size, kernel_size)\n",
        "model.fit(cnn_input, cnn_labels, epochs=30)\n",
        "print_evaluation(model, val_input, val_labels, val_x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_22\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_23 (InputLayer)        (None, 3, 100)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_56 (Conv1D)           (None, 3, 100)            30100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_56 (MaxPooling (None, 1, 100)            0         \n",
            "_________________________________________________________________\n",
            "dropout_56 (Dropout)         (None, 1, 100)            0         \n",
            "_________________________________________________________________\n",
            "flatten_56 (Flatten)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_111 (Dense)            (None, 128)               12928     \n",
            "_________________________________________________________________\n",
            "dense_112 (Dense)            (None, 127)               16383     \n",
            "=================================================================\n",
            "Total params: 59,411\n",
            "Trainable params: 59,411\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "56590/56590 [==============================] - 16s 291us/step - loss: 0.3896 - acc: 0.9122\n",
            "Epoch 2/30\n",
            "56590/56590 [==============================] - 11s 192us/step - loss: 0.1672 - acc: 0.9516\n",
            "Epoch 3/30\n",
            "56590/56590 [==============================] - 11s 191us/step - loss: 0.1385 - acc: 0.9577\n",
            "Epoch 4/30\n",
            "56590/56590 [==============================] - 11s 191us/step - loss: 0.1227 - acc: 0.9610\n",
            "Epoch 5/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.1147 - acc: 0.9627\n",
            "Epoch 6/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.1094 - acc: 0.9640\n",
            "Epoch 7/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.1057 - acc: 0.9643\n",
            "Epoch 8/30\n",
            "56590/56590 [==============================] - 11s 193us/step - loss: 0.1011 - acc: 0.9648\n",
            "Epoch 9/30\n",
            "56590/56590 [==============================] - 11s 192us/step - loss: 0.0997 - acc: 0.9653\n",
            "Epoch 10/30\n",
            "56590/56590 [==============================] - 11s 196us/step - loss: 0.0961 - acc: 0.9662\n",
            "Epoch 11/30\n",
            "56590/56590 [==============================] - 11s 193us/step - loss: 0.0954 - acc: 0.9670\n",
            "Epoch 12/30\n",
            "56590/56590 [==============================] - 11s 192us/step - loss: 0.0919 - acc: 0.9676\n",
            "Epoch 13/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.0907 - acc: 0.9673\n",
            "Epoch 14/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.0895 - acc: 0.9682\n",
            "Epoch 15/30\n",
            "56590/56590 [==============================] - 11s 191us/step - loss: 0.0879 - acc: 0.9682\n",
            "Epoch 16/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.0873 - acc: 0.9684\n",
            "Epoch 17/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.0867 - acc: 0.9694\n",
            "Epoch 18/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.0847 - acc: 0.9692\n",
            "Epoch 19/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.0862 - acc: 0.9689\n",
            "Epoch 20/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.0835 - acc: 0.9696\n",
            "Epoch 21/30\n",
            "56590/56590 [==============================] - 11s 194us/step - loss: 0.0835 - acc: 0.9690\n",
            "Epoch 22/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.0826 - acc: 0.9692\n",
            "Epoch 23/30\n",
            "56590/56590 [==============================] - 11s 192us/step - loss: 0.0818 - acc: 0.9710\n",
            "Epoch 24/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.0833 - acc: 0.9701\n",
            "Epoch 25/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.0803 - acc: 0.9705\n",
            "Epoch 26/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.0796 - acc: 0.9704\n",
            "Epoch 27/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.0806 - acc: 0.9709\n",
            "Epoch 28/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.0813 - acc: 0.9702\n",
            "Epoch 29/30\n",
            "56590/56590 [==============================] - 11s 192us/step - loss: 0.0795 - acc: 0.9711\n",
            "Epoch 30/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.0796 - acc: 0.9706\n",
            "Precision = 87.59, Recall = 83.19, F1 = 85.34\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uW0o0I5hBjQb"
      },
      "source": [
        "**Experiment with a window size of 5 using both the future and past context words and glove embedding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZX2EeSumBA1f",
        "colab_type": "code",
        "outputId": "01ed0e73-1808-4f42-c72f-5460772f6470",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# past and future context of 5, kernel of 3\n",
        "context_size = 5\n",
        "kernel_size = 3\n",
        "cnn_input, cnn_labels = preparePastFutureCNNGloveInput(words_train, context_size, train_label, embeddings_index)\n",
        "val_input, val_labels = preparePastFutureCNNGloveInput(words_val, context_size, val_label, embeddings_index)\n",
        "model = get_glove_model(context_size, kernel_size)\n",
        "model.fit(cnn_input, cnn_labels, epochs=30)\n",
        "print_evaluation(model, val_input, val_labels, val_x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_23\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_24 (InputLayer)        (None, 5, 100)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_57 (Conv1D)           (None, 5, 100)            30100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_57 (MaxPooling (None, 2, 100)            0         \n",
            "_________________________________________________________________\n",
            "dropout_57 (Dropout)         (None, 2, 100)            0         \n",
            "_________________________________________________________________\n",
            "flatten_57 (Flatten)         (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_113 (Dense)            (None, 128)               25728     \n",
            "_________________________________________________________________\n",
            "dense_114 (Dense)            (None, 127)               16383     \n",
            "=================================================================\n",
            "Total params: 72,211\n",
            "Trainable params: 72,211\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "56590/56590 [==============================] - 17s 293us/step - loss: 0.3725 - acc: 0.9176\n",
            "Epoch 2/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.1355 - acc: 0.9621\n",
            "Epoch 3/30\n",
            "56590/56590 [==============================] - 11s 192us/step - loss: 0.1040 - acc: 0.9693\n",
            "Epoch 4/30\n",
            "56590/56590 [==============================] - 11s 193us/step - loss: 0.0900 - acc: 0.9722\n",
            "Epoch 5/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.0768 - acc: 0.9752\n",
            "Epoch 6/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.0724 - acc: 0.9768\n",
            "Epoch 7/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.0683 - acc: 0.9778\n",
            "Epoch 8/30\n",
            "56590/56590 [==============================] - 11s 193us/step - loss: 0.0658 - acc: 0.9786\n",
            "Epoch 9/30\n",
            "56590/56590 [==============================] - 11s 192us/step - loss: 0.0604 - acc: 0.9794\n",
            "Epoch 10/30\n",
            "56590/56590 [==============================] - 11s 191us/step - loss: 0.0585 - acc: 0.9804\n",
            "Epoch 11/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.0589 - acc: 0.9796\n",
            "Epoch 12/30\n",
            "56590/56590 [==============================] - 11s 191us/step - loss: 0.0548 - acc: 0.9812\n",
            "Epoch 13/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.0539 - acc: 0.9816\n",
            "Epoch 14/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.0517 - acc: 0.9816\n",
            "Epoch 15/30\n",
            "56590/56590 [==============================] - 11s 192us/step - loss: 0.0508 - acc: 0.9823\n",
            "Epoch 16/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0510 - acc: 0.9819\n",
            "Epoch 17/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.0507 - acc: 0.9824\n",
            "Epoch 18/30\n",
            "56590/56590 [==============================] - 11s 191us/step - loss: 0.0498 - acc: 0.9824\n",
            "Epoch 19/30\n",
            "56590/56590 [==============================] - 11s 192us/step - loss: 0.0483 - acc: 0.9832\n",
            "Epoch 20/30\n",
            "56590/56590 [==============================] - 11s 193us/step - loss: 0.0470 - acc: 0.9832\n",
            "Epoch 21/30\n",
            "56590/56590 [==============================] - 11s 191us/step - loss: 0.0461 - acc: 0.9840\n",
            "Epoch 22/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.0461 - acc: 0.9842\n",
            "Epoch 23/30\n",
            "56590/56590 [==============================] - 11s 191us/step - loss: 0.0453 - acc: 0.9836\n",
            "Epoch 24/30\n",
            "56590/56590 [==============================] - 11s 191us/step - loss: 0.0448 - acc: 0.9841\n",
            "Epoch 25/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.0444 - acc: 0.9843\n",
            "Epoch 26/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.0450 - acc: 0.9840\n",
            "Epoch 27/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.0427 - acc: 0.9853\n",
            "Epoch 28/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.0448 - acc: 0.9846\n",
            "Epoch 29/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.0455 - acc: 0.9836\n",
            "Epoch 30/30\n",
            "56590/56590 [==============================] - 11s 191us/step - loss: 0.0465 - acc: 0.9839\n",
            "Precision = 91.26, Recall = 89.28, F1 = 90.26\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDkN3y1_BBen",
        "colab_type": "code",
        "outputId": "59e1beb8-cc6f-4970-8183-322598db0cb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# past and future context of 5, kernel of 5\n",
        "context_size = 5\n",
        "kernel_size = 5\n",
        "cnn_input, cnn_labels = preparePastFutureCNNGloveInput(words_train, context_size, train_label, embeddings_index)\n",
        "val_input, val_labels = preparePastFutureCNNGloveInput(words_val, context_size, val_label, embeddings_index)\n",
        "model = get_glove_model(context_size, kernel_size)\n",
        "model.fit(cnn_input, cnn_labels, epochs=30)\n",
        "print_evaluation(model, val_input, val_labels, val_x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_24\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_25 (InputLayer)        (None, 5, 100)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_58 (Conv1D)           (None, 5, 100)            50100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_58 (MaxPooling (None, 2, 100)            0         \n",
            "_________________________________________________________________\n",
            "dropout_58 (Dropout)         (None, 2, 100)            0         \n",
            "_________________________________________________________________\n",
            "flatten_58 (Flatten)         (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_115 (Dense)            (None, 128)               25728     \n",
            "_________________________________________________________________\n",
            "dense_116 (Dense)            (None, 127)               16383     \n",
            "=================================================================\n",
            "Total params: 92,211\n",
            "Trainable params: 92,211\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "56590/56590 [==============================] - 17s 297us/step - loss: 0.3572 - acc: 0.9205\n",
            "Epoch 2/30\n",
            "56590/56590 [==============================] - 11s 191us/step - loss: 0.1311 - acc: 0.9644\n",
            "Epoch 3/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.0996 - acc: 0.9706\n",
            "Epoch 4/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.0849 - acc: 0.9740\n",
            "Epoch 5/30\n",
            "56590/56590 [==============================] - 10s 186us/step - loss: 0.0766 - acc: 0.9758\n",
            "Epoch 6/30\n",
            "56590/56590 [==============================] - 11s 197us/step - loss: 0.0697 - acc: 0.9772\n",
            "Epoch 7/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.0647 - acc: 0.9780\n",
            "Epoch 8/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.0624 - acc: 0.9788\n",
            "Epoch 9/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.0594 - acc: 0.9802\n",
            "Epoch 10/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.0554 - acc: 0.9810\n",
            "Epoch 11/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0554 - acc: 0.9808\n",
            "Epoch 12/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.0513 - acc: 0.9817\n",
            "Epoch 13/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.0524 - acc: 0.9820\n",
            "Epoch 14/30\n",
            "56590/56590 [==============================] - 11s 193us/step - loss: 0.0498 - acc: 0.9836\n",
            "Epoch 15/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.0507 - acc: 0.9823\n",
            "Epoch 16/30\n",
            "56590/56590 [==============================] - 11s 196us/step - loss: 0.0489 - acc: 0.9829\n",
            "Epoch 17/30\n",
            "56590/56590 [==============================] - 11s 192us/step - loss: 0.0477 - acc: 0.9835\n",
            "Epoch 18/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.0461 - acc: 0.9842\n",
            "Epoch 19/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0472 - acc: 0.9834\n",
            "Epoch 20/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.0457 - acc: 0.9848\n",
            "Epoch 21/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.0465 - acc: 0.9838\n",
            "Epoch 22/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.0449 - acc: 0.9844\n",
            "Epoch 23/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0466 - acc: 0.9836\n",
            "Epoch 24/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.0439 - acc: 0.9850\n",
            "Epoch 25/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.0438 - acc: 0.9852\n",
            "Epoch 26/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0434 - acc: 0.9849\n",
            "Epoch 27/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0432 - acc: 0.9850\n",
            "Epoch 28/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0435 - acc: 0.9851\n",
            "Epoch 29/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0449 - acc: 0.9846\n",
            "Epoch 30/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0419 - acc: 0.9857\n",
            "Precision = 90.27, Recall = 88.31, F1 = 89.28\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Pf9cD6x2BnvW"
      },
      "source": [
        "**Experiment with a window size of 7 using both the future and past context words and glove embedding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "og0LVBdhBBQx",
        "colab_type": "code",
        "outputId": "b4e6aecf-6d89-4bf5-d73d-a33d47350b2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# past and future context of 7, kernel of 3\n",
        "context_size = 7\n",
        "kernel_size = 3\n",
        "cnn_input, cnn_labels = preparePastFutureCNNGloveInput(words_train, context_size, train_label, embeddings_index)\n",
        "val_input, val_labels = preparePastFutureCNNGloveInput(words_val, context_size, val_label, embeddings_index)\n",
        "model = get_glove_model(context_size, kernel_size)\n",
        "model.fit(cnn_input, cnn_labels, epochs=30)\n",
        "print_evaluation(model, val_input, val_labels, val_x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_25\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_26 (InputLayer)        (None, 7, 100)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_59 (Conv1D)           (None, 7, 100)            30100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_59 (MaxPooling (None, 3, 100)            0         \n",
            "_________________________________________________________________\n",
            "dropout_59 (Dropout)         (None, 3, 100)            0         \n",
            "_________________________________________________________________\n",
            "flatten_59 (Flatten)         (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dense_117 (Dense)            (None, 128)               38528     \n",
            "_________________________________________________________________\n",
            "dense_118 (Dense)            (None, 127)               16383     \n",
            "=================================================================\n",
            "Total params: 85,011\n",
            "Trainable params: 85,011\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "56590/56590 [==============================] - 16s 289us/step - loss: 0.4000 - acc: 0.9115\n",
            "Epoch 2/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.1359 - acc: 0.9633\n",
            "Epoch 3/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0989 - acc: 0.9719\n",
            "Epoch 4/30\n",
            "56590/56590 [==============================] - 11s 194us/step - loss: 0.0818 - acc: 0.9755\n",
            "Epoch 5/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0702 - acc: 0.9784\n",
            "Epoch 6/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0628 - acc: 0.9800\n",
            "Epoch 7/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0594 - acc: 0.9809\n",
            "Epoch 8/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.0529 - acc: 0.9830\n",
            "Epoch 9/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0534 - acc: 0.9823\n",
            "Epoch 10/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0483 - acc: 0.9841\n",
            "Epoch 11/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0467 - acc: 0.9850\n",
            "Epoch 12/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.0473 - acc: 0.9844\n",
            "Epoch 13/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0442 - acc: 0.9852\n",
            "Epoch 14/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.0438 - acc: 0.9857\n",
            "Epoch 15/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0418 - acc: 0.9860\n",
            "Epoch 16/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0392 - acc: 0.9865\n",
            "Epoch 17/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0396 - acc: 0.9868\n",
            "Epoch 18/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.0381 - acc: 0.9873\n",
            "Epoch 19/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0391 - acc: 0.9879\n",
            "Epoch 20/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0375 - acc: 0.9875\n",
            "Epoch 21/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0378 - acc: 0.9872\n",
            "Epoch 22/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.0369 - acc: 0.9884\n",
            "Epoch 23/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.0375 - acc: 0.9877\n",
            "Epoch 24/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.0348 - acc: 0.9886\n",
            "Epoch 25/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.0369 - acc: 0.9876\n",
            "Epoch 26/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0373 - acc: 0.9884\n",
            "Epoch 27/30\n",
            "56590/56590 [==============================] - 10s 183us/step - loss: 0.0352 - acc: 0.9890\n",
            "Epoch 28/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0353 - acc: 0.9886\n",
            "Epoch 29/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0337 - acc: 0.9889\n",
            "Epoch 30/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0373 - acc: 0.9885\n",
            "Precision = 91.82, Recall = 90.89, F1 = 91.36\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lt5Ikv9EBBOD",
        "colab_type": "code",
        "outputId": "d2a36f13-e8fa-4b77-ec1a-55fe645a34d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# past and future context of 7, kernel of 5\n",
        "context_size = 7\n",
        "kernel_size = 5\n",
        "cnn_input, cnn_labels = preparePastFutureCNNGloveInput(words_train, context_size, train_label, embeddings_index)\n",
        "val_input, val_labels = preparePastFutureCNNGloveInput(words_val, context_size, val_label, embeddings_index)\n",
        "model = get_glove_model(context_size, kernel_size)\n",
        "model.fit(cnn_input, cnn_labels, epochs=30)\n",
        "print_evaluation(model, val_input, val_labels, val_x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_26\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_27 (InputLayer)        (None, 7, 100)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_60 (Conv1D)           (None, 7, 100)            50100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_60 (MaxPooling (None, 3, 100)            0         \n",
            "_________________________________________________________________\n",
            "dropout_60 (Dropout)         (None, 3, 100)            0         \n",
            "_________________________________________________________________\n",
            "flatten_60 (Flatten)         (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dense_119 (Dense)            (None, 128)               38528     \n",
            "_________________________________________________________________\n",
            "dense_120 (Dense)            (None, 127)               16383     \n",
            "=================================================================\n",
            "Total params: 105,011\n",
            "Trainable params: 105,011\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "56590/56590 [==============================] - 16s 289us/step - loss: 0.3666 - acc: 0.9182\n",
            "Epoch 2/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.1258 - acc: 0.9652\n",
            "Epoch 3/30\n",
            "56590/56590 [==============================] - 11s 192us/step - loss: 0.0940 - acc: 0.9733\n",
            "Epoch 4/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.0759 - acc: 0.9772\n",
            "Epoch 5/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0673 - acc: 0.9795\n",
            "Epoch 6/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0594 - acc: 0.9809\n",
            "Epoch 7/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0551 - acc: 0.9819\n",
            "Epoch 8/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0484 - acc: 0.9844\n",
            "Epoch 9/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0471 - acc: 0.9848\n",
            "Epoch 10/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0448 - acc: 0.9854\n",
            "Epoch 11/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0449 - acc: 0.9850\n",
            "Epoch 12/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.0405 - acc: 0.9867\n",
            "Epoch 13/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0416 - acc: 0.9866\n",
            "Epoch 14/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0410 - acc: 0.9865\n",
            "Epoch 15/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0383 - acc: 0.9870\n",
            "Epoch 16/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0378 - acc: 0.9876\n",
            "Epoch 17/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0358 - acc: 0.9880\n",
            "Epoch 18/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0373 - acc: 0.9877\n",
            "Epoch 19/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.0343 - acc: 0.9887\n",
            "Epoch 20/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0358 - acc: 0.9887\n",
            "Epoch 21/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0345 - acc: 0.9888\n",
            "Epoch 22/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0327 - acc: 0.9893\n",
            "Epoch 23/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.0334 - acc: 0.9892\n",
            "Epoch 24/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0349 - acc: 0.9896\n",
            "Epoch 25/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0333 - acc: 0.9895\n",
            "Epoch 26/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0353 - acc: 0.9890\n",
            "Epoch 27/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0343 - acc: 0.9893\n",
            "Epoch 28/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0341 - acc: 0.9895\n",
            "Epoch 29/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0337 - acc: 0.9895\n",
            "Epoch 30/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0348 - acc: 0.9894\n",
            "Precision = 92.07, Recall = 91.62, F1 = 91.84\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8k0U4YUYBBMn",
        "colab_type": "code",
        "outputId": "05d4fe2b-df75-4359-9e42-dcc9774fe1a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# past and future context of 7, kernel of 7\n",
        "context_size = 7\n",
        "kernel_size = 7\n",
        "cnn_input, cnn_labels = preparePastFutureCNNGloveInput(words_train, context_size, train_label, embeddings_index)\n",
        "val_input, val_labels = preparePastFutureCNNGloveInput(words_val, context_size, val_label, embeddings_index)\n",
        "model = get_glove_model(context_size, kernel_size)\n",
        "model.fit(cnn_input, cnn_labels, epochs=30)\n",
        "print_evaluation(model, val_input, val_labels, val_x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_27\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_28 (InputLayer)        (None, 7, 100)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_61 (Conv1D)           (None, 7, 100)            70100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_61 (MaxPooling (None, 3, 100)            0         \n",
            "_________________________________________________________________\n",
            "dropout_61 (Dropout)         (None, 3, 100)            0         \n",
            "_________________________________________________________________\n",
            "flatten_61 (Flatten)         (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dense_121 (Dense)            (None, 128)               38528     \n",
            "_________________________________________________________________\n",
            "dense_122 (Dense)            (None, 127)               16383     \n",
            "=================================================================\n",
            "Total params: 125,011\n",
            "Trainable params: 125,011\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "56590/56590 [==============================] - 17s 299us/step - loss: 0.3517 - acc: 0.9215\n",
            "Epoch 2/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.1205 - acc: 0.9671\n",
            "Epoch 3/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0909 - acc: 0.9734\n",
            "Epoch 4/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0731 - acc: 0.9783\n",
            "Epoch 5/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0638 - acc: 0.9801\n",
            "Epoch 6/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0570 - acc: 0.9816\n",
            "Epoch 7/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0502 - acc: 0.9837\n",
            "Epoch 8/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0502 - acc: 0.9833\n",
            "Epoch 9/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0446 - acc: 0.9851\n",
            "Epoch 10/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0439 - acc: 0.9851\n",
            "Epoch 11/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0414 - acc: 0.9870\n",
            "Epoch 12/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0408 - acc: 0.9869\n",
            "Epoch 13/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0407 - acc: 0.9874\n",
            "Epoch 14/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0385 - acc: 0.9872\n",
            "Epoch 15/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.0375 - acc: 0.9877\n",
            "Epoch 16/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.0391 - acc: 0.9876\n",
            "Epoch 17/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0356 - acc: 0.9885\n",
            "Epoch 18/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0341 - acc: 0.9894\n",
            "Epoch 19/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0374 - acc: 0.9882\n",
            "Epoch 20/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0354 - acc: 0.9888\n",
            "Epoch 21/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.0340 - acc: 0.9892\n",
            "Epoch 22/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0347 - acc: 0.9889\n",
            "Epoch 23/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0323 - acc: 0.9895\n",
            "Epoch 24/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.0335 - acc: 0.9894\n",
            "Epoch 25/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0345 - acc: 0.9893\n",
            "Epoch 26/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0314 - acc: 0.9900\n",
            "Epoch 27/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.0330 - acc: 0.9899\n",
            "Epoch 28/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0308 - acc: 0.9900\n",
            "Epoch 29/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.0308 - acc: 0.9907\n",
            "Epoch 30/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.0311 - acc: 0.9904\n",
            "Precision = 92.28, Recall = 91.8, F1 = 92.04\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hOGB7Jy1BsBr"
      },
      "source": [
        "**Experiment with a window size of 9 using both the future and past context words and glove embedding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7E2ry2dTBBK_",
        "colab_type": "code",
        "outputId": "32022d23-7491-4af0-c645-06bc31fd27a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# past and future context of 9, kernel of 3\n",
        "context_size = 9\n",
        "kernel_size = 3\n",
        "cnn_input, cnn_labels = preparePastFutureCNNGloveInput(words_train, context_size, train_label, embeddings_index)\n",
        "val_input, val_labels = preparePastFutureCNNGloveInput(words_val, context_size, val_label, embeddings_index)\n",
        "model = get_glove_model(context_size, kernel_size)\n",
        "model.fit(cnn_input, cnn_labels, epochs=30)\n",
        "print_evaluation(model, val_input, val_labels, val_x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_28\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_29 (InputLayer)        (None, 9, 100)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_62 (Conv1D)           (None, 9, 100)            30100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_62 (MaxPooling (None, 4, 100)            0         \n",
            "_________________________________________________________________\n",
            "dropout_62 (Dropout)         (None, 4, 100)            0         \n",
            "_________________________________________________________________\n",
            "flatten_62 (Flatten)         (None, 400)               0         \n",
            "_________________________________________________________________\n",
            "dense_123 (Dense)            (None, 128)               51328     \n",
            "_________________________________________________________________\n",
            "dense_124 (Dense)            (None, 127)               16383     \n",
            "=================================================================\n",
            "Total params: 97,811\n",
            "Trainable params: 97,811\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "56590/56590 [==============================] - 17s 293us/step - loss: 0.4138 - acc: 0.9077\n",
            "Epoch 2/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.1339 - acc: 0.9633\n",
            "Epoch 3/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.0966 - acc: 0.9723\n",
            "Epoch 4/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.0764 - acc: 0.9770\n",
            "Epoch 5/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.0646 - acc: 0.9800\n",
            "Epoch 6/30\n",
            "56590/56590 [==============================] - 11s 191us/step - loss: 0.0585 - acc: 0.9819\n",
            "Epoch 7/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.0507 - acc: 0.9837\n",
            "Epoch 8/30\n",
            "56590/56590 [==============================] - 11s 192us/step - loss: 0.0510 - acc: 0.9839\n",
            "Epoch 9/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.0434 - acc: 0.9854\n",
            "Epoch 10/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.0417 - acc: 0.9870\n",
            "Epoch 11/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.0387 - acc: 0.9876\n",
            "Epoch 12/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.0379 - acc: 0.9878\n",
            "Epoch 13/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.0374 - acc: 0.9875\n",
            "Epoch 14/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0370 - acc: 0.9885\n",
            "Epoch 15/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0360 - acc: 0.9882\n",
            "Epoch 16/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0330 - acc: 0.9888\n",
            "Epoch 17/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0347 - acc: 0.9891\n",
            "Epoch 18/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0312 - acc: 0.9898\n",
            "Epoch 19/30\n",
            "56590/56590 [==============================] - 11s 192us/step - loss: 0.0348 - acc: 0.9889\n",
            "Epoch 20/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.0305 - acc: 0.9903\n",
            "Epoch 21/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.0341 - acc: 0.9890\n",
            "Epoch 22/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0315 - acc: 0.9901\n",
            "Epoch 23/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.0303 - acc: 0.9905\n",
            "Epoch 24/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.0331 - acc: 0.9899\n",
            "Epoch 25/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.0307 - acc: 0.9905\n",
            "Epoch 26/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.0326 - acc: 0.9906\n",
            "Epoch 27/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0308 - acc: 0.9906\n",
            "Epoch 28/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.0315 - acc: 0.9904\n",
            "Epoch 29/30\n",
            "56590/56590 [==============================] - 11s 193us/step - loss: 0.0275 - acc: 0.9916\n",
            "Epoch 30/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.0269 - acc: 0.9912\n",
            "Precision = 93.23, Recall = 93.0, F1 = 93.12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TKM-bawBBED",
        "colab_type": "code",
        "outputId": "7322dd18-a828-4e9b-989b-879dc4193413",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# past and future context of 9, kernel of 5\n",
        "context_size = 9\n",
        "kernel_size = 5\n",
        "cnn_input, cnn_labels = preparePastFutureCNNGloveInput(words_train, context_size, train_label, embeddings_index)\n",
        "val_input, val_labels = preparePastFutureCNNGloveInput(words_val, context_size, val_label, embeddings_index)\n",
        "model = get_glove_model(context_size, kernel_size)\n",
        "model.fit(cnn_input, cnn_labels, epochs=30)\n",
        "print_evaluation(model, val_input, val_labels, val_x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_29\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_30 (InputLayer)        (None, 9, 100)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_63 (Conv1D)           (None, 9, 100)            50100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_63 (MaxPooling (None, 4, 100)            0         \n",
            "_________________________________________________________________\n",
            "dropout_63 (Dropout)         (None, 4, 100)            0         \n",
            "_________________________________________________________________\n",
            "flatten_63 (Flatten)         (None, 400)               0         \n",
            "_________________________________________________________________\n",
            "dense_125 (Dense)            (None, 128)               51328     \n",
            "_________________________________________________________________\n",
            "dense_126 (Dense)            (None, 127)               16383     \n",
            "=================================================================\n",
            "Total params: 117,811\n",
            "Trainable params: 117,811\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "56590/56590 [==============================] - 17s 294us/step - loss: 0.4033 - acc: 0.9100\n",
            "Epoch 2/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.1363 - acc: 0.9634\n",
            "Epoch 3/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0955 - acc: 0.9728\n",
            "Epoch 4/30\n",
            "56590/56590 [==============================] - 10s 186us/step - loss: 0.0768 - acc: 0.9771\n",
            "Epoch 5/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.0661 - acc: 0.9798\n",
            "Epoch 6/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0587 - acc: 0.9815\n",
            "Epoch 7/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0527 - acc: 0.9837\n",
            "Epoch 8/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0480 - acc: 0.9843\n",
            "Epoch 9/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.0467 - acc: 0.9849\n",
            "Epoch 10/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0423 - acc: 0.9864\n",
            "Epoch 11/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0420 - acc: 0.9864\n",
            "Epoch 12/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0405 - acc: 0.9876\n",
            "Epoch 13/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0370 - acc: 0.9882\n",
            "Epoch 14/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0382 - acc: 0.9875\n",
            "Epoch 15/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0353 - acc: 0.9884\n",
            "Epoch 16/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.0374 - acc: 0.9880\n",
            "Epoch 17/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0366 - acc: 0.9887\n",
            "Epoch 18/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0344 - acc: 0.9895\n",
            "Epoch 19/30\n",
            "56590/56590 [==============================] - 10s 186us/step - loss: 0.0372 - acc: 0.9892\n",
            "Epoch 20/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0321 - acc: 0.9905\n",
            "Epoch 21/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0356 - acc: 0.9894\n",
            "Epoch 22/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0357 - acc: 0.9899\n",
            "Epoch 23/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0338 - acc: 0.9902\n",
            "Epoch 24/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0356 - acc: 0.9895\n",
            "Epoch 25/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0354 - acc: 0.9896\n",
            "Epoch 26/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.0320 - acc: 0.9904\n",
            "Epoch 27/30\n",
            "56590/56590 [==============================] - 11s 193us/step - loss: 0.0340 - acc: 0.9900\n",
            "Epoch 28/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0338 - acc: 0.9899\n",
            "Epoch 29/30\n",
            "56590/56590 [==============================] - 10s 184us/step - loss: 0.0331 - acc: 0.9906\n",
            "Epoch 30/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0350 - acc: 0.9902\n",
            "Precision = 92.35, Recall = 91.74, F1 = 92.04\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0aZGYfYBBAt",
        "colab_type": "code",
        "outputId": "435e6057-5f95-4b6b-c46b-246759d461e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# past and future context of 9, kernel of 7\n",
        "context_size = 9\n",
        "kernel_size = 7\n",
        "cnn_input, cnn_labels = preparePastFutureCNNGloveInput(words_train, context_size, train_label, embeddings_index)\n",
        "val_input, val_labels = preparePastFutureCNNGloveInput(words_val, context_size, val_label, embeddings_index)\n",
        "model = get_glove_model(context_size, kernel_size)\n",
        "model.fit(cnn_input, cnn_labels, epochs=30)\n",
        "print_evaluation(model, val_input, val_labels, val_x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_30\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_31 (InputLayer)        (None, 9, 100)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_64 (Conv1D)           (None, 9, 100)            70100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_64 (MaxPooling (None, 4, 100)            0         \n",
            "_________________________________________________________________\n",
            "dropout_64 (Dropout)         (None, 4, 100)            0         \n",
            "_________________________________________________________________\n",
            "flatten_64 (Flatten)         (None, 400)               0         \n",
            "_________________________________________________________________\n",
            "dense_127 (Dense)            (None, 128)               51328     \n",
            "_________________________________________________________________\n",
            "dense_128 (Dense)            (None, 127)               16383     \n",
            "=================================================================\n",
            "Total params: 137,811\n",
            "Trainable params: 137,811\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "56590/56590 [==============================] - 17s 297us/step - loss: 0.3653 - acc: 0.9176\n",
            "Epoch 2/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.1206 - acc: 0.9672\n",
            "Epoch 3/30\n",
            "56590/56590 [==============================] - 11s 194us/step - loss: 0.0832 - acc: 0.9754\n",
            "Epoch 4/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.0705 - acc: 0.9788\n",
            "Epoch 5/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.0592 - acc: 0.9816\n",
            "Epoch 6/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0525 - acc: 0.9838\n",
            "Epoch 7/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.0467 - acc: 0.9854\n",
            "Epoch 8/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0455 - acc: 0.9856\n",
            "Epoch 9/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.0409 - acc: 0.9873\n",
            "Epoch 10/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0398 - acc: 0.9874\n",
            "Epoch 11/30\n",
            "56590/56590 [==============================] - 11s 190us/step - loss: 0.0373 - acc: 0.9882\n",
            "Epoch 12/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0377 - acc: 0.9884\n",
            "Epoch 13/30\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.0321 - acc: 0.9899\n",
            "Epoch 14/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0372 - acc: 0.9887\n",
            "Epoch 15/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0331 - acc: 0.9899\n",
            "Epoch 16/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0341 - acc: 0.9895\n",
            "Epoch 17/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0328 - acc: 0.9895\n",
            "Epoch 18/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0307 - acc: 0.9907\n",
            "Epoch 19/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0299 - acc: 0.9907\n",
            "Epoch 20/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0303 - acc: 0.9912\n",
            "Epoch 21/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0297 - acc: 0.9911\n",
            "Epoch 22/30\n",
            "56590/56590 [==============================] - 11s 189us/step - loss: 0.0311 - acc: 0.9910\n",
            "Epoch 23/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.0309 - acc: 0.9912\n",
            "Epoch 24/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.0290 - acc: 0.9915\n",
            "Epoch 25/30\n",
            "56590/56590 [==============================] - 11s 192us/step - loss: 0.0317 - acc: 0.9911\n",
            "Epoch 26/30\n",
            "56590/56590 [==============================] - 10s 185us/step - loss: 0.0320 - acc: 0.9912\n",
            "Epoch 27/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.0289 - acc: 0.9921\n",
            "Epoch 28/30\n",
            "56590/56590 [==============================] - 11s 187us/step - loss: 0.0278 - acc: 0.9923\n",
            "Epoch 29/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.0292 - acc: 0.9921\n",
            "Epoch 30/30\n",
            "56590/56590 [==============================] - 11s 188us/step - loss: 0.0294 - acc: 0.9922\n",
            "Precision = 92.32, Recall = 92.19, F1 = 92.25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsW-Fp2iBA8q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSzLEoLxupQs",
        "colab_type": "text"
      },
      "source": [
        "# **2D-CNN Models**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9l9urBW8icVS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "glove_file = 'glove.6B.100d.txt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYSplewj_BY6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Load the embeddings file\n",
        "import numpy as np\n",
        "def loadGloveModel(gloveFile):\n",
        "    print(\"Loading Glove Model\")\n",
        "    f = open(gloveFile,'r')\n",
        "    model = {}\n",
        "    for line in f:\n",
        "        splitLine = line.split()\n",
        "        word = splitLine[0]\n",
        "        embedding = np.array([float(val) for val in splitLine[1:]])\n",
        "        model[word] = embedding\n",
        "    print(\"Done.\",len(model),\" words loaded!\")\n",
        "    return model\n",
        "\n",
        "##################Loading the Glove Model into a dictionary#######################\n",
        "glove_model = loadGloveModel(glove_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTRRnVL8vWtR",
        "colab_type": "text"
      },
      "source": [
        "## **CNN - Past Context + GLoVE Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YmLjGudaeX6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################### For past CNN using Glove Embeddings ###############################\n",
        "'''\n",
        "Using glove Embeddings here\n",
        "For any given word, take a window of n words, i.e. n-1 previous words and the current word\n",
        "Also, to give weight to the current word for which the label is being predicted, take a context surrounding the current word\n",
        "'''\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def preparePastCNNGloveInput(sentences_list, window_size, labels):\n",
        "  cnn_input = []\n",
        "  cnn_labels = []\n",
        "  for sentence in sentences_list:\n",
        "    #prepend a pad word to the beginning of the sentence\n",
        "    sentence = ['padding'] * (window_size - 1) + sentence\n",
        "    #Now for each word, take the (window_size - 1) previous words and itself, and form an embedding representation of each word\n",
        "    for i in range(window_size - 1, len(sentence)):\n",
        "      words_list = sentence[i-window_size+1:i+1]\n",
        "      embedding = np.zeros(shape=(window_size,100))\n",
        "      for j in range(window_size):\n",
        "        if words_list[j] in glove_model:\n",
        "          embedding[j, :] = glove_model[words_list[j]]\n",
        "      cnn_input.append(embedding)\n",
        "\n",
        "  for label in labels:\n",
        "    for temp in label:\n",
        "      cnn_labels.append(temp)\n",
        "  return cnn_input, cnn_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCSWGy2zsE1P",
        "colab_type": "code",
        "outputId": "87ba7706-3e48-47a2-ec6f-23f7a5eb61c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "cnn_glove_train_input, cnn_glove_train_labels = preparePastCNNGloveInput(words_train, 5, train_label)\n",
        "print(\"Training input length is {}\".format(len(cnn_glove_train_input)))\n",
        "\n",
        "cnn_glove_val_input, cnn_glove_val_labels = preparePastCNNGloveInput(words_val, 5, val_label)\n",
        "print(\"Test input length is {}\".format(len(cnn_glove_val_input)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training input length is 56590\n",
            "Test input length is 9198\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YZhe8zOmFBW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "############################# For context inputs #####################################\n",
        "'''\n",
        "To emphasise on the word for which the slot is being predicted, add the surrounding context words again after the\n",
        "max pooling layer to the CNN. \n",
        "'''\n",
        "import numpy as np\n",
        "#For any given word, consider a window of n words(previous) inclusing the current word as well\n",
        "def preparePastCNNGloveContextInput(sentences_list, cs):\n",
        "  context_input = []\n",
        "  for sentence in sentences_list:\n",
        "    #prepend a pad word to the beginning of the sentence\n",
        "    sentence = ['padding'] * cs + sentence + ['padding'] * cs\n",
        "    for i in range(cs, len(sentence)-cs):\n",
        "      words_list = sentence[i-cs:i+cs+1]\n",
        "      embedding = np.zeros(shape=(2*cs+1,100))\n",
        "      for j in range(2*cs+1):\n",
        "        if words_list[j] in glove_model:\n",
        "          embedding[j, :] = glove_model[words_list[j]]\n",
        "      context_input.append(embedding)\n",
        "  return context_input\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-A6uyDIVs5l3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "context_glove_train_input = preparePastCNNGloveContextInput(words_train, 3)\n",
        "context_glove_val_input = preparePastCNNGloveContextInput(words_val, 3)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHyTasKFtMHx",
        "colab_type": "code",
        "outputId": "815f7889-aa87-4b78-f94a-bedd5acd50bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "x_train = np.asarray(cnn_glove_train_input)\n",
        "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
        "print(\"Shape of x_train\", x_train.shape)\n",
        "y_train = np.asarray(cnn_glove_train_labels)\n",
        "print(\"Shape of y_train\", y_train.shape)\n",
        "\n",
        "x_val = np.asarray(cnn_glove_val_input)\n",
        "x_val = x_val.reshape(x_val.shape[0], x_val.shape[1], x_val.shape[2], 1)\n",
        "print(\"Shape of x_test\", x_val.shape)\n",
        "y_val = np.asarray(cnn_glove_val_labels)\n",
        "print(\"Shape of y_test\", y_val.shape)\n",
        "\n",
        "\n",
        "x_train_context = np.asarray(context_glove_train_input)\n",
        "x_train_context = x_train_context.reshape(x_train_context.shape[0], x_train_context.shape[1], x_train_context.shape[2], 1)\n",
        "print(\"Shape of x_train_context\", x_train_context.shape)\n",
        "\n",
        "x_val_context = np.asarray(context_glove_val_input)\n",
        "x_val_context = x_val_context.reshape(x_val_context.shape[0], x_val_context.shape[1], x_val_context.shape[2], 1)\n",
        "print(\"Shape of x_test_context\", x_val_context.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of x_train (56590, 5, 100, 1)\n",
            "Shape of y_train (56590,)\n",
            "Shape of x_test (9198, 5, 100, 1)\n",
            "Shape of y_test (9198,)\n",
            "Shape of x_train_context (56590, 7, 100, 1)\n",
            "Shape of x_test_context (9198, 7, 100, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYWSEoLzkhMP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################ Model architecture ##############\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D, Convolution1D, MaxPooling1D\n",
        "from keras.utils import np_utils\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.optimizers import *\n",
        "from keras import regularizers\n",
        "from keras import layers\n",
        "\n",
        "def sequentialCNNModel(window_size, cs):\n",
        "  input_tensor = layers.Input(shape=(window_size,100,1))\n",
        "  x = layers.Convolution2D(100, kernel_size=3, strides=1, activation='relu', padding='same')(input_tensor)\n",
        "  x = layers.MaxPooling2D(pool_size=(2,2))(x)\n",
        "  x = layers.Flatten()(x)\n",
        "\n",
        "  input_context = layers.Input(shape=(2*cs+1,100,1))\n",
        "  flatten_context = layers.Flatten()(input_context)\n",
        "\n",
        "  concat = layers.concatenate([x, flatten_context], axis=-1)\n",
        "  dense = layers.Dense(100, activation='relu')(concat)\n",
        "  output = layers.Dense(n_classes, activation ='softmax')(dense)\n",
        "  model = Model([input_tensor, input_context], output)\n",
        "  optim = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
        "  model.compile(loss='sparse_categorical_crossentropy', optimizer=optim, metrics=['accuracy'])\n",
        "  model.summary()\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtNRSwSvki17",
        "colab_type": "code",
        "outputId": "8d3d2208-29bf-4f3c-da42-bbaa48644995",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        }
      },
      "source": [
        "past_cnn_model = sequentialCNNModel(5, 3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_10 (InputLayer)           (None, 5, 100, 1)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 5, 100, 100)  1000        input_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 2, 50, 100)   0           conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "input_11 (InputLayer)           (None, 7, 100, 1)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_10 (Flatten)            (None, 10000)        0           max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_11 (Flatten)            (None, 700)          0           input_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 10700)        0           flatten_10[0][0]                 \n",
            "                                                                 flatten_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 100)          1070100     concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_10 (Dense)                (None, 127)          12827       dense_9[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 1,083,927\n",
            "Trainable params: 1,083,927\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CX9HeRgcuPmW",
        "colab_type": "code",
        "outputId": "970d5a3c-d1f0-48ab-a8e0-90317466d45b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "source": [
        "past_cnn_model.fit([x_train, x_train_context], y_train, epochs=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "56590/56590 [==============================] - 8s 143us/step - loss: 0.3405 - acc: 0.9280\n",
            "Epoch 2/10\n",
            "56590/56590 [==============================] - 8s 135us/step - loss: 0.0977 - acc: 0.9751\n",
            "Epoch 3/10\n",
            "56590/56590 [==============================] - 8s 135us/step - loss: 0.0636 - acc: 0.9824\n",
            "Epoch 4/10\n",
            "56590/56590 [==============================] - 8s 136us/step - loss: 0.0454 - acc: 0.9865\n",
            "Epoch 5/10\n",
            "56590/56590 [==============================] - 8s 135us/step - loss: 0.0359 - acc: 0.9889\n",
            "Epoch 6/10\n",
            "56590/56590 [==============================] - 8s 134us/step - loss: 0.0306 - acc: 0.9903\n",
            "Epoch 7/10\n",
            "56590/56590 [==============================] - 8s 133us/step - loss: 0.0251 - acc: 0.9925\n",
            "Epoch 8/10\n",
            "56590/56590 [==============================] - 7s 131us/step - loss: 0.0224 - acc: 0.9933\n",
            "Epoch 9/10\n",
            "56590/56590 [==============================] - 7s 130us/step - loss: 0.0208 - acc: 0.9934\n",
            "Epoch 10/10\n",
            "56590/56590 [==============================] - 8s 134us/step - loss: 0.0192 - acc: 0.9938\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6de890a940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPpEJ9QRXlhH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#For prediction\n",
        "from metrics.accuracy import conlleval\n",
        "\n",
        "def reportResults(model, x_val, x_val_context):\n",
        "  y_pred = model.predict([x_val, x_val_context])\n",
        "  y_pred_temp = [np.argmax(t) for t in y_pred]\n",
        "\n",
        "  labels_pred_val = []\n",
        "  k = 0\n",
        "  for x in val_x:\n",
        "    temp = []\n",
        "    for i in range(len(x)):\n",
        "      temp.append(y_pred_temp[k])\n",
        "      k = k + 1\n",
        "    labels_pred_val.append(temp)\n",
        "\n",
        "  labels_pred_val = [ list(map(lambda x: idx2la[x], y)) \\\n",
        "                                    for y in labels_pred_val]\n",
        "  con_dict = conlleval(labels_pred_val, labels_val, \n",
        "                            words_val, 'measure.txt')\n",
        "\n",
        "  print('Precision = {}, Recall = {}, F1 = {}'.format(\n",
        "              con_dict['r'], con_dict['p'], con_dict['f1']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKIK6gSEiMb1",
        "colab_type": "code",
        "outputId": "05f72a17-d9bd-45b0-9b65-8cc432024652",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(\"Results for the past CNN\")\n",
        "reportResults(past_cnn_model, x_val, x_val_context)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for the past CNN\n",
            "Precision = 91.26, Recall = 90.84, F1 = 91.05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YAA9f-Wwf5Y",
        "colab_type": "text"
      },
      "source": [
        "## **CNN - Future Context + GLoVE Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4upiqgjW4Kp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "######################### For future CNN ###############################\n",
        "\n",
        "def prepareFutureCNNGloveInput(sentences_list, window_size, labels):\n",
        "  cnn_input = []\n",
        "  cnn_labels = []\n",
        "  for sentence in sentences_list:\n",
        "    #prepend a pad word to the beginning of the sentence\n",
        "    sentence =  sentence + ['padding'] * (window_size - 1)\n",
        "    #Now for each word, take the (window_size - 1) previous words and itself, and form an embedding representation of each word\n",
        "    for i in range(0, len(sentence) - (window_size) + 1):\n",
        "      words_list = sentence[i:i+window_size]\n",
        "      embedding = np.zeros(shape=(window_size,100))\n",
        "      for j in range(window_size):\n",
        "        if words_list[j] in glove_model:\n",
        "          embedding[j, :] = glove_model[words_list[j]]\n",
        "      cnn_input.append(embedding)\n",
        "\n",
        "  for label in labels:\n",
        "    for temp in label:\n",
        "      cnn_labels.append(temp)\n",
        "  return cnn_input, cnn_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYiL9wkskLeB",
        "colab_type": "code",
        "outputId": "9cdc57a6-e9ba-43c0-8986-fae6893b03a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "cnn_glove_train_input, cnn_glove_train_labels = prepareFutureCNNGloveInput(words_train, 5, train_label)\n",
        "print(\"Training input length is {}\".format(len(cnn_glove_train_input)))\n",
        "\n",
        "cnn_glove_val_input, cnn_glove_val_labels = prepareFutureCNNGloveInput(words_val, 5, val_label)\n",
        "print(\"Test input length is {}\".format(len(cnn_glove_val_input)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training input length is 56590\n",
            "Test input length is 9198\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2rWJehJkQVK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "context_glove_train_input = preparePastCNNGloveContextInput(words_train, 3)\n",
        "context_glove_val_input = preparePastCNNGloveContextInput(words_val, 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdWi_a6skcNG",
        "colab_type": "code",
        "outputId": "40103261-9542-4781-d466-62ae167569ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "############## Preparing the Inputs ##############\n",
        "x_train = np.asarray(cnn_glove_train_input)\n",
        "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
        "print(\"Shape of x_train\", x_train.shape)\n",
        "y_train = np.asarray(cnn_glove_train_labels)\n",
        "print(\"Shape of y_train\", y_train.shape)\n",
        "\n",
        "x_val = np.asarray(cnn_glove_val_input)\n",
        "x_val = x_val.reshape(x_val.shape[0], x_val.shape[1], x_val.shape[2], 1)\n",
        "print(\"Shape of x_test\", x_val.shape)\n",
        "y_val = np.asarray(cnn_glove_val_labels)\n",
        "print(\"Shape of y_test\", y_val.shape)\n",
        "\n",
        "\n",
        "x_train_context = np.asarray(context_glove_train_input)\n",
        "x_train_context = x_train_context.reshape(x_train_context.shape[0], x_train_context.shape[1], x_train_context.shape[2], 1)\n",
        "print(\"Shape of x_train_context\", x_train_context.shape)\n",
        "\n",
        "x_val_context = np.asarray(context_glove_val_input)\n",
        "x_val_context = x_val_context.reshape(x_val_context.shape[0], x_val_context.shape[1], x_val_context.shape[2], 1)\n",
        "print(\"Shape of x_test_context\", x_val_context.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of x_train (56590, 5, 100, 1)\n",
            "Shape of y_train (56590,)\n",
            "Shape of x_test (9198, 5, 100, 1)\n",
            "Shape of y_test (9198,)\n",
            "Shape of x_train_context (56590, 7, 100, 1)\n",
            "Shape of x_test_context (9198, 7, 100, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7dbtyiQkxJH",
        "colab_type": "code",
        "outputId": "48a5c2da-2b28-470d-a6fb-fcc4cc6e66a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        }
      },
      "source": [
        "future_cnn_model = sequentialCNNModel(5, 3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            (None, 5, 100, 1)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 5, 100, 100)  1000        input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 2, 50, 100)   0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            (None, 7, 100, 1)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 10000)        0           max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_4 (Flatten)             (None, 700)          0           input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 10700)        0           flatten_3[0][0]                  \n",
            "                                                                 flatten_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 100)          1070100     concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 127)          12827       dense_3[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 1,083,927\n",
            "Trainable params: 1,083,927\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deXhDg-tk31p",
        "colab_type": "code",
        "outputId": "377b4d82-6c9e-41bf-994c-f1ad07e640d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "source": [
        "future_cnn_model.fit([x_train, x_train_context], y_train, epochs=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "56590/56590 [==============================] - 8s 141us/step - loss: 0.3087 - acc: 0.9315\n",
            "Epoch 2/10\n",
            "56590/56590 [==============================] - 8s 134us/step - loss: 0.1060 - acc: 0.9700\n",
            "Epoch 3/10\n",
            "56590/56590 [==============================] - 8s 134us/step - loss: 0.0762 - acc: 0.9767\n",
            "Epoch 4/10\n",
            "56590/56590 [==============================] - 8s 135us/step - loss: 0.0594 - acc: 0.9810\n",
            "Epoch 5/10\n",
            "56590/56590 [==============================] - 8s 134us/step - loss: 0.0490 - acc: 0.9842\n",
            "Epoch 6/10\n",
            "56590/56590 [==============================] - 8s 133us/step - loss: 0.0420 - acc: 0.9858\n",
            "Epoch 7/10\n",
            "56590/56590 [==============================] - 7s 130us/step - loss: 0.0372 - acc: 0.9878\n",
            "Epoch 8/10\n",
            "56590/56590 [==============================] - 7s 129us/step - loss: 0.0330 - acc: 0.9885\n",
            "Epoch 9/10\n",
            "56590/56590 [==============================] - 7s 132us/step - loss: 0.0290 - acc: 0.9902\n",
            "Epoch 10/10\n",
            "56590/56590 [==============================] - 7s 127us/step - loss: 0.0277 - acc: 0.9906\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6de82d01d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWLmYNJAlCkt",
        "colab_type": "code",
        "outputId": "1a62992d-50e3-40bf-971e-eb6b534830d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(\"Results for the future CNN\")\n",
        "reportResults(future_cnn_model, x_val, x_val_context)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for the future CNN\n",
            "Precision = 90.76, Recall = 90.22, F1 = 90.49\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9bCwoNZxGoO",
        "colab_type": "text"
      },
      "source": [
        "## **CNN - Bidirectional Context + GLoVE Model**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12j_KN0ByETa",
        "colab_type": "code",
        "outputId": "355a0d75-799b-47a7-8aea-07128719f55f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "############################### BiDirectional CNN #############################\n",
        "################### Preparing the inputs #####################\n",
        "\n",
        "cnn_past_train_input, cnn_past_train_labels = preparePastCNNGloveInput(words_train, 5, train_label)\n",
        "print(\"Training input length is {}\".format(len(cnn_past_train_input)))\n",
        "\n",
        "cnn_past_val_input, cnn_past_val_labels = preparePastCNNGloveInput(words_val, 5, val_label)\n",
        "print(\"Test input length is {}\".format(len(cnn_past_val_input)))\n",
        "\n",
        "cnn_future_train_input, cnn_future_train_labels = prepareFutureCNNGloveInput(words_train, 5, train_label)\n",
        "print(\"Training input length is {}\".format(len(cnn_future_train_input)))\n",
        "\n",
        "cnn_future_val_input, cnn_future_val_labels = prepareFutureCNNGloveInput(words_val, 5, val_label)\n",
        "print(\"Test input length is {}\".format(len(cnn_future_val_input)))\n",
        "\n",
        "context_train_input = preparePastCNNGloveContextInput(words_train, 3)\n",
        "context_val_input = preparePastCNNGloveContextInput(words_val, 3)\n",
        "\n",
        "x_train_past = np.asarray(cnn_past_train_input)\n",
        "x_train_past = x_train_past.reshape(x_train_past.shape[0], x_train_past.shape[1], x_train_past.shape[2], 1)\n",
        "\n",
        "x_train_future = np.asarray(cnn_future_train_input)\n",
        "x_train_future = x_train_future.reshape(x_train_future.shape[0], x_train_future.shape[1], x_train_future.shape[2], 1)\n",
        "\n",
        "y_train = np.asarray(cnn_future_train_labels)\n",
        "print(\"Shape of y_train\", y_train.shape)\n",
        "\n",
        "x_val_past = np.asarray(cnn_past_val_input)\n",
        "x_val_past = x_val_past.reshape(x_val_past.shape[0], x_val_past.shape[1], x_val_past.shape[2], 1)\n",
        "\n",
        "x_val_future = np.asarray(cnn_future_val_input)\n",
        "x_val_future = x_val_future.reshape(x_val_future.shape[0], x_val_future.shape[1], x_val_future.shape[2], 1)\n",
        "\n",
        "y_val = np.asarray(cnn_future_val_labels)\n",
        "print(\"Shape of y_test\", y_val.shape)\n",
        "\n",
        "\n",
        "x_train_context = np.asarray(context_train_input)\n",
        "x_train_context = x_train_context.reshape(x_train_context.shape[0], x_train_context.shape[1], x_train_context.shape[2], 1)\n",
        "print(\"Shape of x_train_context\", x_train_context.shape)\n",
        "\n",
        "x_val_context = np.asarray(context_val_input)\n",
        "x_val_context = x_val_context.reshape(x_val_context.shape[0], x_val_context.shape[1], x_val_context.shape[2], 1)\n",
        "print(\"Shape of x_test_context\", x_val_context.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training input length is 56590\n",
            "Test input length is 9198\n",
            "Training input length is 56590\n",
            "Test input length is 9198\n",
            "Shape of y_train (56590,)\n",
            "Shape of y_test (9198,)\n",
            "Shape of x_train_context (56590, 7, 100, 1)\n",
            "Shape of x_test_context (9198, 7, 100, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEIXUXXxt3_6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################ Model architecture ##############\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D, Convolution1D, MaxPooling1D\n",
        "from keras.utils import np_utils\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.optimizers import *\n",
        "from keras import regularizers\n",
        "from keras import layers\n",
        "\n",
        "def biSequentialCNNModel(window_size, cs):\n",
        "  input_tensor_past = layers.Input(shape=(window_size,100,1))\n",
        "  x = layers.Convolution2D(100, kernel_size=3, strides=1, activation='relu', padding='same')(input_tensor_past)\n",
        "  x = layers.MaxPooling2D(pool_size=(2,2))(x)\n",
        "  x = layers.Flatten()(x)\n",
        "\n",
        "  input_context = layers.Input(shape=(2*cs+1,100,1))\n",
        "  flatten_context = layers.Flatten()(input_context)\n",
        "\n",
        "  input_tensor_future = layers.Input(shape=(window_size,100,1))\n",
        "  x_future = layers.Convolution2D(100, kernel_size=3, strides=1, activation='relu', padding='same')(input_tensor_future)\n",
        "  x_future = layers.MaxPooling2D(pool_size=(2,2))(x_future)\n",
        "  x_future = layers.Flatten()(x_future)\n",
        "\n",
        "\n",
        "  concat_past = layers.concatenate([x, flatten_context], axis=-1)\n",
        "  concat_future = layers.concatenate([x_future, flatten_context], axis = -1)\n",
        "\n",
        "  concat = layers.concatenate([concat_past, concat_future], axis = -1)\n",
        "  dense = layers.Dense(100, activation='relu')(concat)\n",
        "  output = layers.Dense(n_classes, activation ='softmax')(dense)\n",
        "  model = Model([input_tensor_past, input_context, input_tensor_future], output)\n",
        "  optim = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
        "  model.compile(loss='sparse_categorical_crossentropy', optimizer=optim, metrics=['accuracy'])\n",
        "  model.summary()\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WRs9iUbtpWv",
        "colab_type": "code",
        "outputId": "60965c23-c365-4940-ccca-b75b31d18985",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        }
      },
      "source": [
        "bidirectional_cnn = biSequentialCNNModel(5, 3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_6\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_12 (InputLayer)           (None, 5, 100, 1)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_14 (InputLayer)           (None, 5, 100, 1)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 5, 100, 100)  1000        input_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 5, 100, 100)  1000        input_14[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, 2, 50, 100)   0           conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "input_13 (InputLayer)           (None, 7, 100, 1)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2D)  (None, 2, 50, 100)   0           conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "flatten_12 (Flatten)            (None, 10000)        0           max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_13 (Flatten)            (None, 700)          0           input_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "flatten_14 (Flatten)            (None, 10000)        0           max_pooling2d_8[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 10700)        0           flatten_12[0][0]                 \n",
            "                                                                 flatten_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 10700)        0           flatten_14[0][0]                 \n",
            "                                                                 flatten_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 21400)        0           concatenate_8[0][0]              \n",
            "                                                                 concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_11 (Dense)                (None, 100)          2140100     concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_12 (Dense)                (None, 127)          12827       dense_11[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 2,154,927\n",
            "Trainable params: 2,154,927\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKJYjWE6w0j5",
        "colab_type": "code",
        "outputId": "be81ae6a-f721-46d2-fde7-8227dce6e765",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "source": [
        "bidirectional_cnn.fit([x_train_past, x_train_context, x_train_future], y_train, epochs=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "56590/56590 [==============================] - 11s 186us/step - loss: 0.2891 - acc: 0.9372\n",
            "Epoch 2/10\n",
            "56590/56590 [==============================] - 10s 177us/step - loss: 0.0903 - acc: 0.9756\n",
            "Epoch 3/10\n",
            "56590/56590 [==============================] - 10s 176us/step - loss: 0.0600 - acc: 0.9826\n",
            "Epoch 4/10\n",
            "56590/56590 [==============================] - 10s 175us/step - loss: 0.0440 - acc: 0.9862\n",
            "Epoch 5/10\n",
            "56590/56590 [==============================] - 10s 178us/step - loss: 0.0346 - acc: 0.9889\n",
            "Epoch 6/10\n",
            "56590/56590 [==============================] - 10s 176us/step - loss: 0.0313 - acc: 0.9899\n",
            "Epoch 7/10\n",
            "56590/56590 [==============================] - 10s 176us/step - loss: 0.0250 - acc: 0.9920\n",
            "Epoch 8/10\n",
            "56590/56590 [==============================] - 10s 176us/step - loss: 0.0240 - acc: 0.9920\n",
            "Epoch 9/10\n",
            "56590/56590 [==============================] - 10s 177us/step - loss: 0.0222 - acc: 0.9929\n",
            "Epoch 10/10\n",
            "56590/56590 [==============================] - 10s 176us/step - loss: 0.0222 - acc: 0.9928\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6d01842cc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwUECqabxPCP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reportBiResults(model, x_val_past, x_val_context, x_val_future):\n",
        "  y_pred = model.predict([x_val_past, x_val_context, x_val_future])\n",
        "  y_pred_temp = [np.argmax(t) for t in y_pred]\n",
        "\n",
        "  labels_pred_val = []\n",
        "  k = 0\n",
        "  for x in val_x:\n",
        "    temp = []\n",
        "    for i in range(len(x)):\n",
        "      temp.append(y_pred_temp[k])\n",
        "      k = k + 1\n",
        "    labels_pred_val.append(temp)\n",
        "\n",
        "  labels_pred_val = [ list(map(lambda x: idx2la[x], y)) \\\n",
        "                                    for y in labels_pred_val]\n",
        "  con_dict = conlleval(labels_pred_val, labels_val, \n",
        "                            words_val, 'measure.txt')\n",
        "\n",
        "  print('Precision = {}, Recall = {}, F1 = {}'.format(\n",
        "              con_dict['r'], con_dict['p'], con_dict['f1']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzwehwXVxhc1",
        "colab_type": "code",
        "outputId": "8082c129-7fba-4987-8933-fa6235d4a9aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(\"Results for the bidirectional CNN\")\n",
        "reportBiResults(bidirectional_cnn, x_val_past, x_val_context, x_val_future)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for the bidirectional CNN\n",
            "Precision = 92.0, Recall = 90.28, F1 = 91.13\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxOd-709yDfO",
        "colab_type": "text"
      },
      "source": [
        "## **Sequential CNN - Past Context Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7xGbbG8F16B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###################### Sequential CNN using a Keras Embedding Layer ################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7PvqG3UF-iz",
        "colab_type": "code",
        "outputId": "517feb36-8469-4d15-ae41-737fd6b76dfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(n_vocab)\n",
        "n_vocab = n_vocab + 1\n",
        "print(n_vocab)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "572\n",
            "573\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmvN8JFMF7HO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################## Past CNN ##################\n",
        "\n",
        "def preparePastCNNInput(encoded_list, window_size, labels):\n",
        "  cnn_input = []\n",
        "  cnn_labels = []\n",
        "  for x in encoded_list:\n",
        "    x= np.insert(x, 0, [n_vocab-1] * (window_size - 1))\n",
        "    for i in range(window_size - 1, len(x)):\n",
        "      cnn_input.append(np.asarray(x[i-window_size+1:i+1]))\n",
        "\n",
        "  for label in labels:\n",
        "    for temp in label:\n",
        "      cnn_labels.append(temp)\n",
        "  return cnn_input, cnn_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TitIXAS4HFTi",
        "colab_type": "code",
        "outputId": "42c2e434-2717-40b9-8438-f3a4348f07ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "past_cnn_train_input, past_cnn_train_labels = preparePastCNNInput(train_x, 5, train_label)\n",
        "past_cnn_val_input, past_cnn_val_labels = preparePastCNNInput(val_x, 5, val_label)\n",
        "\n",
        "print(\"Training input size: \", len(past_cnn_train_input))\n",
        "print(\"Testing input size: \", len(past_cnn_val_input))\n",
        "\n",
        "print(\"Training input labels size: \", len(past_cnn_train_labels))\n",
        "print(\"Testing input labels size: \", len(past_cnn_val_labels))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training input size:  56590\n",
            "Testing input size:  9198\n",
            "Training input labels size:  56590\n",
            "Testing input labels size:  9198\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RysOdsYaH7B6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##################### Context input ###################\n",
        "def prepareCNNContextInput(encoded_list, cs):\n",
        "  context_input = []\n",
        "  for x in encoded_list:\n",
        "    x= np.insert(x, 0, [n_vocab-1] * (cs))\n",
        "    x = np.append(x, [n_vocab - 1] * cs)\n",
        "    for i in range(cs, len(x)-cs):\n",
        "      context_input.append(np.asarray(x[i-cs:i+cs+1]))\n",
        "  return context_input"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbaxaVWmIagj",
        "colab_type": "code",
        "outputId": "0b1bdc5e-1686-4ae9-bfde-4517b2955e78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "context_train_input = prepareCNNContextInput(train_x, 3)\n",
        "context_val_input = prepareCNNContextInput(val_x, 3)\n",
        "\n",
        "print(\"Context input train length: \", len(context_train_input))\n",
        "print(\"Context input test length: \", len(context_val_input))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Context input train length:  56590\n",
            "Context input test length:  9198\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXSMuG9CIzUa",
        "colab_type": "code",
        "outputId": "a1cafa56-06fa-41ba-db78-42a2f88f160c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "x_train = np.asarray(past_cnn_train_input)\n",
        "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], 1)\n",
        "print(\"Shape of x_train\", x_train.shape)\n",
        "y_train = np.asarray(past_cnn_train_labels)\n",
        "print(\"Shape of y_train\", y_train.shape)\n",
        "\n",
        "x_val = np.asarray(past_cnn_val_input)\n",
        "x_val = x_val.reshape(x_val.shape[0], x_val.shape[1], 1)\n",
        "print(\"Shape of x_test\", x_val.shape)\n",
        "y_val = np.asarray(past_cnn_val_labels)\n",
        "print(\"Shape of y_test\", y_val.shape)\n",
        "\n",
        "\n",
        "x_train_context = np.asarray(context_train_input)\n",
        "x_train_context = x_train_context.reshape(x_train_context.shape[0], x_train_context.shape[1], 1)\n",
        "print(\"Shape of x_train_context\", x_train_context.shape)\n",
        "\n",
        "x_val_context = np.asarray(context_val_input)\n",
        "x_val_context = x_val_context.reshape(x_val_context.shape[0], x_val_context.shape[1], 1)\n",
        "print(\"Shape of x_test_context\", x_val_context.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of x_train (56590, 5, 1)\n",
            "Shape of y_train (56590,)\n",
            "Shape of x_test (9198, 5, 1)\n",
            "Shape of y_test (9198,)\n",
            "Shape of x_train_context (56590, 7, 1)\n",
            "Shape of x_test_context (9198, 7, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lVXj4vLJl_T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################# Model architecture #######################\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D, Convolution1D, MaxPooling1D\n",
        "from keras.utils import np_utils\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.optimizers import *\n",
        "from keras import regularizers\n",
        "from keras import layers\n",
        "\n",
        "def sequentialCNNModel(window_size, cs):\n",
        "  input_tensor = layers.Input(shape=(window_size,1))\n",
        "  x = layers.Embedding(n_vocab,100)(input_tensor)\n",
        "  x = layers.Reshape((window_size, 100, 1))(x)\n",
        "  x = layers.Convolution2D(100, kernel_size=3, strides=1, activation='relu', padding='same')(x)\n",
        "  x = layers.MaxPooling2D(pool_size=(2,2))(x)\n",
        "  x = layers.Flatten()(x)\n",
        "\n",
        "  input_context = layers.Input(shape=(2*cs + 1,1))\n",
        "  context_embedding = layers.Embedding(n_vocab, 100)(input_context)\n",
        "  flatten_context = layers.Flatten()(context_embedding)\n",
        "\n",
        "  concat = layers.concatenate([x, flatten_context], axis=-1)\n",
        "  dense = layers.Dense(100, activation='relu')(concat)\n",
        "  output = layers.Dense(n_classes, activation ='softmax')(dense)\n",
        "  model = Model([input_tensor, input_context], output)\n",
        "  optim = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
        "  model.compile(loss='sparse_categorical_crossentropy', optimizer=optim, metrics=['accuracy'])\n",
        "  model.summary()\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vmy0Hn7rL1eX",
        "colab_type": "code",
        "outputId": "0c294b46-1c8a-4722-d6d6-d9aedbf5a40d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        }
      },
      "source": [
        "past_cnn_model = sequentialCNNModel(5,3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_10\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_22 (InputLayer)           (None, 5, 1)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_8 (Embedding)         (None, 5, 1, 100)    57300       input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "reshape_5 (Reshape)             (None, 5, 100, 1)    0           embedding_8[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 5, 100, 100)  1000        reshape_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_23 (InputLayer)           (None, 7, 1)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling2D) (None, 2, 50, 100)   0           conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "embedding_9 (Embedding)         (None, 7, 1, 100)    57300       input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "flatten_22 (Flatten)            (None, 10000)        0           max_pooling2d_13[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "flatten_23 (Flatten)            (None, 700)          0           embedding_9[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_16 (Concatenate)    (None, 10700)        0           flatten_22[0][0]                 \n",
            "                                                                 flatten_23[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_19 (Dense)                (None, 100)          1070100     concatenate_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_20 (Dense)                (None, 127)          12827       dense_19[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 1,198,527\n",
            "Trainable params: 1,198,527\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tsmrZ-XMY02",
        "colab_type": "code",
        "outputId": "ee43fd21-4be7-424d-db4c-a10c125f21c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "source": [
        "past_cnn_model.fit([x_train, x_train_context], y_train, epochs=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "56590/56590 [==============================] - 10s 168us/step - loss: 0.3973 - acc: 0.9199\n",
            "Epoch 2/10\n",
            "56590/56590 [==============================] - 9s 151us/step - loss: 0.0735 - acc: 0.9823\n",
            "Epoch 3/10\n",
            "56590/56590 [==============================] - 9s 152us/step - loss: 0.0442 - acc: 0.9883\n",
            "Epoch 4/10\n",
            "56590/56590 [==============================] - 9s 152us/step - loss: 0.0298 - acc: 0.9915\n",
            "Epoch 5/10\n",
            "56590/56590 [==============================] - 9s 152us/step - loss: 0.0214 - acc: 0.9937\n",
            "Epoch 6/10\n",
            "56590/56590 [==============================] - 9s 154us/step - loss: 0.0166 - acc: 0.9950\n",
            "Epoch 7/10\n",
            "56590/56590 [==============================] - 9s 152us/step - loss: 0.0138 - acc: 0.9957\n",
            "Epoch 8/10\n",
            "56590/56590 [==============================] - 9s 153us/step - loss: 0.0118 - acc: 0.9964\n",
            "Epoch 9/10\n",
            "56590/56590 [==============================] - 9s 152us/step - loss: 0.0103 - acc: 0.9969\n",
            "Epoch 10/10\n",
            "56590/56590 [==============================] - 9s 151us/step - loss: 0.0088 - acc: 0.9976\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6cf3525e80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20Qb91-SNiM5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#For prediction\n",
        "from metrics.accuracy import conlleval\n",
        "\n",
        "def reportResults(model, x_val, x_val_context):\n",
        "  y_pred = model.predict([x_val, x_val_context])\n",
        "  y_pred_temp = [np.argmax(t) for t in y_pred]\n",
        "\n",
        "  labels_pred_val = []\n",
        "  k = 0\n",
        "  for x in val_x:\n",
        "    temp = []\n",
        "    for i in range(len(x)):\n",
        "      temp.append(y_pred_temp[k])\n",
        "      k = k + 1\n",
        "    labels_pred_val.append(temp)\n",
        "\n",
        "  labels_pred_val = [ list(map(lambda x: idx2la[x], y)) \\\n",
        "                                    for y in labels_pred_val]\n",
        "  con_dict = conlleval(labels_pred_val, labels_val, \n",
        "                            words_val, 'measure.txt')\n",
        "\n",
        "  print('Precision = {}, Recall = {}, F1 = {}'.format(\n",
        "              con_dict['r'], con_dict['p'], con_dict['f1']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwQOl6A1Noom",
        "colab_type": "code",
        "outputId": "9ab7f5fb-3b3e-41e0-8166-8adfe1614aee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "print(\"Results for Past CNN \")\n",
        "print(reportResults(past_cnn_model, x_val, x_val_context))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for Past CNN \n",
            "Precision = 91.54, Recall = 90.84, F1 = 91.19\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssv0TR2GyMcc",
        "colab_type": "text"
      },
      "source": [
        "## **Sequential CNN - Future Context Model**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7FN1K8GN44t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "############## Future CNN ###################\n",
        "\n",
        "def prepareFutureCNNInput(encoded_list, window_size, labels):\n",
        "  cnn_input = []\n",
        "  cnn_labels = []\n",
        "  for x in encoded_list:\n",
        "    x= np.append(x, [n_vocab-1] * (window_size - 1))\n",
        "    for i in range(0, len(x) - window_size + 1):\n",
        "      cnn_input.append(np.asarray(x[i:i+window_size]))\n",
        "\n",
        "  for label in labels:\n",
        "    for temp in label:\n",
        "      cnn_labels.append(temp)\n",
        "  return cnn_input, cnn_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUnk-LNHO88F",
        "colab_type": "code",
        "outputId": "5e159ff0-8fc7-4d48-c1a0-80fc9eff4a0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "future_cnn_train_input, future_cnn_train_labels = prepareFutureCNNInput(train_x, 5, train_label)\n",
        "future_cnn_val_input, future_cnn_val_labels = prepareFutureCNNInput(val_x, 5, val_label)\n",
        "\n",
        "print(\"Training input length: \", len(future_cnn_train_input))\n",
        "print(\"Testing input length: \", len(future_cnn_val_input))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training input length:  56590\n",
            "Testing input length:  9198\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58vwnRs1PUSi",
        "colab_type": "code",
        "outputId": "2cb5e634-4d03-444d-e344-4784f20c247c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "context_train_input = prepareCNNContextInput(train_x, 3)\n",
        "context_val_input = prepareCNNContextInput(val_x, 3)\n",
        "\n",
        "print(\"Context input train length: \", len(context_train_input))\n",
        "print(\"Context input test length: \", len(context_val_input))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Context input train length:  56590\n",
            "Context input test length:  9198\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NCKPBVaPc0M",
        "colab_type": "code",
        "outputId": "937ad028-3388-4bcf-e220-a9e967de2aee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "x_train = np.asarray(future_cnn_train_input)\n",
        "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], 1)\n",
        "print(\"Shape of x_train\", x_train.shape)\n",
        "y_train = np.asarray(future_cnn_train_labels)\n",
        "print(\"Shape of y_train\", y_train.shape)\n",
        "\n",
        "x_val = np.asarray(future_cnn_val_input)\n",
        "x_val = x_val.reshape(x_val.shape[0], x_val.shape[1], 1)\n",
        "print(\"Shape of x_test\", x_val.shape)\n",
        "y_val = np.asarray(future_cnn_val_labels)\n",
        "print(\"Shape of y_test\", y_val.shape)\n",
        "\n",
        "\n",
        "x_train_context = np.asarray(context_train_input)\n",
        "x_train_context = x_train_context.reshape(x_train_context.shape[0], x_train_context.shape[1], 1)\n",
        "print(\"Shape of x_train_context\", x_train_context.shape)\n",
        "\n",
        "x_val_context = np.asarray(context_val_input)\n",
        "x_val_context = x_val_context.reshape(x_val_context.shape[0], x_val_context.shape[1], 1)\n",
        "print(\"Shape of x_test_context\", x_val_context.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of x_train (56590, 5, 1)\n",
            "Shape of y_train (56590,)\n",
            "Shape of x_test (9198, 5, 1)\n",
            "Shape of y_test (9198,)\n",
            "Shape of x_train_context (56590, 7, 1)\n",
            "Shape of x_test_context (9198, 7, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjuNR-AjPrCC",
        "colab_type": "code",
        "outputId": "67b5a999-1978-470c-9aa0-3e3b8a488776",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        }
      },
      "source": [
        "future_cnn_model = sequentialCNNModel(5, 3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_8\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_17 (InputLayer)           (None, 5, 1)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_3 (Embedding)         (None, 5, 1, 100)    57300       input_17[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "reshape_2 (Reshape)             (None, 5, 100, 1)    0           embedding_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 5, 100, 100)  1000        reshape_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_18 (InputLayer)           (None, 7, 1)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling2D) (None, 2, 50, 100)   0           conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "embedding_4 (Embedding)         (None, 7, 1, 100)    57300       input_18[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "flatten_17 (Flatten)            (None, 10000)        0           max_pooling2d_10[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "flatten_18 (Flatten)            (None, 700)          0           embedding_4[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_12 (Concatenate)    (None, 10700)        0           flatten_17[0][0]                 \n",
            "                                                                 flatten_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_15 (Dense)                (None, 100)          1070100     concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_16 (Dense)                (None, 127)          12827       dense_15[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 1,198,527\n",
            "Trainable params: 1,198,527\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1k6qwjzPPufg",
        "colab_type": "code",
        "outputId": "9d774f90-90b5-4443-822c-fba18100e4fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "source": [
        "future_cnn_model.fit([x_train, x_train_context], y_train, epochs=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "56590/56590 [==============================] - 9s 163us/step - loss: 0.4069 - acc: 0.9134\n",
            "Epoch 2/10\n",
            "56590/56590 [==============================] - 8s 149us/step - loss: 0.0801 - acc: 0.9793\n",
            "Epoch 3/10\n",
            "56590/56590 [==============================] - 8s 149us/step - loss: 0.0502 - acc: 0.9854\n",
            "Epoch 4/10\n",
            "56590/56590 [==============================] - 9s 150us/step - loss: 0.0361 - acc: 0.9889\n",
            "Epoch 5/10\n",
            "56590/56590 [==============================] - 8s 149us/step - loss: 0.0293 - acc: 0.9904\n",
            "Epoch 6/10\n",
            "56590/56590 [==============================] - 9s 151us/step - loss: 0.0229 - acc: 0.9928\n",
            "Epoch 7/10\n",
            "56590/56590 [==============================] - 9s 151us/step - loss: 0.0208 - acc: 0.9932\n",
            "Epoch 8/10\n",
            "56590/56590 [==============================] - 9s 151us/step - loss: 0.0173 - acc: 0.9943\n",
            "Epoch 9/10\n",
            "56590/56590 [==============================] - 8s 148us/step - loss: 0.0148 - acc: 0.9952\n",
            "Epoch 10/10\n",
            "56590/56590 [==============================] - 9s 150us/step - loss: 0.0132 - acc: 0.9955\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6d01d48358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dze9C0seP-yJ",
        "colab_type": "code",
        "outputId": "d3d87f94-e916-4956-df73-0d35aedad85c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "print(\"Results for Future CNN \")\n",
        "print(reportResults(future_cnn_model, x_val, x_val_context))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for Future CNN \n",
            "Precision = 91.68, Recall = 91.65, F1 = 91.67\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvPcSEV0yPaw",
        "colab_type": "text"
      },
      "source": [
        "## **Sequential CNN - Bidirectional Context Model**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHT2Q37cQB2o",
        "colab_type": "code",
        "outputId": "be48c745-4184-432d-c898-c8b62985a5dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "######################## BiDirectional CNN #######################\n",
        "################### Inputs Preparation ########################\n",
        "\n",
        "cnn_past_train_input, cnn_past_train_labels = preparePastCNNInput(train_x, 5, train_label)\n",
        "print(\"Training input length is {}\".format(len(cnn_past_train_input)))\n",
        "\n",
        "cnn_past_val_input, cnn_past_val_labels = preparePastCNNInput(val_x, 5, val_label)\n",
        "print(\"Test input length is {}\".format(len(cnn_past_val_input)))\n",
        "\n",
        "cnn_future_train_input, cnn_future_train_labels = prepareFutureCNNInput(train_x, 5, train_label)\n",
        "print(\"Training input length is {}\".format(len(cnn_future_train_input)))\n",
        "\n",
        "cnn_future_val_input, cnn_future_val_labels = prepareFutureCNNInput(val_x, 5, val_label)\n",
        "print(\"Test input length is {}\".format(len(cnn_future_val_input)))\n",
        "\n",
        "context_train_input = prepareCNNContextInput(train_x, 3)\n",
        "context_val_input = prepareCNNContextInput(val_x, 3)\n",
        "\n",
        "x_train_past = np.asarray(cnn_past_train_input)\n",
        "x_train_past = x_train_past.reshape(x_train_past.shape[0], x_train_past.shape[1], 1)\n",
        "\n",
        "x_train_future = np.asarray(cnn_future_train_input)\n",
        "x_train_future = x_train_future.reshape(x_train_future.shape[0], x_train_future.shape[1], 1)\n",
        "\n",
        "y_train = np.asarray(cnn_future_train_labels)\n",
        "print(\"Shape of y_train\", y_train.shape)\n",
        "\n",
        "x_val_past = np.asarray(cnn_past_val_input)\n",
        "x_val_past = x_val_past.reshape(x_val_past.shape[0], x_val_past.shape[1], 1)\n",
        "\n",
        "x_val_future = np.asarray(cnn_future_val_input)\n",
        "x_val_future = x_val_future.reshape(x_val_future.shape[0], x_val_future.shape[1], 1)\n",
        "\n",
        "y_val = np.asarray(cnn_future_val_labels)\n",
        "print(\"Shape of y_test\", y_val.shape)\n",
        "\n",
        "\n",
        "x_train_context = np.asarray(context_train_input)\n",
        "x_train_context = x_train_context.reshape(x_train_context.shape[0], x_train_context.shape[1], 1)\n",
        "print(\"Shape of x_train_context\", x_train_context.shape)\n",
        "\n",
        "x_val_context = np.asarray(context_val_input)\n",
        "x_val_context = x_val_context.reshape(x_val_context.shape[0], x_val_context.shape[1], 1)\n",
        "print(\"Shape of x_test_context\", x_val_context.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training input length is 56590\n",
            "Test input length is 9198\n",
            "Training input length is 56590\n",
            "Test input length is 9198\n",
            "Shape of y_train (56590,)\n",
            "Shape of y_test (9198,)\n",
            "Shape of x_train_context (56590, 7, 1)\n",
            "Shape of x_test_context (9198, 7, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkvZZ4rzRC-s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################ Model architecture ##############\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D, Convolution1D, MaxPooling1D\n",
        "from keras.utils import np_utils\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.optimizers import *\n",
        "from keras import regularizers\n",
        "from keras import layers\n",
        "\n",
        "def biSequentialCNNModel(window_size, cs):\n",
        "  input_tensor_past = layers.Input(shape=(window_size, 1))\n",
        "  x = layers.Embedding(n_vocab, 100)(input_tensor_past)\n",
        "  x = layers.Reshape((window_size, 100, 1))(x)\n",
        "  x = layers.Convolution2D(100, kernel_size=3, strides=1, activation='relu', padding='same')(x)\n",
        "  x = layers.MaxPooling2D(pool_size=(2,2))(x)\n",
        "  x = layers.Flatten()(x)\n",
        "\n",
        "  input_tensor_future = layers.Input(shape=(window_size, 1))\n",
        "  x_future = layers.Embedding(n_vocab, 100)(input_tensor_future)\n",
        "  x_future = layers.Reshape((window_size, 100, 1))(x_future)\n",
        "  x_future = layers.Convolution2D(100, kernel_size=3, strides=1, activation='relu', padding='same')(x_future)\n",
        "  x_future = layers.MaxPooling2D(pool_size=(2,2))(x_future)\n",
        "  x_future = layers.Flatten()(x_future)\n",
        "\n",
        "  input_context = layers.Input(shape=(2*cs + 1,1))\n",
        "  context_embedding = layers.Embedding(n_vocab, 100)(input_context)\n",
        "  flatten_context = layers.Flatten()(context_embedding)\n",
        "\n",
        "  concat_past = layers.concatenate([x, flatten_context], axis=-1)\n",
        "  concat_future = layers.concatenate([x_future, flatten_context], axis = -1)\n",
        "\n",
        "  concat = layers.concatenate([concat_past, concat_future], axis = -1)\n",
        "  dense = layers.Dense(100, activation='relu')(concat)\n",
        "  output = layers.Dense(n_classes, activation ='softmax')(dense)\n",
        "  model = Model([input_tensor_past, input_context, input_tensor_future], output)\n",
        "  optim = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
        "  model.compile(loss='sparse_categorical_crossentropy', optimizer=optim, metrics=['accuracy'])\n",
        "  model.summary()\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqIk6o_vTKdH",
        "colab_type": "code",
        "outputId": "5a5ab5b5-5ed3-4d0c-ff4c-3b57fcfad657",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        }
      },
      "source": [
        "cnn_bidirectional_model = biSequentialCNNModel(5, 3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_9\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_19 (InputLayer)           (None, 5, 1)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_20 (InputLayer)           (None, 5, 1)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_5 (Embedding)         (None, 5, 1, 100)    57300       input_19[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "embedding_6 (Embedding)         (None, 5, 1, 100)    57300       input_20[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "reshape_3 (Reshape)             (None, 5, 100, 1)    0           embedding_5[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "reshape_4 (Reshape)             (None, 5, 100, 1)    0           embedding_6[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 5, 100, 100)  1000        reshape_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_21 (InputLayer)           (None, 7, 1)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 5, 100, 100)  1000        reshape_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling2D) (None, 2, 50, 100)   0           conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "embedding_7 (Embedding)         (None, 7, 1, 100)    57300       input_21[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling2D) (None, 2, 50, 100)   0           conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten_19 (Flatten)            (None, 10000)        0           max_pooling2d_11[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "flatten_21 (Flatten)            (None, 700)          0           embedding_7[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_20 (Flatten)            (None, 10000)        0           max_pooling2d_12[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_13 (Concatenate)    (None, 10700)        0           flatten_19[0][0]                 \n",
            "                                                                 flatten_21[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_14 (Concatenate)    (None, 10700)        0           flatten_20[0][0]                 \n",
            "                                                                 flatten_21[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_15 (Concatenate)    (None, 21400)        0           concatenate_13[0][0]             \n",
            "                                                                 concatenate_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_17 (Dense)                (None, 100)          2140100     concatenate_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_18 (Dense)                (None, 127)          12827       dense_17[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 2,326,827\n",
            "Trainable params: 2,326,827\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srBkPQ1HTqy0",
        "colab_type": "code",
        "outputId": "77966130-7cd8-40a5-e1f0-5ebbbfe447f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "source": [
        "cnn_bidirectional_model.fit([x_train_past, x_train_context, x_train_future], y_train, epochs=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "56590/56590 [==============================] - 12s 215us/step - loss: 0.3238 - acc: 0.9343\n",
            "Epoch 2/10\n",
            "56590/56590 [==============================] - 11s 201us/step - loss: 0.0600 - acc: 0.9852\n",
            "Epoch 3/10\n",
            "56590/56590 [==============================] - 11s 195us/step - loss: 0.0353 - acc: 0.9898\n",
            "Epoch 4/10\n",
            "56590/56590 [==============================] - 11s 195us/step - loss: 0.0262 - acc: 0.9921\n",
            "Epoch 5/10\n",
            "56590/56590 [==============================] - 11s 195us/step - loss: 0.0188 - acc: 0.9942\n",
            "Epoch 6/10\n",
            "56590/56590 [==============================] - 11s 196us/step - loss: 0.0146 - acc: 0.9957\n",
            "Epoch 7/10\n",
            "56590/56590 [==============================] - 11s 198us/step - loss: 0.0133 - acc: 0.9962\n",
            "Epoch 8/10\n",
            "56590/56590 [==============================] - 11s 197us/step - loss: 0.0122 - acc: 0.9963\n",
            "Epoch 9/10\n",
            "56590/56590 [==============================] - 11s 196us/step - loss: 0.0098 - acc: 0.9970\n",
            "Epoch 10/10\n",
            "56590/56590 [==============================] - 11s 197us/step - loss: 0.0088 - acc: 0.9975\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6d42281a20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B20CGrguT41k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reportBiResults(model, x_val_past, x_val_context, x_val_future):\n",
        "  y_pred = model.predict([x_val_past, x_val_context, x_val_future])\n",
        "  y_pred_temp = [np.argmax(t) for t in y_pred]\n",
        "\n",
        "  labels_pred_val = []\n",
        "  k = 0\n",
        "  for x in val_x:\n",
        "    temp = []\n",
        "    for i in range(len(x)):\n",
        "      temp.append(y_pred_temp[k])\n",
        "      k = k + 1\n",
        "    labels_pred_val.append(temp)\n",
        "\n",
        "  labels_pred_val = [ list(map(lambda x: idx2la[x], y)) \\\n",
        "                                    for y in labels_pred_val]\n",
        "  con_dict = conlleval(labels_pred_val, labels_val, \n",
        "                            words_val, 'measure.txt')\n",
        "\n",
        "  print('Precision = {}, Recall = {}, F1 = {}'.format(\n",
        "              con_dict['r'], con_dict['p'], con_dict['f1']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LH4m2HUiT7Ev",
        "colab_type": "code",
        "outputId": "c7423f1b-b010-442b-f210-1ef3ccf62c6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "print(\"Results for bidirectional CNN\")\n",
        "print(reportBiResults(cnn_bidirectional_model, x_val_past, x_val_context, x_val_future))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for bidirectional CNN\n",
            "Precision = 93.02, Recall = 92.47, F1 = 92.74\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LwFZQwIyU4V",
        "colab_type": "text"
      },
      "source": [
        "# **RNN  Models**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xY__KR1jiZBQ",
        "colab_type": "text"
      },
      "source": [
        "## **SimpleRNN Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xdlEs8PimzH",
        "colab_type": "code",
        "outputId": "99c0d8db-3e3f-431d-a918-f4fd8e71ffa4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers.recurrent import SimpleRNN\n",
        "from keras.layers.core import Dense, Dropout\n",
        "from keras.layers.wrappers import TimeDistributed\n",
        "from keras.layers import Convolution1D\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(n_vocab,100))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(SimpleRNN(100,return_sequences=True))\n",
        "model.add(TimeDistributed(Dense(n_classes, activation='softmax')))\n",
        "model.compile('rmsprop', 'categorical_crossentropy')\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 100)         57200     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, None, 100)         0         \n",
            "_________________________________________________________________\n",
            "simple_rnn_1 (SimpleRNN)     (None, None, 100)         20100     \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, None, 127)         12827     \n",
            "=================================================================\n",
            "Total params: 90,127\n",
            "Trainable params: 90,127\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5Vfnps-dGPQ",
        "colab_type": "code",
        "outputId": "d8454bad-9d2d-4457-9476-403cfb79d95e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import progressbar\n",
        "n_epochs = 30\n",
        "\n",
        "for i in range(n_epochs):\n",
        "    print(\"Training epoch {}\".format(i))\n",
        "    \n",
        "    bar = progressbar.ProgressBar(max_value=len(train_x))\n",
        "    for n_batch, sent in bar(enumerate(train_x)):\n",
        "        label = train_label[n_batch]\n",
        "        # Make labels one hot\n",
        "        label = np.eye(n_classes)[label][np.newaxis,:] \n",
        "        # View each sentence as a batch\n",
        "        sent = sent[np.newaxis,:]\n",
        "        if sent.shape[1] > 1: #ignore 1 word sentences\n",
        "            model.train_on_batch(sent, label)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r                                                                               \r\rN/A% (0 of 4978) |                       | Elapsed Time: 0:00:00 ETA:  --:--:--"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 0\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:00:43 Time:  0:00:43\n",
            "  0% (14 of 4978) |                      | Elapsed Time: 0:00:00 ETA:   0:00:36"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:00:37 Time:  0:00:37\n",
            "  0% (15 of 4978) |                      | Elapsed Time: 0:00:00 ETA:   0:00:34"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:00:37 Time:  0:00:37\n",
            "  0% (14 of 4978) |                      | Elapsed Time: 0:00:00 ETA:   0:00:35"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:00:38 Time:  0:00:38\n",
            "  0% (14 of 4978) |                      | Elapsed Time: 0:00:00 ETA:   0:00:37"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:00:37 Time:  0:00:37\n",
            "  0% (13 of 4978) |                      | Elapsed Time: 0:00:00 ETA:   0:00:38"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:00:37 Time:  0:00:37\n",
            "  0% (14 of 4978) |                      | Elapsed Time: 0:00:00 ETA:   0:00:35"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:00:37 Time:  0:00:37\n",
            "  0% (13 of 4978) |                      | Elapsed Time: 0:00:00 ETA:   0:00:38"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:00:37 Time:  0:00:37\n",
            "  0% (14 of 4978) |                      | Elapsed Time: 0:00:00 ETA:   0:00:37"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:00:37 Time:  0:00:37\n",
            "  0% (15 of 4978) |                      | Elapsed Time: 0:00:00 ETA:   0:00:34"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:00:36 Time:  0:00:36\n",
            "  0% (14 of 4978) |                      | Elapsed Time: 0:00:00 ETA:   0:00:37"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:00:37 Time:  0:00:37\n",
            "  0% (16 of 4978) |                      | Elapsed Time: 0:00:00 ETA:   0:00:32"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:00:36 Time:  0:00:36\n",
            "  0% (12 of 4978) |                      | Elapsed Time: 0:00:00 ETA:   0:00:42"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 12\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:00:37 Time:  0:00:37\n",
            "  0% (15 of 4978) |                      | Elapsed Time: 0:00:00 ETA:   0:00:34"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 13\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:00:36 Time:  0:00:36\n",
            "  0% (14 of 4978) |                      | Elapsed Time: 0:00:00 ETA:   0:00:35"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 14\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:00:36 Time:  0:00:36\n",
            "  0% (16 of 4978) |                      | Elapsed Time: 0:00:00 ETA:   0:00:32"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 15\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:00:36 Time:  0:00:36\n",
            "  0% (16 of 4978) |                      | Elapsed Time: 0:00:00 ETA:   0:00:31"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:00:35 Time:  0:00:35\n",
            "  0% (14 of 4978) |                      | Elapsed Time: 0:00:00 ETA:   0:00:36"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 17\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:00:35 Time:  0:00:35\n",
            "  0% (16 of 4978) |                      | Elapsed Time: 0:00:00 ETA:   0:00:32"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 18\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:00:35 Time:  0:00:35\n",
            "  0% (11 of 4978) |                      | Elapsed Time: 0:00:00 ETA:   0:00:47"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 19\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:00:35 Time:  0:00:35\n",
            "  0% (15 of 4978) |                      | Elapsed Time: 0:00:00 ETA:   0:00:33"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:00:36 Time:  0:00:36\n",
            "  0% (16 of 4978) |                      | Elapsed Time: 0:00:00 ETA:   0:00:31"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 21\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:00:36 Time:  0:00:36\n",
            "  0% (15 of 4978) |                      | Elapsed Time: 0:00:00 ETA:   0:00:34"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 22\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:00:35 Time:  0:00:35\n",
            "  0% (14 of 4978) |                      | Elapsed Time: 0:00:00 ETA:   0:00:36"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 23\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:00:35 Time:  0:00:35\n",
            "  0% (16 of 4978) |                      | Elapsed Time: 0:00:00 ETA:   0:00:31"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 24\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:00:35 Time:  0:00:35\n",
            "  0% (14 of 4978) |                      | Elapsed Time: 0:00:00 ETA:   0:00:37"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:00:36 Time:  0:00:36\n",
            "  0% (15 of 4978) |                      | Elapsed Time: 0:00:00 ETA:   0:00:33"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 26\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:00:35 Time:  0:00:35\n",
            "  0% (15 of 4978) |                      | Elapsed Time: 0:00:00 ETA:   0:00:35"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 27\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:00:35 Time:  0:00:35\n",
            "  0% (14 of 4978) |                      | Elapsed Time: 0:00:00 ETA:   0:00:35"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 28\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:00:35 Time:  0:00:35\n",
            "  0% (15 of 4978) |                      | Elapsed Time: 0:00:00 ETA:   0:00:33"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 29\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:00:36 Time:  0:00:36\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cn3rV2QDdKSx",
        "colab_type": "code",
        "outputId": "8edbd958-a9f7-4841-be25-c43e4753e52e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from metrics.accuracy import conlleval\n",
        "\n",
        "labels_pred_val = []\n",
        "\n",
        "bar = progressbar.ProgressBar(max_value=len(val_x))\n",
        "for n_batch, sent in bar(enumerate(val_x)):\n",
        "    label = val_label[n_batch]\n",
        "    label = np.eye(n_classes)[label][np.newaxis,:]\n",
        "    sent = sent[np.newaxis,:]\n",
        "\n",
        "    pred = model.predict_on_batch(sent)\n",
        "    pred = np.argmax(pred,-1)[0]\n",
        "    labels_pred_val.append(pred)\n",
        "\n",
        "labels_pred_val = [ list(map(lambda x: idx2la[x], y)) \\\n",
        "                                    for y in labels_pred_val]\n",
        "con_dict = conlleval(labels_pred_val, labels_val, \n",
        "                            words_val, 'measure.txt')\n",
        "\n",
        "print('Precision = {}, Recall = {}, F1 = {}'.format(\n",
        "            con_dict['r'], con_dict['p'], con_dict['f1']))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100% (893 of 893) |######################| Elapsed Time: 0:00:01 Time:  0:00:01\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Precision = 92.25, Recall = 92.7, F1 = 92.47\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuUk-9pyqzC4",
        "colab_type": "text"
      },
      "source": [
        "## **SimpleRNN + GLoVE Models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmtF6Ma0Moug",
        "colab_type": "code",
        "outputId": "d98aadae-ff89-4cda-8f25-cec38ef4222e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers.recurrent import SimpleRNN\n",
        "from keras.layers.core import Dense, Dropout\n",
        "from keras.layers.wrappers import TimeDistributed\n",
        "from keras.layers import Convolution1D\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(len(dicts['words2idx']), 300, weights=[embedding_matrix], input_length=maxLen, trainable=False))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(SimpleRNN(300,return_sequences=True))\n",
        "model.add(SimpleRNN(200,return_sequences=True))\n",
        "model.add(TimeDistributed(Dense(n_classes, activation='softmax')))\n",
        "model.compile('rmsprop', 'categorical_crossentropy')\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 46, 300)           171600    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 46, 300)           0         \n",
            "_________________________________________________________________\n",
            "simple_rnn_1 (SimpleRNN)     (None, 46, 300)           180300    \n",
            "_________________________________________________________________\n",
            "simple_rnn_2 (SimpleRNN)     (None, 46, 200)           100200    \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 46, 127)           25527     \n",
            "=================================================================\n",
            "Total params: 477,627\n",
            "Trainable params: 306,027\n",
            "Non-trainable params: 171,600\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJyKPSuvQJl0",
        "colab_type": "code",
        "outputId": "bb11d9e0-9178-4c2b-e08c-b0a8c683e447",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import progressbar\n",
        "n_epochs = 30\n",
        "for i in range(n_epochs):\n",
        "    print(\"Training epoch {}\".format(i))\n",
        "    bar = progressbar.ProgressBar(max_value=len(padded_docs))\n",
        "    for n_batch, sent in bar(enumerate(padded_docs)):\n",
        "        #print(sent.shape)\n",
        "        label = train_label[n_batch]    \n",
        "        if len(label)<maxLen:     \n",
        "          label = np.pad(label, (0, maxLen - len(label)%maxLen), 'constant')\n",
        "        else:\n",
        "          label= label[-maxLen:]\n",
        "        # Make labels one hot\n",
        "        label = np.eye(n_classes)[label][np.newaxis,:] \n",
        "        # View each sentence as a batch\n",
        "        sent = sent[np.newaxis,:]\n",
        "        if sent.shape[1] > 1: #ignore 1 word sentences\n",
        "          model.train_on_batch(sent, label)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r                                                                               \r\rN/A% (0 of 4978) |                       | Elapsed Time: 0:00:00 ETA:  --:--:--"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 0\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:02:12 Time:  0:02:12\n",
            "  0% (4 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:02:14"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:02:11 Time:  0:02:11\n",
            "  0% (4 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:02:11"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:02:12 Time:  0:02:12\n",
            "  0% (4 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:02:21"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:02:12 Time:  0:02:12\n",
            "  0% (4 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:02:13"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:02:11 Time:  0:02:11\n",
            "  0% (4 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:02:09"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:02:12 Time:  0:02:12\n",
            "  0% (4 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:02:34"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:02:12 Time:  0:02:12\n",
            "  0% (4 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:02:16"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:02:13 Time:  0:02:13\n",
            "  0% (4 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:02:19"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:02:12 Time:  0:02:12\n",
            "  0% (4 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:02:11"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:02:12 Time:  0:02:12\n",
            "  0% (4 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:02:25"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:02:13 Time:  0:02:13\n",
            "  0% (4 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:02:18"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:02:12 Time:  0:02:12\n",
            "  0% (4 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:02:12"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 12\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:02:12 Time:  0:02:12\n",
            "  0% (4 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:02:15"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 13\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:02:12 Time:  0:02:12\n",
            "  0% (4 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:02:15"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 14\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:02:13 Time:  0:02:13\n",
            "  0% (4 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:02:19"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 15\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:02:13 Time:  0:02:13\n",
            "  0% (4 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:02:17"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:02:14 Time:  0:02:14\n",
            "  0% (4 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:02:29"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 17\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:02:12 Time:  0:02:12\n",
            "  0% (4 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:02:17"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 18\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:02:13 Time:  0:02:13\n",
            "  0% (4 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:02:15"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 19\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:02:12 Time:  0:02:12\n",
            "  0% (4 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:02:26"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:02:12 Time:  0:02:12\n",
            "  0% (4 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:02:17"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 21\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:02:12 Time:  0:02:12\n",
            "  0% (4 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:02:19"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 22\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:02:13 Time:  0:02:13\n",
            "  0% (4 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:02:21"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 23\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:02:13 Time:  0:02:13\n",
            "  0% (4 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:02:17"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 24\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:02:14 Time:  0:02:14\n",
            "  0% (4 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:02:10"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:02:12 Time:  0:02:12\n",
            "  0% (4 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:02:22"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 26\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:02:14 Time:  0:02:14\n",
            "  0% (4 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:02:21"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 27\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:02:14 Time:  0:02:14\n",
            "  0% (4 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:02:39"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 28\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:02:13 Time:  0:02:13\n",
            "  0% (4 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:02:16"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 29\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:02:12 Time:  0:02:12\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYGid4ckQNI7",
        "colab_type": "code",
        "outputId": "3ec3405e-5d30-42ae-bc59-b3e60963ccb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#2 Simple RNNs, Glove, padded to maxLen, DIGIT handled, embedding dim =300\n",
        "from metrics.accuracy import conlleval\n",
        "\n",
        "padded_docs_val = pad_sequences(val_x, maxlen=maxLen, padding='post')\n",
        "#print(padded_docs_val)\n",
        "\n",
        "labels_pred_val = []\n",
        "bar = progressbar.ProgressBar(max_value=len(padded_docs_val))\n",
        "for n_batch, sent in bar(enumerate(padded_docs_val)):\n",
        "    label = val_label[n_batch]\n",
        "    if len(label)<maxLen:     \n",
        "          label = np.pad(label, (0, maxLen - len(label)%maxLen), 'constant')\n",
        "    else:\n",
        "      label= label[-maxLen:]\n",
        "    label = np.eye(n_classes)[label][np.newaxis,:]\n",
        "    sent = sent[np.newaxis,:]\n",
        "\n",
        "    pred = model.predict_on_batch(sent)\n",
        "    pred = np.argmax(pred,-1)[0]\n",
        "    labels_pred_val.append(pred)\n",
        "\n",
        "labels_pred_val = [ list(map(lambda x: idx2la[x], y)) \\\n",
        "                                    for y in labels_pred_val]\n",
        "con_dict = conlleval(labels_pred_val, labels_val, \n",
        "                            words_val, 'measure.txt')\n",
        "\n",
        "print('Precision = {}, Recall = {}, F1 = {}'.format(\n",
        "            con_dict['r'], con_dict['p'], con_dict['f1']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100% (893 of 893) |######################| Elapsed Time: 0:00:04 Time:  0:00:04\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Precision = 90.17, Recall = 90.07, F1 = 90.12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d98aadae-ff89-4cda-8f25-cec38ef4222e",
        "id": "oJKawLzBTWnZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        }
      },
      "source": [
        "#3 Two Layers of Simple RNNs, Glove, padded to maxLen, DIGIT handled, embedding dim =300\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers.recurrent import SimpleRNN\n",
        "from keras.layers.core import Dense, Dropout\n",
        "from keras.layers.wrappers import TimeDistributed\n",
        "from keras.layers import Convolution1D\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(len(dicts['words2idx']), 300, weights=[embedding_matrix], input_length=maxLen, trainable=False))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(SimpleRNN(300,return_sequences=True))\n",
        "model.add(SimpleRNN(200,return_sequences=True))\n",
        "model.add(TimeDistributed(Dense(n_classes, activation='softmax')))\n",
        "model.compile('rmsprop', 'categorical_crossentropy')\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 46, 300)           171600    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 46, 300)           0         \n",
            "_________________________________________________________________\n",
            "simple_rnn_1 (SimpleRNN)     (None, 46, 300)           180300    \n",
            "_________________________________________________________________\n",
            "simple_rnn_2 (SimpleRNN)     (None, 46, 200)           100200    \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 46, 127)           25527     \n",
            "=================================================================\n",
            "Total params: 477,627\n",
            "Trainable params: 306,027\n",
            "Non-trainable params: 171,600\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "bb11d9e0-9178-4c2b-e08c-b0a8c683e447",
        "id": "2BJfOcSUTp4z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import progressbar\n",
        "n_epochs = 30\n",
        "\n",
        "for i in range(n_epochs):\n",
        "    print(\"Training epoch {}\".format(i))\n",
        "    bar = progressbar.ProgressBar(max_value=len(padded_docs))\n",
        "    for n_batch, sent in bar(enumerate(padded_docs)):\n",
        "        #print(sent.shape)\n",
        "        label = train_label[n_batch]    \n",
        "        if len(label)<maxLen:     \n",
        "          label = np.pad(label, (0, maxLen - len(label)%maxLen), 'constant')\n",
        "        else:\n",
        "          label= label[-maxLen:]\n",
        "        # Make labels one hot\n",
        "        label = np.eye(n_classes)[label][np.newaxis,:] \n",
        "        # View each sentence as a batch\n",
        "        sent = sent[np.newaxis,:]\n",
        "        if sent.shape[1] > 1: #ignore 1 word sentences\n",
        "          model.train_on_batch(sent, label)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r                                                                               \r\rN/A% (0 of 4978) |                       | Elapsed Time: 0:00:00 ETA:  --:--:--"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 0\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:02:12 Time:  0:02:12\n",
            "  0% (4 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:02:14"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:02:11 Time:  0:02:11\n",
            "  0% (4 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:02:11"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:02:12 Time:  0:02:12\n",
            "  0% (4 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:02:21"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:02:12 Time:  0:02:12\n",
            "  0% (4 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:02:13"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:02:11 Time:  0:02:11\n",
            "  0% (4 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:02:09"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:02:12 Time:  0:02:12\n",
            "  0% (4 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:02:34"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:02:12 Time:  0:02:12\n",
            "  0% (4 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:02:16"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:02:13 Time:  0:02:13\n",
            "  0% (4 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:02:19"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:02:12 Time:  0:02:12\n",
            "  0% (4 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:02:11"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:02:12 Time:  0:02:12\n",
            "  0% (4 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:02:25"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:02:13 Time:  0:02:13\n",
            "  0% (4 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:02:18"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:02:12 Time:  0:02:12\n",
            "  0% (4 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:02:12"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 12\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:02:12 Time:  0:02:12\n",
            "  0% (4 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:02:15"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 13\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:02:12 Time:  0:02:12\n",
            "  0% (4 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:02:15"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 14\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:02:13 Time:  0:02:13\n",
            "  0% (4 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:02:19"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 15\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:02:13 Time:  0:02:13\n",
            "  0% (4 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:02:17"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:02:14 Time:  0:02:14\n",
            "  0% (4 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:02:29"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 17\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:02:12 Time:  0:02:12\n",
            "  0% (4 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:02:17"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 18\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:02:13 Time:  0:02:13\n",
            "  0% (4 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:02:15"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 19\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:02:12 Time:  0:02:12\n",
            "  0% (4 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:02:26"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:02:12 Time:  0:02:12\n",
            "  0% (4 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:02:17"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 21\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:02:12 Time:  0:02:12\n",
            "  0% (4 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:02:19"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 22\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:02:13 Time:  0:02:13\n",
            "  0% (4 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:02:21"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 23\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:02:13 Time:  0:02:13\n",
            "  0% (4 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:02:17"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 24\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:02:14 Time:  0:02:14\n",
            "  0% (4 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:02:10"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:02:12 Time:  0:02:12\n",
            "  0% (4 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:02:22"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 26\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:02:14 Time:  0:02:14\n",
            "  0% (4 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:02:21"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 27\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:02:14 Time:  0:02:14\n",
            "  0% (4 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:02:39"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 28\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:02:13 Time:  0:02:13\n",
            "  0% (4 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:02:16"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 29\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:02:12 Time:  0:02:12\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "3ec3405e-5d30-42ae-bc59-b3e60963ccb6",
        "id": "l-CDo9SOTz5m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#2 Simple RNNs, Glove, padded to maxLen, DIGIT handled, embedding dim =300\n",
        "from metrics.accuracy import conlleval\n",
        "\n",
        "padded_docs_val = pad_sequences(val_x, maxlen=maxLen, padding='post')\n",
        "#print(padded_docs_val)\n",
        "\n",
        "labels_pred_val = []\n",
        "bar = progressbar.ProgressBar(max_value=len(padded_docs_val))\n",
        "for n_batch, sent in bar(enumerate(padded_docs_val)):\n",
        "    label = val_label[n_batch]\n",
        "    if len(label)<maxLen:     \n",
        "          label = np.pad(label, (0, maxLen - len(label)%maxLen), 'constant')\n",
        "    else:\n",
        "      label= label[-maxLen:]\n",
        "    label = np.eye(n_classes)[label][np.newaxis,:]\n",
        "    sent = sent[np.newaxis,:]\n",
        "\n",
        "    pred = model.predict_on_batch(sent)\n",
        "    pred = np.argmax(pred,-1)[0]\n",
        "    labels_pred_val.append(pred)\n",
        "\n",
        "labels_pred_val = [ list(map(lambda x: idx2la[x], y)) \\\n",
        "                                    for y in labels_pred_val]\n",
        "con_dict = conlleval(labels_pred_val, labels_val, \n",
        "                            words_val, 'measure.txt')\n",
        "\n",
        "print('Precision = {}, Recall = {}, F1 = {}'.format(\n",
        "            con_dict['r'], con_dict['p'], con_dict['f1']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100% (893 of 893) |######################| Elapsed Time: 0:00:04 Time:  0:00:04\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Precision = 90.17, Recall = 90.07, F1 = 90.12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-zBqkm_jr6p",
        "colab_type": "text"
      },
      "source": [
        "## **LSTM Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78tK1uqfsdcv",
        "colab_type": "code",
        "outputId": "c375797c-a097-49d3-ad98-1b9f24367bde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers.recurrent import SimpleRNN, LSTM\n",
        "from keras.layers.core import Dense, Dropout\n",
        "from keras.layers.wrappers import TimeDistributed\n",
        "from keras.layers import Convolution1D\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(n_vocab,100))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(LSTM(100,return_sequences=True))\n",
        "model.add(LSTM(100,return_sequences=True))\n",
        "model.add(TimeDistributed(Dense(n_classes, activation='softmax')))\n",
        "model.compile('rmsprop', 'categorical_crossentropy')\n",
        "model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_7 (Embedding)      (None, None, 100)         57200     \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, None, 100)         0         \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (None, None, 100)         80400     \n",
            "_________________________________________________________________\n",
            "lstm_6 (LSTM)                (None, None, 100)         80400     \n",
            "_________________________________________________________________\n",
            "time_distributed_5 (TimeDist (None, None, 127)         12827     \n",
            "=================================================================\n",
            "Total params: 230,827\n",
            "Trainable params: 230,827\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OLv02EoixYq",
        "colab_type": "code",
        "outputId": "5d3d176b-8bc6-49ca-8f75-cda2ab7f6dbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import progressbar\n",
        "n_epochs = 30\n",
        "\n",
        "for i in range(n_epochs):\n",
        "    print(\"Training epoch {}\".format(i))\n",
        "    bar = progressbar.ProgressBar(max_value=len(train_x))\n",
        "    for n_batch, sent in bar(enumerate(train_x)):\n",
        "        label = train_label[n_batch]\n",
        "        # Make labels one hot\n",
        "        label = np.eye(n_classes)[label][np.newaxis,:] \n",
        "        # View each sentence as a batch\n",
        "        sent = sent[np.newaxis,:]\n",
        "        \n",
        "        if sent.shape[1] > 1: #ignore 1 word sentences\n",
        "            model.train_on_batch(sent, label)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r                                                                               \r\rN/A% (0 of 4978) |                       | Elapsed Time: 0:00:00 ETA:  --:--:--"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 0\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:01:33 Time:  0:01:33\n",
            "  0% (6 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:01:34"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:01:28 Time:  0:01:28\n",
            "  0% (6 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:01:30"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:01:27 Time:  0:01:27\n",
            "  0% (6 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:01:30"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:01:29 Time:  0:01:29\n",
            "  0% (6 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:01:33"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:01:27 Time:  0:01:27\n",
            "  0% (6 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:01:24"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:01:26 Time:  0:01:26\n",
            "  0% (6 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:01:32"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:01:26 Time:  0:01:26\n",
            "  0% (6 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:01:32"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:01:27 Time:  0:01:27\n",
            "  0% (5 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:01:41"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:01:27 Time:  0:01:27\n",
            "  0% (6 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:01:30"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:01:28 Time:  0:01:28\n",
            "  0% (6 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:01:25"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:01:29 Time:  0:01:29\n",
            "  0% (5 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:01:40"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:01:28 Time:  0:01:28\n",
            "  0% (6 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:01:30"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 12\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:01:29 Time:  0:01:29\n",
            "  0% (6 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:01:31"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 13\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:01:27 Time:  0:01:27\n",
            "  0% (6 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:01:25"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 14\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:01:28 Time:  0:01:28\n",
            "  0% (6 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:01:24"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 15\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:01:24 Time:  0:01:24\n",
            "  0% (6 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:01:27"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:01:24 Time:  0:01:24\n",
            "  0% (7 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:01:22"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 17\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:01:23 Time:  0:01:23\n",
            "  0% (6 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:01:23"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 18\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:01:23 Time:  0:01:23\n",
            "  0% (6 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:01:27"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 19\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:01:23 Time:  0:01:23\n",
            "  0% (6 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:01:25"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:01:24 Time:  0:01:24\n",
            "  0% (6 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:01:25"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 21\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:01:24 Time:  0:01:24\n",
            "  0% (6 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:01:26"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 22\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:01:23 Time:  0:01:23\n",
            "  0% (6 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:01:31"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 23\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:01:23 Time:  0:01:23\n",
            "  0% (6 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:01:29"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 24\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:01:23 Time:  0:01:23\n",
            "  0% (6 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:01:25"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:01:25 Time:  0:01:25\n",
            "  0% (6 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:01:28"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 26\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:01:26 Time:  0:01:26\n",
            "  0% (6 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:01:30"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 27\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:01:25 Time:  0:01:25\n",
            "  0% (6 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:01:30"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 28\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:01:24 Time:  0:01:24\n",
            "  0% (6 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:01:27"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 29\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:01:24 Time:  0:01:24\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r21R5lsOmAQb",
        "colab_type": "code",
        "outputId": "5b981e56-f83b-4db2-f107-0159922871c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from metrics.accuracy import conlleval\n",
        "\n",
        "labels_pred_val = []\n",
        "\n",
        "bar = progressbar.ProgressBar(max_value=len(val_x))\n",
        "for n_batch, sent in bar(enumerate(val_x)):\n",
        "    label = val_label[n_batch]\n",
        "    label = np.eye(n_classes)[label][np.newaxis,:]\n",
        "    sent = sent[np.newaxis,:]\n",
        "\n",
        "    pred = model.predict_on_batch(sent)\n",
        "    pred = np.argmax(pred,-1)[0]\n",
        "    labels_pred_val.append(pred)\n",
        "\n",
        "labels_pred_val = [ list(map(lambda x: idx2la[x], y)) \\\n",
        "                                    for y in labels_pred_val]\n",
        "con_dict = conlleval(labels_pred_val, labels_val, \n",
        "                            words_val, 'measure.txt')\n",
        "\n",
        "print('Precision = {}, Recall = {}, F1 = {}'.format(\n",
        "            con_dict['r'], con_dict['p'], con_dict['f1']))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100% (893 of 893) |######################| Elapsed Time: 0:00:02 Time:  0:00:02\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Precision = 92.07, Recall = 92.62, F1 = 92.35\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6TaccopoDzP",
        "colab_type": "text"
      },
      "source": [
        "## **LSTM + GLoVE Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cfVH5S0Y1Ax",
        "colab_type": "code",
        "outputId": "4321431c-c271-4419-d27a-786eae28fd31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers.recurrent import SimpleRNN, LSTM\n",
        "from keras.layers.core import Dense, Dropout\n",
        "from keras.layers.wrappers import TimeDistributed\n",
        "from keras.layers import Convolution1D, Bidirectional\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(len(dicts['words2idx']), 300, weights=[embedding_matrix], input_length=maxLen, trainable=False))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(LSTM(100,return_sequences=True))\n",
        "model.add(LSTM(100,return_sequences=True))\n",
        "model.add(TimeDistributed(Dense(n_classes, activation='softmax')))\n",
        "model.compile('rmsprop', 'categorical_crossentropy')\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 46, 300)           171600    \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 46, 300)           0         \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 46, 100)           160400    \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 46, 100)           80400     \n",
            "_________________________________________________________________\n",
            "time_distributed_4 (TimeDist (None, 46, 127)           12827     \n",
            "=================================================================\n",
            "Total params: 425,227\n",
            "Trainable params: 253,627\n",
            "Non-trainable params: 171,600\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rm8EgQCbbi-Y",
        "colab_type": "code",
        "outputId": "2626913e-05f3-4b5c-bccf-87a9732bd265",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import progressbar\n",
        "n_epochs = 30\n",
        "\n",
        "for i in range(n_epochs):\n",
        "    print(\"Training epoch {}\".format(i))\n",
        "    bar = progressbar.ProgressBar(max_value=len(padded_docs))\n",
        "    for n_batch, sent in bar(enumerate(padded_docs)):\n",
        "        #print(sent.shape)\n",
        "        label = train_label[n_batch]    \n",
        "        if len(label)<maxLen:     \n",
        "          label = np.pad(label, (0, maxLen - len(label)%maxLen), 'constant')\n",
        "        else:\n",
        "          label= label[-maxLen:]\n",
        "        # Make labels one hot\n",
        "        label = np.eye(n_classes)[label][np.newaxis,:] \n",
        "        # View each sentence as a batch\n",
        "        sent = sent[np.newaxis,:]\n",
        "        if sent.shape[1] > 1: #ignore 1 word sentences\n",
        "          model.train_on_batch(sent, label)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r                                                                               \r\rN/A% (0 of 4978) |                       | Elapsed Time: 0:00:00 ETA:  --:--:--"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:05:11 Time:  0:05:11\n",
            "  0% (2 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:05:05"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:05:09 Time:  0:05:09\n",
            "  0% (2 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:05:18"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:05:08 Time:  0:05:08\n",
            "  0% (2 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:05:12"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:05:06 Time:  0:05:06\n",
            "  0% (2 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:05:11"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:05:08 Time:  0:05:08\n",
            "  0% (2 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:05:18"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:05:07 Time:  0:05:07\n",
            "  0% (2 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:05:11"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:05:09 Time:  0:05:09\n",
            "  0% (2 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:04:55"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:05:04 Time:  0:05:04\n",
            "  0% (2 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:05:16"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:05:06 Time:  0:05:06\n",
            "  0% (2 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:05:13"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:05:06 Time:  0:05:06\n",
            "  0% (2 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:05:23"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:05:04 Time:  0:05:04\n",
            "  0% (2 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:04:56"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:05:06 Time:  0:05:06\n",
            "  0% (2 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:05:32"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 12\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:05:08 Time:  0:05:08\n",
            "  0% (2 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:05:11"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 13\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:05:08 Time:  0:05:08\n",
            "  0% (2 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:05:29"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 14\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:05:10 Time:  0:05:10\n",
            "  0% (2 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:05:22"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 15\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:05:10 Time:  0:05:10\n",
            "  0% (2 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:05:15"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:05:10 Time:  0:05:10\n",
            "  0% (2 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:05:17"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 17\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:05:08 Time:  0:05:08\n",
            "  0% (2 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:05:03"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 18\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:05:05 Time:  0:05:05\n",
            "  0% (2 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:05:08"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 19\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:05:07 Time:  0:05:07\n",
            "  0% (2 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:05:02"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:05:07 Time:  0:05:07\n",
            "  0% (2 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:05:27"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 21\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:05:07 Time:  0:05:07\n",
            "  0% (2 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:05:14"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 22\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:05:06 Time:  0:05:06\n",
            "  0% (2 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:05:23"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 23\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:05:05 Time:  0:05:05\n",
            "  0% (2 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:05:01"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 24\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:05:05 Time:  0:05:05\n",
            "  0% (2 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:05:00"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:05:07 Time:  0:05:07\n",
            "  0% (2 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:05:02"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 26\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:05:07 Time:  0:05:07\n",
            "  0% (2 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:05:10"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 27\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:05:08 Time:  0:05:08\n",
            "  0% (2 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:05:11"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 28\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:05:08 Time:  0:05:08\n",
            "  0% (2 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:05:13"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 29\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:05:08 Time:  0:05:08\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpfEuRlpbnwN",
        "colab_type": "code",
        "outputId": "aeaf1689-8405-423b-9765-edc01b7e023a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#Glove, padded to maxLen, DIGIT handled, embedding dim =300\n",
        "from metrics.accuracy import conlleval\n",
        "\n",
        "padded_docs_val = pad_sequences(val_x, maxlen=maxLen, padding='post')\n",
        "#print(padded_docs_val)\n",
        "\n",
        "labels_pred_val = []\n",
        "bar = progressbar.ProgressBar(max_value=len(padded_docs_val))\n",
        "for n_batch, sent in bar(enumerate(padded_docs_val)):\n",
        "    label = val_label[n_batch]\n",
        "    if len(label)<maxLen:     \n",
        "          label = np.pad(label, (0, maxLen - len(label)%maxLen), 'constant')\n",
        "    else:\n",
        "      label= label[-maxLen:]\n",
        "    label = np.eye(n_classes)[label][np.newaxis,:]\n",
        "    sent = sent[np.newaxis,:]\n",
        "\n",
        "    pred = model.predict_on_batch(sent)\n",
        "    pred = np.argmax(pred,-1)[0]\n",
        "    labels_pred_val.append(pred)\n",
        "\n",
        "labels_pred_val = [ list(map(lambda x: idx2la[x], y)) \\\n",
        "                                    for y in labels_pred_val]\n",
        "con_dict = conlleval(labels_pred_val, labels_val, \n",
        "                            words_val, 'measure.txt')\n",
        "\n",
        "print('Precision = {}, Recall = {}, F1 = {}'.format(\n",
        "            con_dict['r'], con_dict['p'], con_dict['f1']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100% (893 of 893) |######################| Elapsed Time: 0:00:07 Time:  0:00:07\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Precision = 93.34, Recall = 92.78, F1 = 93.06\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxhICknKk2Us",
        "colab_type": "text"
      },
      "source": [
        "## **Bidirectional LSTM Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JDO70QWdb82",
        "colab_type": "code",
        "outputId": "847ba09c-68e2-4a9c-dcdf-dcf6eef08fc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers.recurrent import SimpleRNN, LSTM\n",
        "from keras.layers.core import Dense, Dropout\n",
        "from keras.layers.wrappers import TimeDistributed\n",
        "from keras.layers import Convolution1D, Bidirectional\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(n_vocab,100))\n",
        "model.add(Bidirectional(LSTM(100,return_sequences=True)))\n",
        "model.add(Bidirectional(LSTM(100,return_sequences=True)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(TimeDistributed(Dense(n_classes, activation='softmax')))\n",
        "model.compile('rmsprop', 'categorical_crossentropy')\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, None, 100)         57200     \n",
            "_________________________________________________________________\n",
            "bidirectional_5 (Bidirection (None, None, 200)         160800    \n",
            "_________________________________________________________________\n",
            "bidirectional_6 (Bidirection (None, None, 200)         240800    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, None, 200)         0         \n",
            "_________________________________________________________________\n",
            "time_distributed_3 (TimeDist (None, None, 127)         25527     \n",
            "=================================================================\n",
            "Total params: 484,327\n",
            "Trainable params: 484,327\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVUHeNYHMtxc",
        "colab_type": "code",
        "outputId": "0b3808ae-eaae-4984-f4b4-21c3a6af1bff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import progressbar\n",
        "n_epochs = 30\n",
        "\n",
        "for i in range(n_epochs):\n",
        "    print(\"Training epoch {}\".format(i))\n",
        "    \n",
        "    bar = progressbar.ProgressBar(max_value=len(train_x))\n",
        "    for n_batch, sent in bar(enumerate(train_x)):\n",
        "        label = train_label[n_batch]\n",
        "        # Make labels one hot\n",
        "        label = np.eye(n_classes)[label][np.newaxis,:] \n",
        "        # View each sentence as a batch\n",
        "        sent = sent[np.newaxis,:]\n",
        "        \n",
        "        if sent.shape[1] > 1: #ignore 1 word sentences\n",
        "            model.train_on_batch(sent, label)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r                                                                               \r\rN/A% (0 of 4978) |                       | Elapsed Time: 0:00:00 ETA:  --:--:--"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:03:18 Time:  0:03:18\n",
            "  0% (3 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:03:34"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:03:10 Time:  0:03:10\n",
            "  0% (3 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:03:50"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:03:10 Time:  0:03:10\n",
            "  0% (3 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:04:22"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:03:10 Time:  0:03:10\n",
            "  0% (3 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:03:47"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:03:10 Time:  0:03:10\n",
            "  0% (3 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:03:41"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:03:09 Time:  0:03:09\n",
            "  0% (3 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:03:47"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:03:08 Time:  0:03:08\n",
            "  0% (3 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:03:41"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:03:08 Time:  0:03:08\n",
            "  0% (3 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:03:41"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:03:11 Time:  0:03:11\n",
            "  0% (3 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:03:46"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:03:13 Time:  0:03:13\n",
            "  0% (3 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:03:54"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:03:13 Time:  0:03:13\n",
            "  0% (3 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:03:50"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:03:13 Time:  0:03:13\n",
            "  0% (3 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:03:54"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 12\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:03:11 Time:  0:03:11\n",
            "  0% (3 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:03:53"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 13\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:03:11 Time:  0:03:11\n",
            "  0% (3 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:03:49"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 14\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:03:10 Time:  0:03:10\n",
            "  0% (3 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:03:44"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 15\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:03:12 Time:  0:03:12\n",
            "  0% (3 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:03:51"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:03:12 Time:  0:03:12\n",
            "  0% (3 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:03:50"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 17\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:03:11 Time:  0:03:11\n",
            "  0% (3 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:03:42"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 18\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:03:14 Time:  0:03:14\n",
            "  0% (3 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:04:00"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 19\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:03:12 Time:  0:03:12\n",
            "  0% (2 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:04:11"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:03:12 Time:  0:03:12\n",
            "  0% (2 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:04:22"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 21\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:03:14 Time:  0:03:14\n",
            "  0% (2 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:04:09"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 22\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:03:12 Time:  0:03:12\n",
            "  0% (3 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:03:54"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 23\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:03:14 Time:  0:03:14\n",
            "  0% (3 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:03:49"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 24\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:03:13 Time:  0:03:13\n",
            "  0% (3 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:04:05"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:03:12 Time:  0:03:12\n",
            "  0% (3 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:03:56"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 26\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:03:10 Time:  0:03:10\n",
            "  0% (3 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:03:38"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 27\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:03:12 Time:  0:03:12\n",
            "  0% (3 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:03:43"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 28\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:03:13 Time:  0:03:13\n",
            "  0% (3 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:03:52"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 29\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:03:14 Time:  0:03:14\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jomZEB5MxY9",
        "colab_type": "code",
        "outputId": "e42b59a7-a162-45c0-a2f3-6c2b53928d0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from metrics.accuracy import conlleval\n",
        "\n",
        "labels_pred_val = []\n",
        "\n",
        "bar = progressbar.ProgressBar(max_value=len(val_x))\n",
        "for n_batch, sent in bar(enumerate(val_x)):\n",
        "    label = val_label[n_batch]\n",
        "    label = np.eye(n_classes)[label][np.newaxis,:]\n",
        "    sent = sent[np.newaxis,:]\n",
        "\n",
        "    pred = model.predict_on_batch(sent)\n",
        "    pred = np.argmax(pred,-1)[0]\n",
        "    labels_pred_val.append(pred)\n",
        "\n",
        "labels_pred_val = [ list(map(lambda x: idx2la[x], y)) \\\n",
        "                                    for y in labels_pred_val]\n",
        "con_dict = conlleval(labels_pred_val, labels_val, \n",
        "                            words_val, 'measure.txt')\n",
        "\n",
        "print('Precision = {}, Recall = {}, F1 = {}'.format(\n",
        "            con_dict['r'], con_dict['p'], con_dict['f1']))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100% (893 of 893) |######################| Elapsed Time: 0:00:04 Time:  0:00:04\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Precision = 95.17, Recall = 95.81, F1 = 95.49\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRz4aH9sGue_",
        "colab_type": "text"
      },
      "source": [
        "## **Bidirectional LSTM + GLoVE Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVuNPpUYb1zP",
        "colab_type": "code",
        "outputId": "2d3d30a2-38b5-460e-c92f-b41fd991ca02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers.recurrent import SimpleRNN, LSTM\n",
        "from keras.layers.core import Dense, Dropout\n",
        "from keras.layers.wrappers import TimeDistributed\n",
        "from keras.layers import Convolution1D, Bidirectional\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(len(dicts['words2idx']), 300, weights=[embedding_matrix], input_length=maxLen, trainable=False))\n",
        "model.add(Bidirectional(LSTM(100,return_sequences=True)))\n",
        "model.add(Bidirectional(LSTM(100,return_sequences=True)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(TimeDistributed(Dense(n_classes, activation='softmax')))\n",
        "model.compile('rmsprop', 'categorical_crossentropy')\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 50, 300)           171600    \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, 50, 200)           320800    \n",
            "_________________________________________________________________\n",
            "bidirectional_4 (Bidirection (None, 50, 200)           240800    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 50, 200)           0         \n",
            "_________________________________________________________________\n",
            "time_distributed_2 (TimeDist (None, 50, 127)           25527     \n",
            "=================================================================\n",
            "Total params: 758,727\n",
            "Trainable params: 587,127\n",
            "Non-trainable params: 171,600\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1YEFvkzcb_Lm",
        "outputId": "6e13e3de-33c2-4fe3-ad51-9575dce9c503",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import progressbar\n",
        "n_epochs = 30\n",
        "\n",
        "for i in range(n_epochs):\n",
        "    print(\"Training epoch {}\".format(i))\n",
        "    \n",
        "    bar = progressbar.ProgressBar(max_value=len(padded_docs))\n",
        "    for n_batch, sent in bar(enumerate(padded_docs)):\n",
        "        label = train_label[n_batch]\n",
        "        label = np.pad(label, (0, maxLen - len(label)%maxLen), 'constant')\n",
        "        # Make labels one hot\n",
        "        label = np.eye(n_classes)[label][np.newaxis,:]\n",
        "        # View each sentence as a batch\n",
        "        sent = sent[np.newaxis,:]\n",
        "        \n",
        "        if sent.shape[1] > 1: #ignore 1 word sentences\n",
        "            model.train_on_batch(sent, label)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r                                                                               \r\rN/A% (0 of 4978) |                       | Elapsed Time: 0:00:00 ETA:  --:--:--"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:08:05 Time:  0:08:05\n",
            "  0% (1 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:09:44"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:09:00 Time:  0:09:00\n",
            "  0% (1 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:11:16"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:09:00 Time:  0:09:00\n",
            "  0% (1 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:10:04"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:08:57 Time:  0:08:57\n",
            "  0% (1 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:08:35"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:08:53 Time:  0:08:53\n",
            "  0% (1 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:09:31"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:09:14 Time:  0:09:14\n",
            "  0% (1 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:09:04"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:09:24 Time:  0:09:24\n",
            "  0% (1 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:10:50"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:09:24 Time:  0:09:24\n",
            "  0% (1 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:09:53"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:09:25 Time:  0:09:25\n",
            "  0% (1 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:10:37"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:09:25 Time:  0:09:25\n",
            "  0% (1 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:10:18"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:09:25 Time:  0:09:25\n",
            "  0% (1 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:10:32"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:09:29 Time:  0:09:29\n",
            "  0% (1 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:10:06"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 12\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:09:26 Time:  0:09:26\n",
            "  0% (1 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:09:27"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 13\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:09:25 Time:  0:09:25\n",
            "  0% (1 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:10:40"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 14\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:09:24 Time:  0:09:24\n",
            "  0% (1 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:10:44"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 15\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:09:24 Time:  0:09:24\n",
            "  0% (1 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:10:26"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:09:24 Time:  0:09:24\n",
            "  0% (1 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:08:58"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 17\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:09:20 Time:  0:09:20\n",
            "  0% (1 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:10:12"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 18\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:09:20 Time:  0:09:20\n",
            "  0% (1 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:08:57"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 19\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:09:19 Time:  0:09:19\n",
            "  0% (1 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:10:45"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:09:24 Time:  0:09:24\n",
            "  0% (1 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:09:56"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 21\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:09:25 Time:  0:09:25\n",
            "  0% (1 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:10:22"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 22\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:09:21 Time:  0:09:21\n",
            "  0% (1 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:10:01"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 23\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:09:23 Time:  0:09:23\n",
            "  0% (1 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:09:28"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 24\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:09:22 Time:  0:09:22\n",
            "  0% (1 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:10:16"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:09:22 Time:  0:09:22\n",
            "  0% (1 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:09:02"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 26\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:09:24 Time:  0:09:24\n",
            "  0% (1 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:09:58"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 27\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:09:25 Time:  0:09:25\n",
            "  0% (1 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:10:36"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 28\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:09:23 Time:  0:09:23\n",
            "  0% (1 of 4978) |                       | Elapsed Time: 0:00:00 ETA:   0:10:03"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 29\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (4978 of 4978) |####################| Elapsed Time: 0:09:24 Time:  0:09:24\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "b8nv1Xsjb_L3",
        "outputId": "723d3e4e-61cb-4e99-daf5-370daa296cf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from metrics.accuracy import conlleval\n",
        "\n",
        "labels_pred_val = []\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "padded_docs = pad_sequences(val_x, maxlen=maxLen, padding='post')\n",
        "\n",
        "bar = progressbar.ProgressBar(max_value=len(padded_docs))\n",
        "for n_batch, sent in bar(enumerate(padded_docs)):\n",
        "    label = val_label[n_batch]\n",
        "    label = np.pad(label, (0, maxLen - len(label)%maxLen), 'constant')\n",
        "    label = np.eye(n_classes)[label][np.newaxis,:]\n",
        "    sent = sent[np.newaxis,:]\n",
        "\n",
        "    pred = model.predict_on_batch(sent)\n",
        "    pred = np.argmax(pred,-1)[0]\n",
        "    labels_pred_val.append(pred)\n",
        "\n",
        "labels_pred_val = [ list(map(lambda x: idx2la[x], y)) \\\n",
        "                                    for y in labels_pred_val]\n",
        "con_dict = conlleval(labels_pred_val, labels_val, \n",
        "                            words_val, 'measure.txt')\n",
        "\n",
        "print('Precision = {}, Recall = {}, F1 = {}'.format(\n",
        "            con_dict['r'], con_dict['p'], con_dict['f1']))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100% (893 of 893) |######################| Elapsed Time: 0:00:10 Time:  0:00:10\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Precision = 95.28, Recall = 95.48, F1 = 95.38\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}